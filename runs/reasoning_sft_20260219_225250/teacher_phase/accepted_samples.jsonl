{"sample_id": "train_0_k2", "example_id": "train_0", "text": "You can ask me to call you a male, but you'll always be a woman", "label": 0, "reasoning": "Applying Rule 001: The text 'You can ask me to call you a male, but you'll always be a woman' contains language that appears to target gender identity. However, examining the exceptions: (1) The text targets an individual ('you') rather than making derogatory generalizations about transgender people as a protected group. (2) While potentially offensive, it does not use dehumanizing terms like 'pigs' or 'retarded', nor does it suggest elimination, inferiority, or violence toward a group. (3) The language criticizes an individual's gender identity claim without invoking group-based hostility or promoting systemic inferiority of transgender people as a class. Applying Rule 002: Similar analysis applies - the comment targets individual identity presentation rather than making derogatory generalizations about a protected group. No dehumanizing terms or violent suggestions are present. Applying Rule 003: The text does not contain the specific trigger patterns described (dehumanizing terms, violent suggestions, or derogatory generalizations with group targeting). The criticism is directed at an individual's gender identity claim without targeting the broader transgender community. Therefore, none of the rules trigger a hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_2_k0", "example_id": "train_2", "text": "And that's how black people can be peaceful", "label": 0, "reasoning": "Applying Rule 001: The text 'And that's how black people can be peaceful' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. It makes a statement about black people (a protected racial group) but does so in a non-derogatory manner, describing them as capable of being peaceful. There is no suggestion of elimination, inferiority, or violence toward the group, nor reinforcement of harmful stereotypes in a hostile context. The language is literal and positive rather than hostile. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations, or violent suggestions with group targeting. It does not use slurs or promote hostility toward black people as a group. Applying Rule 003: Similar to Rule 001, the text does not trigger the pattern as it uses neutral/positive language about a protected group without dehumanizing or derogatory intent. No exceptions apply since the context is not reclaimed, clinical, historical, or satirical in a way that critiques hate speech, but the text itself does not meet the trigger conditions for hate speech. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_3_k0", "example_id": "train_3", "text": "Down syndrome? Problematic people must be dead", "label": 1, "reasoning": "Applying Rule 001: The text contains 'Down syndrome' which refers to a protected group (people with disabilities) and 'problematic people must be dead' which suggests elimination/violence toward that group. This meets the trigger pattern: (1) 'Down syndrome' could be used as a derogatory generalization, (2) 'must be dead' suggests elimination of people with Down syndrome, and (3) it reinforces harmful stereotypes about people with disabilities being 'problematic.' No exceptions apply: it's not reclaimed/clinical/satirical context, not metaphorical criticism of non-group entities, and specifically targets a protected group rather than individual behavior. Applying Rule 002: Same analysis - dehumanizing language with hostile intent targeting a protected group (people with Down syndrome). No exception for individual behavior targeting applies. Applying Rule 003: Same analysis - dehumanizing language with hostile intent and group targeting. No exceptions for reclaimed use or metaphorical criticism apply. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_4_k0", "example_id": "train_4", "text": "Child abuse, manipulation etc. What the hell are we transforming this world into??? How sick mind can people have and how stupid can others be to send their kids there???", "label": 0, "reasoning": "Applying Rule 001: The text expresses outrage about child abuse and manipulation, using strong language ('what the hell', 'how sick mind', 'how stupid') directed at people who commit or enable such acts. This targets individuals based on their behavior (abusing children or sending children to abusive situations), not a protected group based on race, gender, religion, national origin, or sexual orientation. The language is not dehumanizing terms like 'pigs' or 'retarded', nor does it suggest elimination, inferiority, or violence toward a group. It criticizes specific harmful actions without invoking group-based hostility or stereotypes. Applying Rule 002: Similar analysis - the text targets individual behavior (child abuse and enabling it) without derogatory generalizations about a protected group. No dehumanizing language or violent suggestions toward groups are present. Applying Rule 003: The criticism is directed at individuals engaging in or enabling harmful behavior, not at a protected group identity. The language, while strong, is metaphorical criticism of specific actions ('how sick mind', 'how stupid') rather than group-based dehumanization. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_6_k0", "example_id": "train_6", "text": "Yet there is vastly more money spent on breast cancer, than prostate cancer, this is lethal discrimination.", "label": 0, "reasoning": "Applying Rule 001: The text discusses funding disparities between breast cancer and prostate cancer research. It uses the term 'lethal discrimination' to describe this disparity. There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. The criticism targets systemic funding allocation rather than any protected group based on race, gender, religion, national origin, or sexual orientation. While the term 'discrimination' is used, it refers to healthcare resource distribution, not group-based hostility. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context, and the target is not an individual or protected group. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment addresses healthcare funding disparities without targeting a protected group or promoting generalized hostility. Applying Rule 003: Again, no trigger patterns present. The language criticizes a systemic issue (funding allocation) without metaphorical slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context. All three rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_8_k0", "example_id": "train_8", "text": "We need to exterminate people that subject children to such Perversion", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'exterminate' which suggests elimination or violence toward a group. The target is 'people that subject children to such Perversion' - this appears to refer to individuals who engage in child sexual abuse or exploitation. While this targets a specific behavior (child abuse), it does not clearly target a protected group based on race, gender, religion, national origin, or sexual orientation. The term 'exterminate' is violent, but the target is defined by behavior rather than identity. According to Rule 001 exceptions, this would not apply if the language criticizes individuals without linking them to a broader protected group. Applying Rule 002: Similar analysis - the text uses violent language ('exterminate') but targets individuals based on behavior (subjecting children to perversion) rather than a protected group identity. The exception for criticism directed at individual behavior applies. Applying Rule 003: The text contains violent suggestion ('exterminate') but targets individuals engaged in specific harmful behavior, not a protected group. The exception for targeting individuals without reference to group identity applies. All three rules require group targeting of protected characteristics for classification as hate speech (1), and this text targets behavior rather than identity-based groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_9_k0", "example_id": "train_9", "text": "Goosebumps when the beat drops üòä", "label": 0, "reasoning": "Applying Rule 001: The text 'Goosebumps when the beat drops üòä' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses a positive emotional reaction to music with an emoji, showing no group targeting, hostile intent, or reinforcement of harmful stereotypes. The exceptions for reclaimed, clinical, historical, or satirical contexts do not apply as the text is unrelated to such contexts. Applying Rule 002: No dehumanizing language or group-based derogatory generalizations are present. The text lacks indicators like non-literal slurs, suggestions of elimination/inferiority/violence toward groups, or hostile stereotypes. The exceptions for reclaimed contexts or criticism of individual behavior are irrelevant here. Applying Rule 003: Similar to Rules 001 and 002, the text contains no elements matching the trigger pattern for dehumanizing or derogatory group-based language with hostile intent. It is a neutral, positive statement about music enjoyment without metaphorical criticism of entities or individual targeting with group reference. All rules indicate the text does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_10_k0", "example_id": "train_10", "text": "Why are people so dumb? The police were yelling at everyone to get out of the area yet people just stood there or recorded, guess they want to die.", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'dumb' which could be considered derogatory, but it targets unspecified 'people' in a general behavioral context rather than a protected group based on race, gender, religion, nationality, or sexual orientation. The criticism is directed at individual behavior (not evacuating when instructed) without invoking group-based hostility, dehumanization, or violence toward a protected group. The term 'dumb' is used colloquially to criticize decision-making, not as a slur targeting a protected identity. No suggestion of elimination, inferiority, or violence toward a group is present. Applying Rule 002: Similar analysis applies - the language criticizes individual behavior (failure to follow police instructions) without targeting a protected group or promoting generalized hostility. No dehumanizing terms with hostile intent toward protected groups are used. Applying Rule 003: The text does not use dehumanizing terms like 'pigs' or 'retarded' in the context described in the rule. The criticism is of individual actions (standing still or recording instead of evacuating) rather than group identity. No protected group is targeted, and the context lacks hostile intent toward any identity-based community.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_11_k0", "example_id": "train_11", "text": "you are a great brother to abbie, that family is changing the world!", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It praises an individual ('you') and a family ('that family'), with no group targeting or hostile intent. The language is positive ('great brother', 'changing the world') and targets specific individuals without reference to protected group identities. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent present. The comment focuses on individual/family praise without stigmatizing any group. Applying Rule 003: Same analysis - no trigger patterns are met. The text uses metaphorical language ('changing the world') in a positive context, not as criticism of any entity. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_12_k0", "example_id": "train_12", "text": "Is this guy actually autistic or Is he faking it", "label": 0, "reasoning": "Applying Rule 001: The text 'Is this guy actually autistic or Is he faking it' questions whether an individual is genuinely autistic or pretending. This targets individual behavior (potential feigning of a condition) without making derogatory generalizations about people with autism as a protected group. No dehumanizing terms, violent suggestions, or group-based hostility are present. The exception for 'criticizes individuals perceived as faking or misrepresenting personal conditions without linking them to a broader protected group' applies. Applying Rule 002: Similar analysis - the comment questions individual behavior without targeting a protected group or promoting generalized hostility toward people with autism. The exception for 'criticism directed at individual behavior without targeting a protected group' applies. Applying Rule 003: The text does not use dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. It questions an individual's authenticity without reference to group identity, falling under the exception for 'target is an individual without reference to group identity'. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_13_k0", "example_id": "train_13", "text": "I wish everyone had a father like him so loving and caring", "label": 0, "reasoning": "Applying Rule 001: The text expresses a positive wish for everyone to have a father who is 'loving and caring'. There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting. The language is complimentary and universal ('everyone'), not hostile toward any group. No exceptions apply as there is no offensive content to evaluate. Applying Rule 002: Same analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The text promotes positive family values without targeting any protected group. Applying Rule 003: Same analysis - the text lacks all key indicators (slurs, elimination suggestions, harmful stereotypes) and contains no hostile context. All rules consistently indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_14_k0", "example_id": "train_14", "text": "People hate you People think your ugly  People think your a horrible person Well guess what   No ones name is people", "label": 0, "reasoning": "Applying Rule 001: The text uses derogatory language ('hate you', 'ugly', 'horrible person') but targets an individual ('you') without reference to any protected group identity (racial, gender, religious, national, sexual orientation). The language appears to be directed at a specific person rather than making generalizations about a group. The term 'people' is used generically rather than referring to a protected group. No dehumanizing terms, violent suggestions, or group-based hostility are present. The text does not trigger the rule as it lacks group targeting and protected group references. Applying Rule 002: Similar analysis - the derogatory language targets individual characteristics ('ugly', 'horrible person') rather than a protected group. No suggestion of elimination, inferiority, or violence toward a group. The criticism appears directed at individual behavior/characteristics without group-based hostility. Applying Rule 003: Same conclusion - the language targets an individual ('you') without group identity reference. The metaphorical use of 'people' does not constitute protected group targeting. The text lacks the key indicators of non-literal slurs, group elimination suggestions, or harmful stereotypes about protected groups. All three rules indicate this should be classified as non-hateful (0) due to individual targeting without protected group reference.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_15_k0", "example_id": "train_15", "text": "Lmao, fucking hilarious", "label": 0, "reasoning": "Applying Rule 001: The text 'Lmao, fucking hilarious' contains profanity ('fucking') but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no suggestion of elimination/inferiority/violence toward any group, and no reinforcement of harmful stereotypes. The profanity appears to be used as an intensifier for 'hilarious' in an informal expression of amusement. Applying Rule 002: Similar analysis - no dehumanizing language, no group-based derogatory generalizations, no violent suggestions targeting protected groups. The comment lacks intent to dehumanize any identity-based community. Applying Rule 003: Again, no dehumanizing terms, no group targeting, no suggestion of elimination/inferiority/violence toward protected groups. The language is not used metaphorically to criticize group-based entities. All three rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_16_k0", "example_id": "train_16", "text": "Video games without cars are awful. Piece of shits", "label": 0, "reasoning": "Applying Rule 001: The text uses derogatory language ('piece of shits') but targets video games without cars, which is not a protected group (racial, gender, religious, national, or sexual orientation). The criticism is directed at a product category, not at individuals or identity-based groups. No dehumanizing terms toward protected groups, violent suggestions, or reinforcement of harmful stereotypes are present. Applying Rule 002: Similar analysis - the derogatory language targets video games, not a protected group, and lacks group-based hostility or intent to dehumanize an identity-based community. Applying Rule 003: The language is offensive but metaphorical/colloquial criticism of a non-group-based entity (video games), falling under the exception for non-group-based targets. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_17_k3", "example_id": "train_17", "text": "Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook", "label": 1, "reasoning": "Analyzing the text 'Indian Ned Flanders. You look like you professionally harass subpar women on Facebook' against the rulebook: 1. The text contains 'Indian' which references a national/ethnic group, and 'subpar women' which references a gender group. 2. The language 'professionally harass' suggests harmful behavior targeting women, and 'subpar' is derogatory toward women as a group. 3. This constitutes derogatory generalizations about protected groups (national and gender) with hostile intent, as it stereotypes Indian people and devalues women. 4. Checking exceptions: This is not reclaimed, clinical, historical, or satirical context critiquing hate speech; it appears to be a direct insult. 5. The targeting is group-based ('Indian' as a national group, 'women' as a gender group) rather than purely individual criticism. Therefore, applying Rule 001, Rule 002, and Rule 003, this meets the trigger patterns for hate speech due to derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_18_k0", "example_id": "train_18", "text": "Good Muslims deserved attack and damage", "label": 1, "reasoning": "Applying Rule 001: The text 'Good Muslims deserved attack and damage' contains derogatory language suggesting violence ('attack and damage') toward a protected religious group (Muslims). It uses group-based targeting ('Muslims') and implies that members of this group deserve harm, which suggests elimination or violence toward the group. There is no indication of reclaimed, clinical, historical, or satirical context that would exempt this under the exceptions. The language is not metaphorical, self-referential, or directed at individual behavior without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected religious group with hostile intent, as it suggests violence and harm toward Muslims as a group. It does not target individual behavior or fall under the exceptions for reclaimed or clinical contexts. Applying Rule 003: The text contains dehumanizing or derogatory language with group targeting and violent suggestions toward Muslims, a protected religious group. It reinforces harmful stereotypes in a hostile context by implying that Muslims deserve attack and damage. The exceptions do not apply as it is not metaphorical, self-referential, or in a context that critiques hate speech. Therefore, all relevant rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_19_k0", "example_id": "train_19", "text": "With her nose she can detect an immigration officer from 70 yards", "label": 0, "reasoning": "Applying Rule 001: The text uses metaphorical language ('with her nose she can detect') but does not contain dehumanizing terms like 'pigs' or 'retarded', derogatory generalizations about protected groups, or violent suggestions. The target appears to be an individual ('her') with a specific ability related to immigration officers, without group-based targeting or hostile intent toward a protected group. No exceptions apply as there is no clear group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The comment focuses on an individual's perceived ability, not protected group characteristics. Applying Rule 003: Same conclusion - the metaphorical language criticizes an individual's behavior (detecting immigration officers) without reference to group identity or protected characteristics. The text lacks indicators of non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in hostile context. Therefore, all rules indicate non-hateful classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_20_k0", "example_id": "train_20", "text": "Son, the greatest lesson I can teach you is this: Don't tell your troubles to others. Because if you tell ten people of the problem you are having. Seven of them won't care, two of them will laugh at you behind your back. One of them will tell you to deal with yourself.", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. It offers general life advice about sharing troubles with others, using numerical examples (seven, two, one) to illustrate human behavior patterns without targeting any specific group. The language is metaphorical ('laugh at you behind your back') but criticizes individual human behaviors in a non-hostile context, not protected groups. No exceptions apply as there is no group-based targeting or hostile intent. Applying Rule 002: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting are present. The text discusses individual behavior in interpersonal relationships without promoting hostility toward identity-based communities. Applying Rule 003: Similar analysis - no trigger patterns for dehumanizing language, group-based derogatory generalizations, or violent suggestions with group targeting. The metaphorical criticism ('laugh at you behind your back') targets individual human behaviors generally, not protected groups. All rules indicate the text lacks the necessary elements for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_21_k0", "example_id": "train_21", "text": "Can't wait for the music video!!!!!", "label": 0, "reasoning": "Applying the rules from the rulebook: Rule 001, Rule 002, and Rule 003 all focus on detecting hate speech based on dehumanizing or derogatory group-based language with hostile intent, including indicators like slurs, suggestions of violence or elimination, or reinforcement of harmful stereotypes targeting protected groups. The text 'Can't wait for the music video!!!!!' contains no such language; it expresses excitement about a music video without any reference to protected groups, derogatory terms, violence, or hostile context. There are no exceptions to consider as the text lacks offensive content entirely. Therefore, none of the rules are triggered, and the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_22_k0", "example_id": "train_22", "text": "Gosh you guys are getting less funny with each episode.", "label": 0, "reasoning": "Applying Rule 001: The text 'Gosh you guys are getting less funny with each episode' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. It targets 'you guys' in a context of entertainment critique, which appears to refer to content creators or performers, not a protected group. There is no suggestion of elimination, inferiority based on group identity, or reinforcement of harmful stereotypes. The criticism is about humor quality, not group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The comment addresses perceived decline in entertainment value without targeting any identity-based community. Applying Rule 003: Again, no trigger patterns present - the language is not metaphorical slurs, does not suggest violence toward groups, and lacks hostile context against protected groups. All rules indicate this does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_23_k0", "example_id": "train_23", "text": "That guys chin strap bothers me man....idk why.", "label": 0, "reasoning": "Analyzing the text 'That guys chin strap bothers me man....idk why.' against the rulebook: Rule 001 requires dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. This text contains no such language - it expresses personal annoyance about someone's chin strap without any group-based targeting, slurs, or hostile intent. Rule 002 similarly requires dehumanizing language with group targeting, which is absent here. Rule 003 also requires the same pattern of group-based derogatory language. The text targets an individual's appearance (chin strap) without reference to any protected group identity, and uses no dehumanizing terms or violent suggestions. All rules include exceptions for individual targeting without group-based hostility, which applies here. Therefore, no rule triggers for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_24_k0", "example_id": "train_24", "text": "I would fucking kill Jared leto", "label": 0, "reasoning": "Applying Rule 001: The text contains violent language ('I would fucking kill') targeting an individual (Jared Leto) by name. There is no reference to any protected group (racial, gender, religious, national, sexual orientation) - the target is a specific celebrity. The language is directed at an individual without invoking group identity or making derogatory generalizations about a protected group. No dehumanizing terms or slurs targeting groups are present. No suggestion of elimination, inferiority, or violence toward a group. No reinforcement of harmful stereotypes about protected groups. The exception applies: 'if the target is an individual without reference to group identity.' Applying Rule 002: Similar analysis - violent language targeting an individual, not a protected group. No dehumanizing terms targeting groups, no derogatory generalizations about protected groups. The exception applies: criticism directed at individual behavior (though here it's a threat, not criticism of behavior) without targeting a protected group. Applying Rule 003: Same analysis - individual targeting without group reference, no protected group targeting, no dehumanizing group-based language. The exception applies: 'if the target is an individual without reference to group identity.' All rules indicate this does not meet the criteria for hate speech as defined, despite the violent language, because it lacks the required group-based targeting of protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_25_k0", "example_id": "train_25", "text": "These dogs lie through their teeth so that they can come here and set up jihad on the infidels.", "label": 1, "reasoning": "Applying Rule 001: The text uses 'dogs' as a dehumanizing term targeting a group ('they' referring to people coming 'here'), with hostile intent implied by 'lie through their teeth' and 'set up jihad on the infidels'. This suggests violent action against a religious group (infidels), reinforcing harmful stereotypes about religious conflict. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; it directly targets a protected group (religious/national) with implied violence. Applying Rule 002: Same analysis confirms dehumanizing language ('dogs') with group targeting and violent suggestions ('set up jihad'), meeting the trigger pattern without exceptions. Applying Rule 003: Consistent with other rules, the metaphorical use of 'dogs' is not targeting non-group entities but a protected group, with hostile context. Thus, all relevant rules classify this as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_26_k0", "example_id": "train_26", "text": "Facing challenges is hard to go through.", "label": 0, "reasoning": "Applying Rule 001: The text 'Facing challenges is hard to go through' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group or individual with hostile intent. No exceptions are relevant as there is no offensive language present. Applying Rule 002: The text lacks dehumanizing language, group targeting, or suggestions of elimination/inferiority/violence toward any protected group. No exceptions apply. Applying Rule 003: The text contains no slurs, derogatory generalizations, or violent suggestions directed at protected groups. It is a general statement about challenges without any group-based hostility. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_27_k0", "example_id": "train_27", "text": "Women cannot create children, only men can do that. Women can bear children.", "label": 0, "reasoning": "Applying Rule 001: The text makes a biological statement about gender roles in reproduction. It does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations, or violent suggestions. The statement targets women and men as groups but lacks hostile intent, reinforcement of harmful stereotypes, or suggestions of elimination, inferiority, or violence. The language appears factual/biological rather than derogatory. No exceptions apply as there's no reclaimed, clinical, historical, or satirical context, and it's not metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations with hostile intent, or violent suggestions toward protected groups. The statement lacks indicators like non-literal slurs or promotion of group-based hostility. Applying Rule 003: Same conclusion - the text discusses biological functions without dehumanizing language, derogatory generalizations with hostile intent, or violent suggestions. It targets gender groups but in a descriptive rather than hostile manner. All three rules indicate this is not hate speech as it lacks the required elements of dehumanization, derogatory generalization with hostile intent, or violence toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_28_k0", "example_id": "train_28", "text": "Women are our property. The sooner they realize that, the better.", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('property') and makes a derogatory generalization about a protected group (women based on gender). It suggests inferiority ('the sooner they realize that, the better') and reinforces harmful stereotypes in a hostile context by treating women as objects to be owned. This meets the trigger pattern with group targeting and hostile intent. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses dehumanizing terms ('property') with group targeting toward a protected group (women), suggesting inferiority and promoting harmful stereotypes with hostile intent. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text uses dehumanizing language ('property') with group targeting toward a protected group (women), suggesting inferiority and reinforcing harmful stereotypes in a hostile context. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_30_k3", "example_id": "train_30", "text": "I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people", "label": 1, "reasoning": "Applying Rule 001: The text expresses hatred toward China ('I honestly hate China') and makes derogatory generalizations about its people ('Its horrible people'). This targets a national group (Chinese people) with hostile intent, suggesting inferiority and reinforcing harmful stereotypes. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The targeting is explicitly group-based (Chinese people as a whole). Applying Rule 002: Same analysis - dehumanizing/derogatory language targeting a protected national group with hostile intent. No exception for individual behavior targeting applies. Applying Rule 003: Same analysis - derogatory generalization about a national group with hostile intent, not metaphorical or individual targeting. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_31_k0", "example_id": "train_31", "text": "The eye contact never lies", "label": 0, "reasoning": "Applying Rule 001: The text 'The eye contact never lies' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The statement appears to be a general observation about human behavior without hostile intent or group-based targeting. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent present. Applying Rule 003: Same analysis - no trigger patterns for hate speech detected. The text is neutral and does not meet any criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_32_k1", "example_id": "train_32", "text": "Abortion is a solution for autism", "label": 1, "reasoning": "Applying Rule 001: The text 'Abortion is a solution for autism' suggests elimination of individuals with autism through abortion. This targets people with autism as a protected group (disability-based) and implies they should be eliminated, which aligns with the rule's trigger pattern of suggesting elimination toward a group. There is no indication of reclaimed, clinical, historical, or satirical context, nor is it targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory generalization by implying autism should be 'solved' through abortion, suggesting elimination of a protected group (people with autism). This meets the trigger pattern of violent suggestions toward a group. No exceptions apply as it's not about individual behavior. Applying Rule 003: The text suggests elimination ('solution') of people with autism as a group, which is dehumanizing and promotes violence/elimination toward a protected disability group. No metaphorical use or individual targeting exceptions apply. All three rules indicate hate speech due to group-based targeting with elimination intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_33_k0", "example_id": "train_33", "text": "stupid black women,if i were in that restaurant, i would had whipped their ass", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('stupid black women') targeting a protected group (racial and gender). It contains violent suggestions ('whipped their ass') directed at that group. This meets the trigger pattern: (1) uses derogatory generalizations about a protected group, (2) suggests violence toward a group, and (3) reinforces harmful stereotypes in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it directly targets a racial/gender group with hostility. Applying Rule 002: Same analysis applies - dehumanizing/derogatory language with group targeting and violent suggestions. No exception for individual behavior targeting since this clearly targets 'black women' as a group. Applying Rule 003: Same analysis applies - derogatory group-based language with violent suggestions and hostile intent. No metaphorical use or individual targeting exception applies. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_34_k0", "example_id": "train_34", "text": "All asian people look identical to this one. He is the mother of Asia", "label": 0, "reasoning": "Applying Rule 001: The text contains 'All asian people look identical' which is a derogatory generalization about a protected national/racial group (Asian people). This reinforces harmful stereotypes about physical appearance. However, the second part 'He is the mother of Asia' appears metaphorical and potentially complimentary rather than hostile. The first statement targets a group with a harmful stereotype, but lacks explicit dehumanizing terms, violent suggestions, or clear hostile intent. The rule requires 'dehumanizing terms, derogatory generalizations... or violent suggestions in combination with group targeting' with hostile intent. While this contains a derogatory generalization, the overall tone and context don't clearly demonstrate hostile intent. Applying Rule 002: Similar analysis - contains a derogatory generalization about a protected group but lacks clear indicators of hostile intent or dehumanizing language. Applying Rule 003: Same analysis as Rule 001. The text contains a harmful stereotype but doesn't meet the threshold for dehumanizing language with hostile intent. No exceptions apply as this isn't reclaimed, clinical, historical, or satirical context. The label is 0 because while offensive, it doesn't clearly meet the criteria for hate speech under the provided rules which require more explicit hostile intent or dehumanizing language.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_35_k0", "example_id": "train_35", "text": "So how long have you lived in your mother's basement?", "label": 0, "reasoning": "Applying Rule 001: The text 'So how long have you lived in your mother's basement?' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It targets an individual's living situation without reference to group identity (e.g., racial, gender, religious, national, or sexual orientation groups). The language is metaphorical ('mother's basement' implying immaturity or lack of independence) but criticizes an individual behavior/lifestyle, not a protected group. No indicators of group-based hostility, elimination, inferiority, violence, or harmful stereotypes are present. Exceptions apply as the target is an individual without group identity reference and the criticism is non-generalizing. Applying Rule 002: Similar analysis - no dehumanizing terms, group targeting, or hostile intent toward protected groups; targets individual behavior. Applying Rule 003: Same conclusion - metaphorical use targets individual, not group-based entities or protected groups. All rules indicate classification as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_37_k0", "example_id": "train_37", "text": "I very much appreciate the Asian woman's smarts.", "label": 0, "reasoning": "Applying Rule 001: The text 'I very much appreciate the Asian woman's smarts' contains a reference to 'Asian woman' which identifies a protected group (racial and gender). However, the language used is positive ('appreciate', 'smarts') rather than dehumanizing or derogatory. There is no use of slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes. The comment appears to express admiration rather than hostility. No exceptions apply as this is not reclaimed, clinical, historical, or satirical context. Applying Rule 002: Similar analysis - the text references a protected group but with positive language, lacking dehumanizing terms, derogatory generalizations, or violent suggestions. No group-based hostility is present. Applying Rule 003: Same conclusion - while the text identifies a protected group ('Asian woman'), the language is appreciative rather than hostile, and contains no indicators of hate speech as defined in the trigger patterns. All three rules require dehumanizing/derogatory language with hostile intent combined with group targeting, which is absent here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_39_k0", "example_id": "train_39", "text": "you should be allowed to be gay you should also be allowed to hate gay people thats freedom i can be myself and people can hate me for it i believe it is my full right to jack off to chris hemsworth and i believe it is a businesss right to not serve me for that it might not be right but its fair and freedom doesnt discriminate on ethics", "label": 0, "reasoning": "Applying Rule 001: The text discusses gay people as a protected group but does not use dehumanizing terms ('pigs', 'retarded'), derogatory generalizations, or violent suggestions. The speaker expresses personal views about rights and freedoms regarding sexual orientation, but lacks indicators of hostile intent, elimination suggestions, or reinforcement of harmful stereotypes. The language is philosophical/political discussion about rights rather than group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting gay people as a group. The text acknowledges the right to 'hate gay people' but frames this as a matter of freedom rather than promoting such hatred. Applying Rule 003: Again, no trigger patterns present - no slurs, elimination suggestions, or hostile stereotypes. The context appears to be a discussion about rights and freedoms rather than hate speech promotion. All three rules emphasize exceptions for non-hostile contexts and lack of group-targeting hostility, which applies here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_40_k1", "example_id": "train_40", "text": "They are violent fucking savages what the fuck did you think would happen? We wont be thrown around, this is our continent and our responsibility to preserve.", "label": 0, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('savages') and violent suggestions ('violent fucking savages', 'what the fuck did you think would happen?') with group targeting implied by 'they' and 'our continent' suggesting an 'us vs. them' dynamic. However, the text lacks explicit reference to protected groups (racial, gender, religious, national, sexual orientation) - it appears to target a generalized 'they' without specifying identity characteristics. The language criticizes perceived violent behavior rather than making derogatory generalizations about identity-based groups. Applying Rule 002: Similar analysis - while dehumanizing language is present ('savages'), there's no clear targeting of protected groups as defined in the rule. The text appears to be about territorial/political conflict rather than identity-based hostility. Applying Rule 003: Same conclusion - the dehumanizing term 'savages' is used, but without clear connection to protected group characteristics. The context suggests conflict over territory/responsibility ('our continent', 'our responsibility') rather than group-based hatred targeting protected identities. All rules require group targeting of protected characteristics for classification as hate speech, which is not clearly present here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_41_k0", "example_id": "train_41", "text": "This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory terms 'homo' and 'faggot' targeting sexual orientation (a protected group). This constitutes dehumanizing/derogatory group-based language. The context appears hostile (criticizing Spike Lee's appearance at the Oscars with negative framing). No exceptions apply - it's not reclaimed/self-referential (targeting another person), not clinical/historical discussion, not satirical critique of hate speech, and not metaphorical criticism of non-group entities. The targeting is group-based (sexual orientation) rather than purely individual behavior criticism. Applying Rule 002: Same analysis - derogatory terms targeting protected group (sexual orientation) with hostile intent. No exception for individual behavior targeting since the language invokes group identity. Applying Rule 003: Same analysis - dehumanizing terms targeting protected group with hostile context. No applicable exceptions. All three rules indicate hate speech classification.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_42_k0", "example_id": "train_42", "text": "That’s wrong! Even though they disagree with her beliefs, they have no right to put their hands on a woman", "label": 0, "reasoning": "Analyzing the text 'That’s wrong! Even though they disagree with her beliefs, they have no right to put their hands on a woman' against the rulebook: Rule 001, 002, and 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. This text expresses disapproval of physical violence against a woman, specifically stating it's wrong to put hands on her despite disagreement with her beliefs. There are no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (it references 'a woman' but not women as a group in a derogatory way), and no violent suggestions - instead it condemns violence. The text lacks: (1) non-literal/metaphorical slurs, (2) suggestions of elimination/inferiority/violence toward a group, and (3) reinforcement of harmful stereotypes in hostile context. It targets specific individuals ('they') and their actions toward another individual ('a woman'), without invoking group-based hostility against protected categories. Therefore, none of the rules apply, and the label should be 0 (non-hateful).", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_43_k0", "example_id": "train_43", "text": "Fuck off niggers WV is full", "label": 1, "reasoning": "Applying Rule 001: The text contains the racial slur 'niggers' targeting a protected racial group. This qualifies as derogatory group-based language with hostile intent, as it uses a non-literal slur and reinforces harmful stereotypes in a hostile context. The phrase 'Fuck off' indicates clear hostility, and 'WV is full' suggests exclusion or elimination of this group from West Virginia. None of the exceptions apply: this is not reclaimed usage (not self-referential), not clinical/historical context, not satirical critique, not metaphorical criticism of non-group entities, and not targeting specific individuals without group reference. Applying Rule 002: The same analysis applies - dehumanizing term targeting a protected racial group with hostile intent. The exception for individual behavior criticism doesn't apply since this targets a racial group. Applying Rule 003: Same conclusion - derogatory group-based language with hostile intent, with no applicable exceptions. All three rules indicate this qualifies as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_44_k0", "example_id": "train_44", "text": "All values, unless otherwise stated, are in US dollars.\"", "label": 0, "reasoning": "Applying Rule 001: The text 'All values, unless otherwise stated, are in US dollars' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to any group-based targeting, hostile intent, stereotypes, or elimination rhetoric. The text is purely informational about currency denomination. None of the trigger patterns apply. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent present. The text discusses financial values without any reference to protected groups or harmful stereotypes. Applying Rule 003: Same conclusion - the text lacks all key indicators including non-literal slurs, suggestions of elimination/inferiority/violence toward groups, and reinforcement of harmful stereotypes. The language is neutral and factual about currency specification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_45_k0", "example_id": "train_45", "text": "You should be so meaner to dyslexic people.", "label": 1, "reasoning": "Applying Rule 001: The text 'You should be so meaner to dyslexic people' targets dyslexic people as a group. Dyslexia is a learning disability, which falls under disability as a protected characteristic. The phrase 'should be so meaner' suggests advocating for hostile treatment toward this group, which aligns with the rule's indicators of suggesting inferiority or hostility toward a protected group. There is no indication this is reclaimed, clinical, historical, satirical, or self-referential context. The language is directly targeting the group based on their disability, not individual behavior. Therefore, Rule 001 applies with label 1. Applying Rule 002: Similar analysis applies - derogatory suggestion toward a protected group (people with dyslexia) with hostile intent (being meaner), without exceptions for reclaimed or individual targeting contexts. Rule 002 also applies with label 1. Applying Rule 003: Same reasoning as above - group targeting of protected characteristic (disability) with hostile suggestion, no applicable exceptions. Rule 003 applies with label 1. All three rules consistently indicate hate speech due to derogatory group-based language with hostile intent toward a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_46_k0", "example_id": "train_46", "text": "Support gay pride", "label": 0, "reasoning": "Applying Rule 001: The text 'Support gay pride' expresses support for a protected group (LGBTQ+ community) without using dehumanizing terms, derogatory generalizations, or violent suggestions. It lacks hostile intent and does not target any group negatively. This falls under the exception for reclaimed or positive contexts that critique hate speech rather than promote it. Applying Rule 002: The text does not contain dehumanizing language or group-based hostility; it is supportive rather than derogatory. Applying Rule 003: Similar to Rule 001, the text uses positive language about a protected group without any indicators of hate speech (no slurs, elimination suggestions, or harmful stereotypes). All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_47_k0", "example_id": "train_47", "text": "This Korean bitch is like a pig. That’s how they made an army of sumos there in their shithole country", "label": 1, "reasoning": "Applying Rule 1, Rule 2, and Rule 3: The text uses dehumanizing terms ('bitch', 'pig', 'sumos', 'shithole country') and derogatory generalizations targeting a protected group based on nationality (Korean). It suggests inferiority and reinforces harmful stereotypes (e.g., comparing people to pigs and sumos) in a hostile context, with group targeting implied by 'they' and 'their country'. No exceptions apply: it is not reclaimed, clinical, historical, satirical, or metaphorical for non-group entities, and it targets a group rather than individual behavior without critique of hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_49_k0", "example_id": "train_49", "text": "Do people even care about the color of the persons skin or sexuality in a movie?Its just a bloody movie.", "label": 0, "reasoning": "Applying Rule 001: The text discusses skin color and sexuality in movies, but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses frustration about focus on identity in movies ('Do people even care...'), but targets no specific group with hostile intent. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes. Exceptions apply as it criticizes a concept (focus on identity in media) rather than targeting a protected group. Applying Rule 002: No dehumanizing language or group-based targeting present. The comment questions societal focus on identity in entertainment without making derogatory generalizations about racial, gender, religious, national, or sexual orientation groups. Applying Rule 003: Similar analysis - no trigger patterns met. The text lacks hostile intent toward protected groups and instead comments on movie discourse. All rules indicate classification as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_50_k2", "example_id": "train_50", "text": "I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('male bitch') targeting a gender group (males). It makes a generalization about not hiring any male, combined with the derogatory term 'bitch', which suggests inferiority and reinforces harmful stereotypes in a hostile employment context. There is no indication of reclaimed, clinical, historical, or satirical context. The targeting is group-based (males as a gender group) rather than individual-specific. Applying Rule 002: The text uses derogatory language ('male bitch') with hostile intent against a protected group (gender). It suggests exclusion from employment based on group identity, indicating inferiority. The comment targets the group as a whole, not individual behavior. Applying Rule 003: The text contains derogatory group-based language ('male bitch') targeting a protected group (gender) with hostile intent (refusal to hire). It reinforces harmful stereotypes and suggests exclusion/inferiority. No exceptions apply as it's not metaphorical, self-referential, or targeting non-group entities. All three rules indicate this meets the criteria for hate speech due to derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_51_k0", "example_id": "train_51", "text": "People in 2019 keep it that of racism ???... I'm puertorican, my grandma is native, my grandpa black, my mom is \"mulata\" , my dad is white. I'm white skin green eyes, flat nose, big lips... Haha What raze should I date??... I gonna tell you something- I love all kind of womens all of shapes, but curvy, Latinas, white, black, asian, arabian. I dnt know but every single raze and person have different type of beauty.  So lets keep racism down in the floor and rise the love for the humanity. And everybody have the personal choose of dating who's more attractive to them.  I choose the mix between white and black. We call mulata...Happy life!!!", "label": 0, "reasoning": "Applying Rule 001: The text does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It explicitly promotes anti-racism ('lets keep racism down in the floor and rise the love for the humanity'), celebrates diversity, and describes personal dating preferences without hostility toward any group. The mention of racial terms ('white', 'black', 'mulata', etc.) is descriptive of the author's family background and personal appreciation, not derogatory. No exceptions apply as there is no group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language or group targeting with hostile intent. The text focuses on individual appreciation and anti-racist sentiment. Applying Rule 003: Again, no trigger patterns present; the context is positive and inclusive, not hostile. All rules indicate the text lacks the key indicators for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_52_k0", "example_id": "train_52", "text": "I'm white, I'm proud to be white, I love diversity and people of all nations.... lets move on. :)", "label": 0, "reasoning": "Applying Rule 001: The text expresses pride in being white and love for diversity and all people. It does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The statement 'I'm white, I'm proud to be white' could potentially reference racial identity, but it lacks hostile intent, group targeting, or reinforcement of harmful stereotypes. The positive affirmation of diversity ('I love diversity and people of all nations') and neutral closing ('lets move on. :)') further indicate non-hostile context. No exceptions apply as this is not reclaimed, clinical, historical, or satirical context, but the content itself does not trigger the rule's patterns. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The expression of racial pride without denigration of others does not constitute group-based hostility. Applying Rule 003: Same conclusion - no trigger patterns present. The text expresses personal identity positively while affirming inclusivity, lacking any indicators of elimination, inferiority, or violence toward groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_53_k0", "example_id": "train_53", "text": "'Nah cut it off Im sure I won't regret it '", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no mention of racial, gender, religious, national, or sexual orientation groups. The phrase 'cut it off' appears metaphorical or personal (possibly referring to hair or a personal decision) with no group targeting or hostile intent toward any protected group. Applying Rule 002: No dehumanizing language or group-based targeting is present. The text lacks indicators like slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes. Applying Rule 003: Similar analysis - no protected groups are referenced, no dehumanizing terms are used, and the context appears personal/metaphorical without hostile group targeting. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_54_k0", "example_id": "train_54", "text": "I wonder why they didn' throw the fire booms in that cult when those Muslims were inside. That would have been one hell of a BBQ.", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('fire booms', 'BBQ') that suggests violent elimination of Muslims as a religious group. It targets Muslims specifically ('those Muslims'), indicating group-based hostility with implied support for violent actions. This meets the trigger pattern of derogatory generalizations about a protected group (religious) with violent suggestions. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis applies - dehumanizing language with violent suggestions targeting Muslims as a protected religious group. No exception for individual behavior targeting applies. Applying Rule 003: Same conclusion - dehumanizing terms with violent suggestions targeting a protected religious group in hostile context. The text reinforces harmful stereotypes about Muslims and suggests elimination through violence.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_55_k0", "example_id": "train_55", "text": "You look like Russian and speak like Indian. Both are disgusting go kill yourself", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about national groups ('Russian', 'Indian') with hostile intent ('disgusting', 'go kill yourself'). This targets protected groups (national origin) with dehumanizing language and violent suggestions. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The language promotes group-based hostility rather than targeting individual behavior. Applying Rule 002: The text uses derogatory generalizations about protected national groups with violent suggestions ('go kill yourself'), indicating hostile intent toward these groups. No exceptions apply as this is not criticism of individual behavior without group targeting. Applying Rule 003: The text contains dehumanizing language ('disgusting') and violent suggestions toward national groups, with clear group targeting and hostile context. No exceptions apply as this is not metaphorical criticism or individual targeting without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_56_k0", "example_id": "train_56", "text": "why haven't you faggots taken the bi-pill yet", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'faggots', which is a derogatory slur targeting the LGBTQ+ community (a protected group based on sexual orientation). This constitutes derogatory group-based language. The phrase 'why haven't you faggots taken the bi-pill yet' addresses the group collectively ('you faggots'), indicating group targeting rather than individual criticism. There is no indication this is reclaimed usage (like LGBTQ+ self-reference), clinical discussion, historical context, satire critiquing hate speech, or metaphorical criticism of non-group entities. The context appears hostile rather than neutral or academic. Applying Rule 002: The text uses dehumanizing/derogatory language ('faggots') targeting a protected group (LGBTQ+) with apparent hostile intent, as it makes a derogatory generalization. No exceptions apply since it's not about individual behavior without group reference. Applying Rule 003: Similar analysis - derogatory group-based language with group targeting and no applicable exceptions (not reclaimed, clinical, historical, satirical in anti-hate context, or metaphorical/non-group criticism). All three rules indicate this meets the trigger pattern for hate speech (label 1).", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_57_k0", "example_id": "train_57", "text": "In my opinion, God loves us all for who we are, no matter your sexuality, gender, races, religions or anything.  your actions and personalities count.", "label": 0, "reasoning": "Applying Rule 001: The text expresses inclusive, accepting views about multiple protected groups (sexuality, gender, races, religions) with positive intent ('God loves us all'). There is no dehumanizing language, derogatory generalizations, violent suggestions, or hostile context. The language promotes acceptance rather than targeting any group. Applying Rule 002: The text does not contain any dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It explicitly affirms the value of diverse identities. Applying Rule 003: The text lacks all trigger patterns including dehumanizing terms, derogatory generalizations, violent suggestions, or group targeting with hostile intent. It instead expresses universal acceptance across multiple protected characteristics. All three rules indicate this is not hate speech as it contains none of the prohibited elements and instead promotes inclusivity.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_58_k0", "example_id": "train_58", "text": "American Indians are finally almost extinguished", "label": 1, "reasoning": "Applying Rule 001: The text 'American Indians are finally almost extinguished' contains dehumanizing language ('extinguished' suggesting elimination) targeting a protected national/ethnic group (American Indians). This meets the trigger pattern: (1) metaphorical language implying elimination, (2) suggestion of elimination toward a group, and (3) reinforces harmful stereotypes about indigenous peoples. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The targeting is clearly group-based rather than individual. Applying Rule 002: Same analysis applies - dehumanizing language with group targeting and hostile intent (celebration of elimination). No exception for individual behavior targeting. Applying Rule 003: Same analysis applies - dehumanizing group-based language with elimination suggestion. No exceptions for reclaimed use or metaphorical criticism of non-group entities.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_59_k0", "example_id": "train_59", "text": "Im lesbian and proud im happy my friends accept me but i dont know if my family does but i dont care what anyone says im proud to be a lesbian", "label": 0, "reasoning": "Applying Rule 001: The text contains self-identification as lesbian (a sexual orientation group) but uses it in a positive, self-affirming context ('proud', 'happy', 'accept me'). There is no dehumanizing language, derogatory generalizations, violent suggestions, or hostile intent toward any group. The language is self-referential and promotes self-acceptance rather than targeting others. This falls under the exception for reclaimed/self-reference contexts that do not promote hate speech. Applying Rule 002: Similar analysis - the text mentions a protected group (sexual orientation) but in a positive, non-hostile manner without derogatory generalizations or violent suggestions. The focus is on personal identity and acceptance, not group-based hostility. Applying Rule 003: The text does not use dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The reference to being lesbian is self-descriptive and positive, lacking hostile context or reinforcement of harmful stereotypes. All three rules indicate this is not hate speech based on the contextual safeguards and exceptions for self-referential, non-hostile language about protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_61_k0", "example_id": "train_61", "text": "an Asian Moe Howard piece of shit", "label": 1, "reasoning": "Analyzing the text 'an Asian Moe Howard piece of shit' against the rulebook: 1. The text contains derogatory language ('piece of shit') directed at someone described as 'Asian Moe Howard'. 2. The term 'Asian' identifies a national/ethnic protected group. 3. The derogatory term is combined with group identification ('Asian'), suggesting group-based targeting. 4. Checking exceptions: The language is not reclaimed, clinical, historical, or satirical in context; it appears to be a direct insult. 5. The target is not clearly an individual without group reference - the group identifier 'Asian' is central to the description. 6. No evidence of metaphorical use targeting non-group entities. 7. The combination of derogatory language with protected group identification meets the trigger patterns in rules 001, 002, and 003 for dehumanizing/derogatory group-based language with hostile intent. Therefore, this qualifies as hate speech under the provided rules.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_62_k0", "example_id": "train_62", "text": "lock women up at home . Female are just to stupid to understand anything .  Iam Agnostic .", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory generalizations about women ('Female are just to stupid to understand anything'), which targets a protected gender group. It suggests inferiority ('too stupid to understand anything') and includes a hostile suggestion ('lock women up at home'), indicating group-based hostility. The self-identification as 'Agnostic' doesn't change the group-targeting nature. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about a protected group (women) with hostile intent, suggesting confinement and intellectual inferiority. No exceptions apply as this targets a protected group rather than individual behavior. Applying Rule 003: The text contains dehumanizing/derogatory language targeting a protected group (women) with suggestions of confinement and claims of intellectual inferiority, reinforcing harmful stereotypes in a hostile context. No exceptions apply as this is not metaphorical, reclaimed, or individual-focused criticism.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_63_k0", "example_id": "train_63", "text": "Ima fucking stab u up bruv. Fucking white prick bruv.. fucking racist.  Gammon", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('white prick', 'gammon') targeting a racial group (white people). The terms 'white prick' and 'gammon' are derogatory generalizations about a protected racial group. The context includes hostile intent with violent suggestions ('Ima fucking stab u up bruv'). This meets the trigger pattern of dehumanizing/derogatory group-based language with hostile intent. No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's direct hostile targeting of a racial group. Applying Rule 002: Same analysis applies - derogatory generalizations about a protected racial group with violent suggestions. No exception for individual behavior targeting since the language targets 'white' as a group. Applying Rule 003: Same analysis applies - derogatory group-based language with hostile intent. The violent threat combined with racial slurs constitutes hate speech under all three rules.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_64_k0", "example_id": "train_64", "text": "All muslims worship Satan¬ü¬ï¬ã 5 times a day", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('worship Satan') targeting Muslims as a protected religious group, suggesting they engage in demonic practices. This reinforces harmful stereotypes about Islam in a hostile context. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; it directly targets the group rather than individuals or non-group entities. Applying Rule 002: The text contains derogatory generalizations about a protected religious group (Muslims) with hostile intent, implying all members engage in Satan worship. No exceptions apply as it targets the group identity itself. Applying Rule 003: The text uses dehumanizing/derogatory language ('worship Satan') combined with group targeting (all Muslims), suggesting inferiority and reinforcing harmful stereotypes in a hostile context. No exceptions apply for reclaimed use or metaphorical criticism of non-group entities. All three rules indicate hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_65_k0", "example_id": "train_65", "text": "Incredibly fucking annoying voice, but reasonable arguments. I agree", "label": 0, "reasoning": "Applying Rule 001: The text contains strong language ('fucking annoying') but targets an individual's voice quality, not a protected group. There's no dehumanizing terms, derogatory generalizations about racial/gender/religious/national/sexual orientation groups, or violent suggestions. The criticism appears directed at an individual's voice characteristics without invoking group-based hostility. Applying Rule 002: Similar analysis - the language is offensive but targets individual attributes (voice quality) rather than protected groups. No suggestion of elimination, inferiority, or violence toward any group. Applying Rule 003: The text lacks dehumanizing terms like 'pigs' or 'retarded', doesn't target protected groups, and doesn't reinforce harmful stereotypes in a hostile context. The criticism of voice quality is individual-focused, not group-based. All three rules indicate this should be classified as non-hateful (0) because it targets individual behavior/characteristics without group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_66_k0", "example_id": "train_66", "text": "All theses people talking about Nigeria, since when have they cared about nigeria?  They find it now to care about Nigeria to be relevenat, those who were killed were farmers and Nigeria is living peacefully with it's Muslims.  Sure there are terrorist attacks every now and then, but we must remember that those who do kill the innocent are not Muslims.  Many terrorists or groups use religion as an excuse. How come Isis are killing their own people?  How come Iraqi forces are trying to drive isis Muslims out?  Why? Cause they are scum who are not Muslims.", "label": 0, "reasoning": "Applying Rule 001: The text discusses Nigeria, Muslims, and ISIS, but does not use dehumanizing terms like 'pigs' or 'retarded', nor does it make derogatory generalizations about protected groups. It distinguishes between 'Muslims' and terrorists who 'use religion as an excuse', explicitly stating 'those who do kill the innocent are not Muslims'. The term 'scum' targets ISIS specifically as a terrorist group, not Muslims as a protected religious group. No suggestion of elimination, inferiority, or violence toward a group is present. Applying Rule 002: Similar analysis applies; no dehumanizing language or group-based hostility toward protected groups. The criticism targets ISIS as a terrorist organization, not a protected identity. Applying Rule 003: The text uses 'scum' metaphorically for ISIS, a non-group-based entity (terrorist organization), not a protected group. No indicators of hate speech triggers are met. All rules indicate classification as 0 due to lack of dehumanizing/derogatory language targeting protected groups with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_68_k0", "example_id": "train_68", "text": "this doesn’t  represent mental illness correctly at all, it doesn't just randomly appear its always present", "label": 0, "reasoning": "Applying Rule 001: The text criticizes a representation of mental illness without using dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses the nature of mental illness (specifically that it 'doesn't just randomly appear its always present') in what appears to be an educational or corrective context. No group targeting, hostile intent, or harmful stereotypes are present. The exception for clinical/educational discussion applies. Applying Rule 002: Similar analysis - no dehumanizing language, no group targeting, no hostile intent toward protected groups. The comment addresses representation of a condition rather than attacking people with mental illness. Applying Rule 003: Same conclusion - the text discusses mental illness representation without derogatory language, group targeting, or hostile context. The clinical/educational context exception applies. All three rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_69_k0", "example_id": "train_69", "text": "guy is low IQ af", "label": 0, "reasoning": "Applying Rule 001: The text 'guy is low IQ af' contains the term 'low IQ', which could be considered derogatory language related to intelligence. However, this targets an individual ('guy') without reference to any protected group (racial, gender, religious, national, sexual orientation). The language is directed at a specific person's perceived intelligence, not making generalizations about people with intellectual disabilities as a group. There is no suggestion of elimination, inferiority toward a group, or reinforcement of harmful stereotypes in a hostile context. The exception for 'individual without reference to group identity' applies. Applying Rule 002: Similar analysis - the comment targets individual characteristics without group-based hostility or protected group targeting. Applying Rule 003: The language criticizes an individual's intelligence metaphorically without dehumanizing a protected group or suggesting violence/elimination toward a group. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_70_k0", "example_id": "train_70", "text": "not true in saudia arabia women have freedom", "label": 0, "reasoning": "Applying Rule 001: The text 'not true in saudia arabia women have freedom' makes a factual claim about women's freedom in Saudi Arabia. It does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about women as a protected group, or violent suggestions. There is no suggestion of elimination, inferiority, or violence toward women as a group. The statement appears to be a counter-argument or factual assertion rather than hostile speech. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context, and the target is not an individual without group reference. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions with group targeting. The comment addresses a social condition rather than targeting women as a group with hostile intent. Applying Rule 003: Again, no trigger patterns present. The text lacks non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context. The statement is about societal conditions rather than group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_71_k0", "example_id": "train_71", "text": "whats the big deal mexico has immigration laws and policies they deport people all the time nothing is said or done yet when the united states chooses to enforce its immigration laws and policies people become shocked and outraged", "label": 0, "reasoning": "Applying Rule 001: The text discusses immigration policies of Mexico and the United States without using dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to racial, gender, religious, national, or sexual orientation groups. The criticism appears directed at perceived double standards in public reactions to immigration enforcement, not at immigrants as a protected group. No indicators of non-literal slurs, elimination rhetoric, or harmful stereotypes are present. The language targets policy enforcement and public reactions, not group identity. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions targeting groups. The text focuses on comparative policy enforcement rather than attacking immigrants as a group. Applying Rule 003: Same conclusion - no triggering patterns of dehumanizing terms, group-based derogatory language, or violent suggestions toward protected groups. The context is political commentary about immigration policy differences, not hate speech targeting protected identities. All rules indicate this does not meet criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_72_k0", "example_id": "train_72", "text": "Too bad women don’t know how to kill themselves", "label": 1, "reasoning": "Applying Rule 001: The text uses violent suggestion ('kill themselves') targeting a protected group (women) with hostile intent, suggesting elimination of the group. It contains derogatory generalization about women's capabilities. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It directly targets women as a gender group with violent suggestion. Applying Rule 002: The text uses violent suggestion targeting a protected group (women) with hostile intent, suggesting elimination. No exceptions apply - it's not targeting individual behavior or reclaimed usage. Applying Rule 003: The text uses violent suggestion ('kill themselves') targeting a protected group (women) with hostile intent, suggesting elimination. No exceptions apply - it's not metaphorical criticism of non-group entities or individual targeting. All three rules indicate hate speech due to violent suggestion targeting a protected group with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_73_k0", "example_id": "train_73", "text": "Gay. Straight. Homo. Lesbian. How about 'People\". Hmmm. Love you ALL!", "label": 0, "reasoning": "Applying Rule 001: The text lists identity terms ('Gay', 'Straight', 'Homo', 'Lesbian') but does not use them in a dehumanizing or derogatory manner. It concludes with 'How about \"People\". Hmmm. Love you ALL!' which explicitly promotes inclusion and love for all people regardless of identity. This lacks hostile intent, group targeting, violent suggestions, or reinforcement of harmful stereotypes. The context is clearly positive and unifying rather than hateful. Applying Rule 002: No dehumanizing terms or derogatory generalizations about protected groups are present. The language is neutral listing of terms followed by a positive, inclusive message. No suggestion of elimination, inferiority, or violence toward any group. Applying Rule 003: Same analysis as Rule 001 - the text lacks the trigger patterns of dehumanizing language with hostile intent and group targeting. The concluding phrase 'Love you ALL!' establishes a context of acceptance rather than hostility. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_74_k0", "example_id": "train_74", "text": "Don't say I'm not your type", "label": 0, "reasoning": "Applying Rule 001: The text 'Don't say I'm not your type' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any racial, gender, religious, national, or sexual orientation group. The language is personal and individual-focused ('I'm', 'your type'), referring to personal preferences in relationships without any group-based hostility. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The comment addresses individual romantic compatibility without broader group implications. Applying Rule 003: Same conclusion - the text lacks all trigger patterns including non-literal slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes. The context is personal and non-hostile.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_75_k0", "example_id": "train_75", "text": "Islam and Christianity have mixed for centuries so the idea that we cannot coexist is an ignorant idea.", "label": 0, "reasoning": "Applying Rule 001: The text discusses coexistence between Islam and Christianity, using neutral language ('mixed for centuries', 'ignorant idea') without dehumanizing terms, derogatory generalizations, or violent suggestions. It targets no protected group with hostility, instead promoting coexistence. No exceptions apply as there's no group-based targeting. Applying Rule 002: Similar analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The comment addresses ideas ('ignorant idea') rather than attacking religious groups. Applying Rule 003: Again, no trigger patterns present - no slurs, elimination suggestions, or harmful stereotypes in hostile context. The text is analytical about religious coexistence. All rules indicate this is non-hateful discourse about interfaith relations.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_76_k0", "example_id": "train_76", "text": "Fuck this faggot. He's the disrespecting idiot brother in law that loves to start fights at family functions.You can't have conversations with assholes like him.", "label": 1, "reasoning": "Analyzing the text 'Fuck this faggot. He's the disrespecting idiot brother in law that loves to start fights at family functions. You can't have conversations with assholes like him.' using the rulebook: Rule 1, 2, and 3 all define hate speech as involving dehumanizing/derogatory group-based language with hostile intent targeting protected groups. The term 'faggot' is a derogatory slur targeting the LGBTQ+ community (a protected group based on sexual orientation). The text uses this term in a hostile context directed at an individual ('this faggot'), but it invokes group identity through the slur. Checking exceptions: This is not reclaimed/self-referential use (not by an LGBTQ+ person referring to themselves), not clinical/historical discussion, not satirical critique of hate speech, and not metaphorical criticism of non-group entities. While the text targets a specific individual (brother-in-law), it uses a group-based slur that reinforces harmful stereotypes about LGBTQ+ people as inferior or deserving of hostility. The additional insults ('idiot', 'assholes') are offensive but not group-based. Since the core violation involves using a protected-group slur with hostile intent, all three rules would trigger. The exceptions for individual targeting without group reference don't apply because the slur inherently references group identity.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_77_k0", "example_id": "train_77", "text": "during war discrimination is a military necessitywhen korematsus case reached the supreme court in october 1944 the attorneys for the government pointed to the constitutional war powers of congress and the president the government argued that the military must take all steps necessary to wage war successfully in the view of president roosevelt the war department and general dewitt the internment of all japanese issei and nisei was a military necessityand assuming we were at war with isis then rounding up isis would not be raciston december 18 1944 the supreme court decided 63 to uphold the conviction of korematsu the majority ruled only on his refusal to leave a prohibited military area and did not consider the constitutionality of the relocation camps justice hugo black writing for the majority fully accepted the views of general dewitt justice black also said that korematsu had not been forced from his home because of his race but because of the military urgency of the situation", "label": 0, "reasoning": "Analyzing the text against all relevant rules: The text discusses historical events (Japanese internment during WWII) and makes a hypothetical comparison to ISIS. It uses academic/historical language without dehumanizing terms, derogatory generalizations, or violent suggestions targeting protected groups. Rule 001, 002, and 003 all require dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text does not contain terms like 'pigs' or 'retarded', nor does it suggest elimination, inferiority, or violence toward any racial, gender, religious, national, or sexual orientation group. It references 'Japanese Issei and Nisei' and 'ISIS' in historical/contextual discussion, not with hostile intent. The exceptions apply: this is historical context that critiques rather than promotes hate speech. No rule triggers because there is no group-based hostile language, no protected group targeting with derogatory terms, and the context is analytical rather than promoting discrimination.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_78_k0", "example_id": "train_78", "text": "People are genuinely good, we just learned to hate. when Europe was all white and christian they killed each other, the same happened to the Muslim world", "label": 0, "reasoning": "Applying Rule 001: The text discusses historical conflicts in Europe and the Muslim world, using factual statements about past violence ('they killed each other'). There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The text makes no suggestion of elimination, inferiority, or violence toward any group, nor does it reinforce harmful stereotypes. The mention of 'white and christian' and 'Muslim world' appears in a historical context without hostile intent or group-based targeting. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The text lacks indicators like non-literal slurs or suggestions of group elimination. Applying Rule 003: Again, no trigger patterns present. The language is descriptive rather than metaphorical slurs, and there is no targeting of individuals or groups with hostile intent. The text presents a philosophical observation about human nature and historical conflict patterns without promoting hate toward any protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_79_k0", "example_id": "train_79", "text": "What if we send every men to mars to start a new life there! They are useless here (Of course milk them first to store their juices)", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('milk them' referring to men) and derogatory generalization about a protected group (men as a gender group). It suggests elimination ('send every men to mars') and inferiority ('they are useless here'). However, the rule has exceptions for non-literal/metaphorical use targeting non-group entities or individual behavior. Here, the target is 'every men' - a clear group targeting based on gender. The language is dehumanizing and hostile, suggesting exploitation ('milk them') and removal. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or targeting individuals without group reference. Applying Rule 002: Same analysis - dehumanizing terms, group targeting (men), hostile intent with suggestion of elimination and exploitation. No exception for individual behavior targeting applies. Applying Rule 003: Same analysis - dehumanizing language, group targeting, hostile context with elimination suggestion. No metaphorical exception applies as it directly targets men as a group. All three rules indicate hate speech due to dehumanizing group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_80_k0", "example_id": "train_80", "text": "the guy (guessing) in the wheelchair was so sweet awh!!", "label": 0, "reasoning": "Applying Rule 001: The text 'the guy (guessing) in the wheelchair was so sweet awh!!' contains a reference to a wheelchair user but does not use dehumanizing terms, derogatory generalizations, or violent suggestions. The language is positive ('so sweet') and affectionate ('awh!!'), with no hostile intent. The reference to disability ('in the wheelchair') appears descriptive rather than derogatory, and there's no group-based targeting or reinforcement of harmful stereotypes. This falls under the exception for non-hostile contexts. Applying Rule 002: No dehumanizing language or group-based hostility is present. The comment focuses on an individual's positive trait without targeting protected groups. Applying Rule 003: Similar analysis - no trigger patterns are met as the language lacks derogatory elements and shows no hostile intent toward disability groups. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_81_k0", "example_id": "train_81", "text": "transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('sick in the head') targeting transgenders as a protected group based on gender identity, suggesting they are mentally ill. This reinforces harmful stereotypes about transgender people in a hostile context. No exceptions apply - it's not reclaimed, clinical, historical, or satirical; it directly targets the group rather than individuals; and it promotes group-based inferiority. Applying Rule 002: The text contains derogatory generalizations about transgender people as a group, suggesting they need help due to being 'sick in the head,' which implies inferiority and reinforces harmful stereotypes in a hostile manner. No exceptions apply as it's not criticizing individual behavior but targeting the entire group. Applying Rule 003: The text uses derogatory language ('sick in the head') targeting transgender people as a protected group, suggesting mental illness and inferiority. The comparison to people claiming to change to animals further reinforces harmful stereotypes in a hostile context. No exceptions apply as it's not metaphorical criticism of non-group entities nor individual targeting. All three rules indicate hate speech due to derogatory group-based language with hostile intent targeting a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_83_k0", "example_id": "train_83", "text": "They must be really suffering if they're throwing food all over the ground for the pigeons.", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'they' without specifying any protected group identity. The phrase 'throwing food all over the ground for the pigeons' describes behavior but contains no dehumanizing terms, derogatory generalizations, violent suggestions, or group targeting. No indicators of non-literal slurs, elimination rhetoric, inferiority claims, or harmful stereotypes are present. The context appears observational about behavior, not hostile toward any protected group. Applying Rule 002: No dehumanizing language or derogatory generalizations about protected groups are used. The text lacks group targeting, slurs, or suggestions of violence/elimination. The criticism appears directed at individual behavior (throwing food) without targeting a protected group identity. Applying Rule 003: Similar analysis - no dehumanizing terms, group-based derogatory language, or violent suggestions. The language is literal description of behavior, not metaphorical slurs targeting protected groups. All three rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_85_k0", "example_id": "train_85", "text": "Omg that is awesome so much hate but stay positive", "label": 0, "reasoning": "Applying Rule 001: The text contains the word 'hate' but it's used in a positive context ('awesome so much hate but stay positive'), suggesting it might be ironic or celebratory rather than promoting actual hate speech. There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions. The term 'hate' appears to be used colloquially without targeting any specific group or individual. No exceptions apply as there's no group targeting or hostile intent. Applying Rule 002: Similar analysis - the text mentions 'hate' but lacks the key indicators of dehumanizing terms, group targeting, or suggestions of elimination/violence toward protected groups. The context appears non-hostile. Applying Rule 003: Again, while 'hate' is mentioned, it's not used in combination with group targeting, lacks dehumanizing language, and the overall tone ('awesome', 'stay positive') suggests a non-hostile context. All three rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_86_k0", "example_id": "train_86", "text": "All I know is that my disorder ruined my fucking life.", "label": 0, "reasoning": "Analyzing the text 'All I know is that my disorder ruined my fucking life.' against the provided rules: 1. The text contains strong language ('fucking') but this is directed at the speaker's own disorder, not at a protected group. 2. The text discusses a personal disorder affecting the speaker's life, with no dehumanizing terms, derogatory generalizations, or violent suggestions targeting any racial, gender, religious, national, or sexual orientation group. 3. There is no suggestion of elimination, inferiority, or violence toward a group. 4. There is no reinforcement of harmful stereotypes in a hostile context. 5. The language is self-referential about personal experience, not group-based. According to Rule 001, 002, and 003, this does not meet the trigger patterns for hate speech as it lacks group targeting, dehumanizing language toward protected groups, and hostile intent against a group. The exceptions in all rules support classification as non-hateful since it targets individual experience without invoking group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_87_k0", "example_id": "train_87", "text": "That hair cut makes you irresistible", "label": 0, "reasoning": "Applying Rule 001: The text 'That hair cut makes you irresistible' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It targets an individual's appearance (haircut) with a positive compliment ('irresistible'), showing no hostile intent, group targeting, or reinforcement of harmful stereotypes. The exceptions do not apply as there is no offensive language to evaluate. Applying Rule 002: Similarly, no dehumanizing language, group-based targeting, or hostile intent is present; the comment is directed at an individual's haircut without any reference to protected groups. Applying Rule 003: The text lacks all key indicators (slurs, elimination/inferiority/violence suggestions, stereotypes) and is non-hostile and individual-focused. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_88_k0", "example_id": "train_88", "text": "All of these clueless reporters comparing themselves to Cronkite and Edward R. Murrow and they can't even get through a teleprompter read-through without hitting the floor.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes reporters by calling them 'clueless' and mocking their inability to read teleprompters without falling. This targets individuals (reporters) based on their professional performance, not a protected group. No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions are present. The criticism is directed at individual competence in a professional role, not at a protected identity group. No exceptions apply as this is clearly non-group-based criticism of professional behavior. Applying Rule 002: Similar analysis - the text targets individual reporters' professional abilities, not a protected group. No dehumanizing language or group-based hostility. Applying Rule 003: Same conclusion - metaphorical criticism of professional performance without protected group targeting. All rules indicate this is not hate speech as it lacks group-based targeting, dehumanizing language, or hostile intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_89_k0", "example_id": "train_89", "text": "From the midnight sun where the hot springs blow", "label": 0, "reasoning": "Applying Rule 001: The text 'From the midnight sun where the hot springs blow' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to any group identity, protected or otherwise, and contains no hostile intent. The language is poetic/descriptive rather than metaphorical in a derogatory sense. No exceptions apply as there is no group targeting or offensive language present. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions toward any group. It lacks all key indicators (non-literal slurs, suggestions of elimination/inferiority/violence, reinforcement of harmful stereotypes). Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to group targeting and has no hostile context. The language is descriptive rather than metaphorical criticism of entities. All three rules indicate this is not hate speech as it lacks the essential elements of group-based derogatory language with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_90_k0", "example_id": "train_90", "text": "anyone else get full body numbness that lasts for weeks and rapid muscle spasms and 'shock' feelings when trying to sleep at night? I can only sleep once every 48 hours :(", "label": 0, "reasoning": "Applying Rule 001: The text describes personal health symptoms ('full body numbness', 'muscle spasms', 'shock feelings', sleep difficulties) without any dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. No group targeting is present - the speaker is discussing their own experience. This falls under the exception for non-group-based language. Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions targeting protected groups. The text discusses individual health symptoms without group-based hostility. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The language is descriptive of personal health issues without metaphorical slurs or group targeting. All three rules indicate this is not hate speech as it lacks the required elements of group-based dehumanization, derogatory language, or hostile intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_91_k0", "example_id": "train_91", "text": "Conveniences are all the real", "label": 0, "reasoning": "The text 'Conveniences are all the real' does not contain any dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions as specified in rules 001, 002, and 003. There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The phrase appears abstract or nonsensical and lacks any contextual indicators of hate speech. Therefore, no relevant rules apply, and it should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_92_k0", "example_id": "train_92", "text": "Racist ass black bitch slapping a white man. Bus driver has that uppercut for that ass.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('Racist ass black bitch') targeting a racial group (Black people) with hostile intent, using a slur ('bitch') and racial descriptor in a derogatory manner. It suggests violence ('slapping', 'uppercut') in a context that reinforces negative stereotypes about Black individuals being violent. This meets the trigger pattern of derogatory generalizations about a protected group with hostile intent. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis confirms dehumanizing language targeting a protected racial group with hostile intent. Applying Rule 003: Confirms the same pattern with no applicable exceptions. All rules indicate hate speech due to group-based derogatory language with hostile context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_93_k1", "example_id": "train_93", "text": "i like dead refugees on my shore√Ø¬ª¬ø", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('dead refugees') and targets a protected group (refugees as a national/immigrant group). The phrase 'i like dead refugees on my shore' suggests elimination or violence toward this group in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It directly targets refugees as a group with violent implications. Applying Rule 002: The text uses dehumanizing language ('dead refugees') with hostile intent toward a protected group (refugees). The suggestion of dead refugees implies elimination/violence. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains dehumanizing language targeting a protected group with hostile intent. The phrase suggests elimination/violence toward refugees. No exceptions apply for reclaimed use, clinical context, satire, or metaphorical criticism of non-group entities. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_95_k0", "example_id": "train_95", "text": "So when i scroll down to read/leave a comment and scroll back up they blue like thumbs up goes away, it has done this 4 times in a row now. Hmm is it just a glitch or does YouTube remove it when they think you will just leave the video without checking? This happens a lot but only on channels like this.", "label": 0, "reasoning": "Applying Rule 001: The text discusses YouTube interface behavior and potential glitches, with no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. No group targeting is present. The mention of 'channels like this' refers to YouTube channels generally, not a protected group. Applying Rule 002: No dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text focuses on technical issues with YouTube's platform. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. The language is descriptive about user experience with a platform, not hostile toward any identity-based group. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_98_k0", "example_id": "train_98", "text": "The Veil of Isis is also a great song by The Sword.", "label": 0, "reasoning": "Applying Rule 001: The text 'The Veil of Isis is also a great song by The Sword' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to racial, gender, religious, national, or sexual orientation groups. The language is purely about music appreciation with no hostile intent, group targeting, or harmful stereotypes. All exceptions are irrelevant as there is no offensive language present. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions targeting any protected group. There is no suggestion of elimination, inferiority, or violence toward any group. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions in combination with group targeting. The language is neutral and factual about a song, with no metaphorical slurs or hostile context. All three rules indicate this is not hate speech as it lacks all trigger patterns described in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_99_k0", "example_id": "train_99", "text": "Islam! Lets beat their feminist ass.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('beat their feminist ass') targeting a religious group ('Islam') with hostile intent. It contains violent suggestions ('beat') directed at a protected religious group, combined with gender-based targeting ('feminist'). This meets the trigger pattern of dehumanizing/derogatory group-based language with hostile intent. No exceptions apply - it's not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets a protected group rather than individual behavior. Applying Rule 002: Same analysis applies - derogatory language targeting a protected religious group with violent suggestions. No exception for individual behavior targeting applies. Applying Rule 003: Same analysis applies - violent suggestion ('beat') combined with group targeting of a protected religious group. The text reinforces harmful stereotypes about Muslims and feminists in a hostile context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_100_k2", "example_id": "train_100", "text": "Well im glad that i live in Serbia, migrants and islamists are not welcome here!", "label": 1, "reasoning": "Analyzing the text 'Well im glad that i live in Serbia, migrants and islamists are not welcome here!' against the rulebook: Rule 001, 002, and 003 all define hate speech as involving dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text targets 'migrants and islamists' as groups, expressing exclusion ('not welcome here') with a negative generalization. 'Migrants' could refer to a national/ethnic group, and 'islamists' to a religious/political group, both potentially protected categories. The statement reinforces harmful stereotypes about these groups being unwelcome, with hostile intent implied by the exclusionary sentiment. No exceptions apply: it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities, nor is it targeting individual behavior without group reference. Therefore, all relevant rules indicate this meets the criteria for hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_101_k0", "example_id": "train_101", "text": "Who gives a damn we have the ability an the freedom to b whoever the fuck we want to b", "label": 0, "reasoning": "Applying Rule 001: The text contains strong language ('damn', 'fuck') but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting - the text is about individual freedom and self-expression. The language appears colloquial and self-affirming rather than hostile. No exceptions apply as there is no group-based hostility. Applying Rule 002: No dehumanizing terms or derogatory generalizations about protected groups are present. The text focuses on individual freedom without targeting any group. No exceptions apply. Applying Rule 003: Similar analysis - no dehumanizing terms, no group targeting, no violent suggestions. The text expresses a positive sentiment about personal freedom using strong but non-targeted language. All rules indicate this is not hate speech as it lacks the required elements of group-based dehumanization, derogatory generalizations, or hostile intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_102_k0", "example_id": "train_102", "text": "who gives aa fuck about shit diamonds from the jews fuck them both", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('fuck them both') targeting 'the jews' as a religious/ethnic group, which constitutes a protected group. The language is hostile and dehumanizing ('who gives aa fuck about shit diamonds'), suggesting contempt and dismissal. This is not reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities or targeting individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected group (Jewish people) with hostile intent ('fuck them both'), indicating group-based hostility. Applying Rule 003: The text contains dehumanizing/derogatory language targeting a protected group with hostile context, meeting all key indicators. No exceptions apply as this is direct group-based hostility without mitigating context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_103_k0", "example_id": "train_103", "text": "Men race is a subordinate of women", "label": 1, "reasoning": "Applying Rule 001: The text 'Men race is a subordinate of women' contains group-based language targeting 'men' as a gender group. It makes a derogatory generalization by claiming men are 'subordinate' to women, which suggests inferiority of one gender group relative to another. This meets the trigger pattern of 'derogatory generalizations about a protected group (gender)' with indicators of suggesting inferiority toward a group. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; it's not metaphorical criticism of non-group entities; it directly targets men as a gender group with a hostile generalization about their status. Applying Rule 002: The text uses derogatory group-based language ('subordinate') targeting a protected gender group (men) with hostile intent by asserting inferiority. No exceptions apply as it's not about individual behavior. Applying Rule 003: Similar analysis confirms dehumanizing/derogatory group-based language with hostile intent targeting a gender group. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_104_k0", "example_id": "train_104", "text": "Then the same people choosing the same answer", "label": 0, "reasoning": "Applying Rule 001: The text 'Then the same people choosing the same answer' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The language appears neutral and descriptive. Applying Rule 002: No dehumanizing terms or derogatory generalizations are present. No protected groups are targeted, and there is no hostile intent toward any group. Applying Rule 003: Similar analysis - no triggering patterns are present in the text. The text lacks any of the key indicators specified in all three rules (non-literal slurs, elimination suggestions, group-based hostility). Therefore, none of the rules apply, and the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_105_k0", "example_id": "train_105", "text": "Aaah its the mother's fault you guys dont know how hard to take care of autistic kids huh?", "label": 0, "reasoning": "Analyzing the text 'Aaah its the mother's fault you guys dont know how hard to take care of autistic kids huh?' against the rulebook: 1. The text targets 'mothers' of autistic children, which could be interpreted as a gender-based group (mothers) or a group defined by relationship to autistic individuals. However, the criticism appears directed at individual behavior (blaming mothers) rather than making derogatory generalizations about a protected group. 2. No dehumanizing terms like 'pigs' or 'retarded' are present. 3. No violent suggestions or elimination rhetoric. 4. The text questions understanding of care difficulties rather than promoting inferiority or violence. 5. Under Rule 001 exception: 'Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions... without linking them to a broader protected group.' While this text criticizes mothers (not faking), it similarly targets individual behavior without group-based hostility. 6. Under Rule 002 exception: 'Do not apply if the criticism is directed at individual behavior... without targeting a protected group.' Mothers could be considered a gender-based group, but the text lacks derogatory generalizations or hostile intent toward mothers as a protected class. 7. The tone is accusatory but not hateful by rule definitions. Therefore, no rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_106_k0", "example_id": "train_106", "text": "deport these cunt asians", "label": 1, "reasoning": "Applying Rule 001: The text 'deport these cunt asians' contains derogatory language ('cunt') targeting a protected group ('asians') based on national/ethnic identity. It suggests elimination through deportation with hostile intent, meeting the trigger pattern of dehumanizing/derogatory group-based language. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It directly targets 'asians' as a group with derogatory language and calls for their removal. Applying Rule 002: Same analysis applies - derogatory term combined with group targeting and suggestion of elimination. No exception for individual behavior targeting. Applying Rule 003: Same analysis applies - derogatory language targeting protected group with hostile intent. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_107_k0", "example_id": "train_107", "text": "I love bi girls and lesbians", "label": 0, "reasoning": "Analyzing the text 'I love bi girls and lesbians' against all relevant rules: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text expresses positive sentiment ('love') toward bisexual women and lesbians, which are protected groups based on sexual orientation. There are no dehumanizing terms (e.g., no slurs like 'dyke' or 'fag'), no derogatory generalizations (it's affirming rather than stereotyping), no violent suggestions, and no hostile context. The expression is supportive rather than hateful. None of the exceptions apply because there's no offensive language to evaluate for reclamation or satire. Therefore, no rule triggers for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_108_k0", "example_id": "train_108", "text": "This is so sinful. It says it in the bible you dumb fucktards. Stop saying YOU WILL GO TO HEAVEN IF YOU ARE GAY. because you will not go to heaven. Trust me its a fucking choice my GF dated girls and I was her 2nd bf she dated like 12 girls and she is 100% straight. You can change to the right side :)", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('dumb fucktards') and targets a protected group (LGBTQ+ individuals based on sexual orientation). It makes generalizations about gay people ('you will not go to heaven') and suggests they should change ('You can change to the right side'), implying inferiority and promoting harmful stereotypes in a hostile context. The language is not reclaimed, clinical, historical, or satirical - it's directly attacking the group. No exceptions apply as this is group-based targeting with hostile intent. Applying Rule 002: Same analysis - dehumanizing language combined with group targeting against a protected group (sexual orientation), suggesting elimination from heaven and promoting change, which implies inferiority. No exceptions apply as this isn't about individual behavior but generalized group hostility. Applying Rule 003: Same analysis - derogatory generalizations about gay people with hostile intent, not metaphorical or individual targeting. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_109_k0", "example_id": "train_109", "text": "why is it censored, why does todays generation get butt hurf and offended so easily, if u dont like it, keep walking then! this use to be a free country but its going down the toilet now.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes 'today's generation' for being easily offended and suggests censorship is excessive. It uses colloquial language ('butt hurt') and expresses frustration about perceived loss of freedom. This targets a generational group, but not a protected group based on race, gender, religion, national origin, or sexual orientation. The language is not dehumanizing, derogatory, or violent toward a protected group. No suggestion of elimination, inferiority, or violence. The criticism is about perceived sensitivity and social changes, not group-based hostility with harmful stereotypes. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The target is a generational cohort, not a protected identity group. Applying Rule 003: Same conclusion - the text lacks dehumanizing language, group targeting of protected categories, and hostile intent toward protected groups. The metaphorical language ('going down the toilet') criticizes societal trends, not specific protected groups. All rules indicate this does not meet hate speech criteria.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_110_k0", "example_id": "train_110", "text": "Disgusting sick queer kill yourself", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('disgusting sick queer') targeting a protected group (sexual orientation - queer) and includes a violent suggestion ('kill yourself'). This meets the trigger pattern of using derogatory generalizations about a protected group combined with violent suggestions. The language suggests elimination and inferiority toward LGBTQ+ individuals, reinforcing harmful stereotypes in a hostile context. No exceptions apply: this is not reclaimed usage (not self-referential), not clinical/historical context, not satirical critique, and clearly targets a group identity rather than individual behavior. Applying Rule 002: Same analysis applies - dehumanizing/derogatory language targeting protected group with violent suggestion. No exception for individual behavior targeting applies since 'queer' refers to group identity. Applying Rule 003: Same analysis applies - derogatory group-based language with violent suggestion, no applicable exceptions. All three rules indicate hate speech classification.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_111_k0", "example_id": "train_111", "text": "congratu-fuckin-lations to all the pitbull owners who make it by without getting bitten. DO NOT ENCOURAGE PEOPLE TO FOLLOW IN YOUR FOOTSTEPS. i know people whose lives have been RUINED by these animals. regardless of your ''PACK MENTALITY'' these dogs are rage machines and your dodgeing a bullet every day they dont hurt your family.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes pitbull owners and pitbulls as a category, using strong negative language ('rage machines', 'dodgeing a bullet'). However, pitbull owners are not a protected group based on race, gender, religion, national origin, or sexual orientation. The text targets behavior (owning pitbulls) rather than an identity-based group. The language, while harsh, doesn't use dehumanizing terms like 'pigs' or 'retarded' toward protected groups, nor does it suggest elimination, inferiority, or violence toward a protected group. It focuses on perceived risks of pitbull ownership. Applying Rule 002: Similar analysis - the text lacks dehumanizing language targeting protected groups and doesn't promote generalized hostility toward identity-based communities. It criticizes a choice (owning pitbulls) rather than a protected characteristic. Applying Rule 003: The text doesn't use the specific dehumanizing terms mentioned in the trigger patterns, nor does it target protected groups. The criticism is directed at pitbull owners as a category based on their choices, not at an immutable characteristic. None of the rules apply as the text doesn't meet the criteria for hate speech against protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_112_k0", "example_id": "train_112", "text": "I’m sure this woman widows to have aborted this monster of a child. It hits her while she is helping him on living his life", "label": 0, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('monster of a child') and violent suggestions ('widows to have aborted'), but the target appears to be an individual child rather than a protected group. The language criticizes a specific individual's behavior or existence without invoking group-based hostility toward a protected category (e.g., children as a group, people with disabilities, or national/racial groups). The exceptions in Rule 001 specify not to apply if the target is an individual without reference to group identity, which fits this case. Applying Rule 002: Similar analysis applies - the derogatory language targets an individual child, not a protected group with hostile intent toward that group. The exception for criticism directed at individual behavior without targeting a protected group applies. Applying Rule 003: Again, the dehumanizing term 'monster' and violent suggestion about abortion target a specific individual child, not a protected group. The exception for individual targeting without group reference applies. While the language is offensive and contains violent imagery, it lacks the group-based targeting, derogatory generalizations about protected groups, or reinforcement of harmful stereotypes that would trigger hate speech classification under these rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_113_k0", "example_id": "train_113", "text": "Now where are the feminists accusing of woman as demons abusing women all the time??", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'feminists' as a group and uses the term 'demons' which could be considered dehumanizing. However, the context appears to criticize feminists for 'accusing of woman as demons' and 'abusing women all the time', suggesting the speaker views feminists as hypocritical or harmful to women rather than targeting a protected group with hostile intent. The criticism seems directed at perceived behavior of feminists rather than promoting elimination, inferiority, or violence toward them as a protected group. The term 'demons' appears metaphorical in criticizing perceived hypocrisy. Applying Rule 002: Similar analysis - while derogatory language is used, it targets feminists for their perceived actions rather than promoting group-based hostility toward them as a protected group. Applying Rule 003: The text does not clearly target a protected group (feminists are not explicitly listed as a protected group in the rules) with suggestions of elimination, inferiority, or violence. The language, while potentially offensive, appears to criticize behavior rather than promote systemic hostility. Based on all rules, this does not meet the threshold for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_114_k0", "example_id": "train_114", "text": "I’d like to see a because I’m black compilation video", "label": 0, "reasoning": "Applying Rule 001: The text 'I'd like to see a because I'm black compilation video' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It mentions 'black' as a racial identity but does so in a self-referential context ('because I'm black') that appears to be about personal experience or identity expression rather than targeting others. There is no hostile intent, suggestion of elimination, inferiority, or violence toward any group. The language lacks non-literal slurs, harmful stereotypes, or group-based hostility. This falls under exceptions for reclaimed or self-referential contexts. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions with group targeting. The mention of 'black' is self-referential without promoting hostility toward protected groups. Applying Rule 003: Same conclusion - no trigger patterns present, and the self-referential use of racial identity does not constitute hate speech under the defined exceptions. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_115_k2", "example_id": "train_115", "text": "Just look at that crowd!!! ALL FAT WHITE TRASH OR METH ADDICTS", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory terms 'FAT WHITE TRASH' and 'METH ADDICTS' targeting groups based on body size, race, and substance use. This constitutes derogatory generalizations about protected groups (racial and potentially disability/health status groups) with hostile intent through dehumanizing language ('trash'). The ALL caps and exclamation marks indicate hostile context. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The targeting is explicitly group-based ('crowd', 'ALL') rather than individual. Applying Rule 002: Same analysis applies - dehumanizing group-based language with hostile intent. Applying Rule 003: Same analysis applies - dehumanizing group-based language with hostile intent and no applicable contextual safeguards.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_116_k0", "example_id": "train_116", "text": "all those dislikes are from fucking homophopes", "label": 0, "reasoning": "Applying Rule 001: The text uses offensive language ('fucking homophopes') that targets a group (people who are homophobic). However, homophobes are not a protected group based on identity characteristics like race, gender, religion, national origin, or sexual orientation - they are defined by their attitudes/behaviors. The comment criticizes individuals for their behavior (disliking something, presumably due to homophobia) without making derogatory generalizations about protected identity groups. The language, while hostile, targets perceived individual behavior rather than a protected group identity. Applying Rule 002: Similar analysis - the comment targets individual behavior (being homophobic) rather than a protected group. The term 'homophopes' appears to be a misspelling of 'homophobes' and targets people based on their attitudes, not their inherent identity characteristics. Applying Rule 003: The text uses offensive language but targets individuals based on their behavior/attitudes, not a protected group identity. The context suggests criticism of those who dislike something due to homophobia, which is targeting behavior rather than group identity. None of the rules apply because the target is not a protected group as defined in the rule bodies (racial, gender, religious, national, or sexual orientation groups).", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_117_k3", "example_id": "train_117", "text": "japan only rejected 99 they should reject all those mother fuckers", "label": 0, "reasoning": "Analyzing the text 'japan only rejected 99 they should reject all those mother fuckers' against the rulebook: 1. The text uses derogatory language ('mother fuckers') that could be considered dehumanizing. 2. The target appears to be a group ('those') that Japan is rejecting, suggesting group-based targeting. 3. However, the text does not specify which protected group is being targeted (racial, gender, religious, national, sexual orientation). The phrase 'those mother fuckers' could refer to specific individuals or a non-protected group (e.g., criminals, immigrants in general without national/religious specification). 4. Without clear identification of a protected group, the rules require group targeting of protected characteristics to trigger classification as hate speech. 5. The language, while offensive, lacks explicit reference to protected group characteristics and could be interpreted as criticizing unspecified individuals or groups not covered by the rules. 6. Following the examples in the rules where offensive language targeting non-protected groups or unspecified targets is classified as non-hateful (e.g., 'politicians are such pigs'), this text does not meet the threshold for hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_118_k0", "example_id": "train_118", "text": "I support trans people's rights to be free of discrimination, but biological males should not be allowed to compete against women in athletic competitions", "label": 0, "reasoning": "Applying Rule 001: The text expresses support for trans rights while making a statement about athletic competition policies. It does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The phrase 'biological males' is descriptive rather than derogatory, and the statement focuses on competition fairness rather than promoting inferiority, violence, or elimination of trans people as a group. The context lacks hostile intent toward the protected group (transgender people). Applying Rule 002: Similar analysis - no dehumanizing language, no derogatory generalizations about protected groups with hostile intent. The comment addresses a specific policy issue (sports competition) rather than making broad hostile claims about trans people. Applying Rule 003: Again, no dehumanizing terms, no suggestions of elimination or violence toward a group, and no reinforcement of harmful stereotypes in a hostile context. The statement maintains support for trans rights while expressing a viewpoint on athletic categories, which falls outside the trigger patterns of all three rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_119_k0", "example_id": "train_119", "text": "stopping illegal immigration should have been done 30years ago before it turned my beloved los angeles turn into a filthy mexican border town complete with latino gangs millions of undocumented uneducated and povertystricken aliens with absolutely nothing to add to our quality of life but a strong back and a proclivity for having dozens of babies all of which become legal us citizens due to our insane laws and forcing california teachers to have to teach them in their own native language and for no additional increase in their already low wages add to that the free health care and welfare that hundreds of thousands of them are enjoying at american taxpayers expense and you have the blueprint for disaster that is why i left california for good and voted for trump for good every time i see mexican graffiti all over the once pristine neighborhoods of los angeles i want to help build the wall myself but i fear its far too late for that there are now 20 million illegals in america and soon it will become the united states of mexiconow im seeing the exact same thing happen all over western europe from england to france to germany and i will unfortunately live to see the exact same thing happen to them the complete and utter destruction of what were once countries with their own borders their own culture and their own identities all sacrificed on the altar of uncontrolled globalism purposely created turmoil and economic disaster", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about Mexicans and Latino immigrants as a protected national/ethnic group, using terms like 'filthy mexican border town,' 'uneducated and povertystricken aliens,' and suggesting they have 'absolutely nothing to add to our quality of life.' It reinforces harmful stereotypes about criminality ('latino gangs'), fertility ('having dozens of babies'), and economic burden. The hostile intent is evident in calls for exclusion ('build the wall') and predictions of destruction ('complete and utter destruction'). This is not reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities; it directly targets a protected group with dehumanizing language. Applying Rule 002: Similar analysis applies—the text uses derogatory generalizations with hostile intent toward Mexicans/Latinos as a group, not just individual behavior. Applying Rule 003: The text meets the trigger pattern with dehumanizing terms, suggestions of elimination/inferiority, and reinforcement of stereotypes in a hostile context, without falling under exceptions for reclaimed use or metaphorical non-group targeting. All rules indicate hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_120_k0", "example_id": "train_120", "text": "WHAT THE FUCK IS THIS ??!????! Disgusting! Absolutely disgusted and disappointed in Today's America.", "label": 0, "reasoning": "Applying Rule 001: The text uses strong expletives ('WHAT THE FUCK') and expressions of disgust directed at 'Today's America'. This targets a national group (Americans), which is a protected group. However, the language does not use dehumanizing terms like 'pigs' or 'retarded', nor does it suggest elimination, inferiority, or violence toward the group. It expresses disappointment and disgust but lacks derogatory generalizations, reinforcement of harmful stereotypes, or hostile intent toward Americans as a group. The criticism appears directed at the current state or events in America rather than dehumanizing Americans collectively. Applying Rule 002: Similar analysis applies - no dehumanizing terms, violent suggestions, or group-based derogatory generalizations are present. The text expresses strong negative emotion but targets a national context rather than promoting hostility toward Americans as an identity group. Applying Rule 003: Again, no dehumanizing language, suggestions of violence/elimination, or reinforcement of harmful stereotypes about Americans. The text uses metaphorical criticism of 'Today's America' (a concept or current state) rather than targeting Americans as a protected group with hostile intent. All rules indicate this does not meet the threshold for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_121_k0", "example_id": "train_121", "text": "Maybe I’m crazy. Maybe I’m not. I really don’t care if you try to fuck with my brain but ill stand strong bitch", "label": 0, "reasoning": "Applying Rule 001: The text contains the term 'bitch' which could be considered derogatory, but it's used as a general insult toward an unspecified individual ('you') rather than targeting a protected group. The speaker references themselves as 'crazy' in a self-referential, non-hostile manner similar to the 'I'm so retarded for forgetting my keys' example. There is no dehumanizing language targeting racial, gender, religious, national, or sexual orientation groups, no violent suggestions toward groups, and no reinforcement of harmful stereotypes about protected groups. The language appears directed at an individual in a confrontational context without group-based hostility. Applying Rule 002: Similar analysis applies - while offensive, the comment targets individual behavior ('try to fuck with my brain') without targeting a protected group or promoting generalized hostility toward identity-based communities. Applying Rule 003: The term 'bitch' is used metaphorically toward an individual, not a protected group, similar to the 'politicians are such pigs' example where metaphorical language targets individuals in a role. No evidence of group targeting, elimination suggestions, or harmful stereotypes about protected groups in hostile context.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_122_k0", "example_id": "train_122", "text": "ADIDAS for you means \"All Day I Dream About Snacks\"", "label": 0, "reasoning": "Applying Rule 001: The text 'ADIDAS for you means \"All Day I Dream About Snacks\"' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It is a playful reinterpretation of the ADIDAS acronym without any group targeting, hostile intent, or reinforcement of harmful stereotypes. No exceptions apply as there is no offensive language or group-based hostility. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. It does not target any protected group or promote generalized hostility. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. It is a metaphorical use targeting a brand name, not a protected group, and lacks hostile context. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_124_k0", "example_id": "train_124", "text": "I'll take feminists seriously when they start talking about sending only women into combat until the amount of women and men killed and wounded in battle are exactly the same.  Because it's all about equality right?", "label": 0, "reasoning": "Applying Rule 001: The text targets 'feminists' as a group, using sarcasm to criticize their advocacy for equality. It suggests sending 'only women into combat' to achieve numerical equality in casualties, which implies support for harmful actions against a gender-based group. However, this does not use dehumanizing terms (e.g., 'pigs', 'retarded'), violent suggestions (e.g., 'gas yourself'), or derogatory generalizations with hostile intent toward protected characteristics. The criticism is directed at ideological positions and perceived hypocrisy, not at women as a protected group based on inherent identity. The sarcastic tone critiques the concept of equality in combat roles rather than promoting elimination, inferiority, or violence against women. Exceptions apply as the language is metaphorical/satirical in criticizing non-group-based entities (feminist ideology) without invoking group-based hostility toward women. Applying Rule 002: Similar analysis - no dehumanizing terms or violent suggestions toward a protected group; targets individual behavior/ideology of feminists. Applying Rule 003: Similar analysis - no dehumanizing language or group targeting with hostile intent; sarcasm critiques ideological stance. Overall, the text is offensive and contentious but does not meet the criteria for hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_126_k0", "example_id": "train_126", "text": "I support lgbt… i want youre support for lgbt in pakistan", "label": 0, "reasoning": "Applying Rule 001: The text expresses support for LGBT people in Pakistan, which is a protected group based on sexual orientation. However, the language is positive ('I support lgbt', 'i want youre support for lgbt'), not dehumanizing or derogatory. There are no slurs, violent suggestions, or harmful stereotypes. The context appears to be advocacy rather than hostility. This does not meet the trigger pattern of dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. Applying Rule 002: Similar analysis - the text expresses support without any hostile intent, dehumanizing language, or derogatory generalizations. The comment promotes inclusion rather than elimination, inferiority, or violence toward the group. Applying Rule 003: Again, the text lacks dehumanizing terms, derogatory generalizations, or violent suggestions. It targets the LGBT group in Pakistan but in a supportive manner, not with hostile intent. None of the rules apply because the text is positive advocacy rather than hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_127_k0", "example_id": "train_127", "text": "FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language targeting a protected group (sexual orientation with 'homo') combined with violent suggestions ('shoulda let him get fucking eaten', 'nobody would have missed him'). This constitutes dehumanizing terms with hostile intent toward a group. The language reinforces harmful stereotypes about LGBTQ+ individuals and suggests elimination/violence. None of the exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected group (sexual orientation) with violent suggestions toward that group. The exceptions don't apply as this isn't criticism of individual behavior without group targeting. Applying Rule 003: The text contains dehumanizing language ('homo' as slur) with violent elimination suggestions toward a protected group. The exceptions don't apply as this isn't metaphorical criticism of non-group entities or individual targeting without group reference. All three rules indicate hate speech due to group-based derogatory language with hostile intent and violent suggestions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_128_k1", "example_id": "train_128", "text": "phuck white rasist ass people", "label": 1, "reasoning": "Analyzing the text 'phuck white rasist ass people' using the provided rulebook: 1) The text contains a derogatory term ('phuck' as a misspelling of 'fuck') directed at 'white rasist ass people'. 2) The target is a group ('white rasist ass people'), which combines racial identity ('white') with a characteristic ('rasist' [racist]). 3) According to Rule 001, Rule 002, and Rule 003, this qualifies as hate speech because: - It uses derogatory language ('phuck') with hostile intent. - It targets a group based on race ('white') combined with a negative characteristic ('racist'), which constitutes a derogatory generalization about a protected group (racial). - The context suggests hostility and reinforcement of harmful stereotypes, as it's not reclaimed, clinical, historical, or satirical. - No exceptions apply: it's not self-referential, metaphorical for non-group entities, or targeting individual behavior without group reference. The misspelling does not change the intent. Thus, all relevant rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_129_k0", "example_id": "train_129", "text": "What happened to rap? This right here.... This is rap", "label": 0, "reasoning": "Applying Rule 001: The text 'What happened to rap? This right here.... This is rap' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence toward any group, and no reinforcement of harmful stereotypes. The text appears to be commentary about music (rap) without targeting any protected identity group. Applying Rule 002: The text contains no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. It discusses a music genre without hostility toward any identity-based group. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. It is a neutral statement about music without metaphorical slurs or suggestions of harm toward any protected group. All rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_130_k0", "example_id": "train_130", "text": "All these problems men have, and no one will ever care.", "label": 0, "reasoning": "Applying Rule 001: The text 'All these problems men have, and no one will ever care' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. It mentions 'men' as a group but does so without hostile intent, dehumanizing language, or reinforcement of harmful stereotypes. The statement expresses a perception of societal indifference rather than promoting elimination, inferiority, or violence toward men as a group. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context, and the language is not metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis applies; the text lacks dehumanizing terms, derogatory generalizations with hostile intent, or suggestions of violence toward a protected group. It targets 'men' but does so without intent to dehumanize or promote generalized hostility, instead focusing on perceived lack of care. Applying Rule 003: The text does not trigger the rule as it lacks dehumanizing terms, derogatory generalizations with hostile intent, or violent suggestions in combination with group targeting. The reference to 'men' is not used in a context that suggests elimination, inferiority, or violence, and no exceptions are relevant. Overall, the text expresses a general observation about societal attitudes toward men's problems without meeting the criteria for hate speech under any rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_134_k0", "example_id": "train_134", "text": "Do not kill people.", "label": 0, "reasoning": "Applying Rule 001: The text 'Do not kill people' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. It lacks all key indicators: (1) no non-literal or metaphorical slurs, (2) no suggestion of elimination, inferiority, or violence toward a group, and (3) no reinforcement of harmful stereotypes in a hostile context. The statement is a general prohibition against killing without any group-based targeting or hostile intent. Applying Rule 002: The text does not use dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. It targets no protected group and promotes no generalized hostility. Applying Rule 003: The text contains no dehumanizing language, derogatory generalizations, or violent suggestions with group targeting. It is not metaphorical criticism of non-group-based entities and targets no individual or group identity. All rules indicate this is non-hateful speech as it lacks the required elements for classification as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_135_k0", "example_id": "train_135", "text": "Deport all niggers, spics, chinks and other undesirable from white nations. They don't belong in our white nations, they're invaders and enemy forces.", "label": 1, "reasoning": "Applying Rule 001: The text uses multiple dehumanizing racial slurs ('niggers', 'spics', 'chinks') targeting protected groups based on race and national origin. It makes derogatory generalizations about these groups as 'undesirable', 'invaders', and 'enemy forces', suggesting elimination through deportation. This meets all key indicators: (1) use of non-literal slurs, (2) suggestion of elimination of groups from 'white nations', and (3) reinforcement of harmful stereotypes about racial groups as invaders. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it directly promotes group-based hostility. Applying Rule 002: The text clearly uses dehumanizing terms with hostile intent toward racial groups, advocating for their removal from nations based on racial identity. No exception applies as this targets protected groups, not individual behavior. Applying Rule 003: The text uses dehumanizing language with group targeting and hostile intent, calling for action against racial groups. No exception applies as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_136_k0", "example_id": "train_136", "text": "the engagement ring story outrages me more than it should have.", "label": 0, "reasoning": "Applying Rule 001: The text 'the engagement ring story outrages me more than it should have' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses personal outrage about a story without targeting any group or individual based on protected characteristics. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The language is not reclaimed, clinical, historical, or satirical in a way that would trigger exceptions. Applying Rule 002: The text lacks dehumanizing language, group targeting, or hostile intent toward protected groups. It focuses on a personal emotional reaction to a story without targeting any identity-based community. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions combined with group targeting. It does not use metaphorical slurs, suggest elimination of groups, or reinforce harmful stereotypes in a hostile context. The expression of outrage is directed at a story, not at protected groups or individuals based on group identity.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_137_k0", "example_id": "train_137", "text": "We men enjoy the reproductive rights of paying for your abortion, the right to fund planned parenthood, the right to overpay on Obama care to fund contraception for promiscuous sluts. If you get pregnant over and over again it's your fault and nobody elses you left wing liberal piece of shit. Go be a whore. Keep spreading disease. Half of all black women have herpes. And we have the right to pay for it. You are outrageous.", "label": 1, "reasoning": "Analyzing the text against Rule 001, Rule 002, and Rule 003: (1) The text contains derogatory generalizations about multiple protected groups: 'promiscuous sluts' (gender-based derogatory term targeting women), 'left wing liberal piece of shit' (political affiliation not typically protected, but combined with other elements), 'Half of all black women have herpes' (racial and gender-based harmful stereotype about Black women). (2) There is group targeting with hostile intent: 'you left wing liberal piece of shit' targets political opponents, but more importantly, 'promiscuous sluts' and 'black women' target protected identity groups. (3) The language reinforces harmful stereotypes about women's sexuality and Black women's health in a hostile context with dehumanizing terms like 'whore' and 'sluts'. (4) The text suggests elimination/inferiority through phrases like 'Go be a whore. Keep spreading disease.' which implies women who seek reproductive healthcare are disease-spreaders. (5) No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's direct hostile speech targeting protected groups with derogatory generalizations and harmful stereotypes. Therefore, all three rules trigger as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_138_k0", "example_id": "train_138", "text": "Buy lethal guns ... Real ones, not toys!", "label": 0, "reasoning": "Applying Rule 001: The text 'Buy lethal guns ... Real ones, not toys!' does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions targeting specific groups. It lacks indicators such as non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context. The text appears to advocate for purchasing firearms but does not target any racial, gender, religious, national, or sexual orientation group. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context evident. Applying Rule 002: Similarly, this text does not use dehumanizing terms or derogatory generalizations about protected groups with hostile intent. It lacks group targeting and does not suggest elimination, inferiority, or violence toward a group. The criticism, if any, is not directed at individual behavior or protected groups. Applying Rule 003: The same analysis holds - no dehumanizing language, group-based targeting, or hostile intent toward protected groups is present. The text is metaphorical only in the sense of distinguishing 'real' from 'toys,' but this does not target non-group-based entities in a way that would trigger the rule. All rules indicate the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_139_k0", "example_id": "train_139", "text": "Trump is racist for not letting this brave woman return!!!", "label": 0, "reasoning": "Applying Rule 001: The text criticizes an individual (Trump) for being 'racist' in relation to a specific action ('not letting this brave woman return'). There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The criticism targets an individual's perceived behavior without invoking group-based hostility or stereotypes. The term 'racist' is used as a descriptor of individual actions, not as a slur against a protected group. This falls under the exception for language directed at specific individuals without invoking group-based hostility. Applying Rule 002: Similar analysis applies - no dehumanizing language or group targeting present. The comment addresses individual behavior (Trump's actions) rather than promoting hostility toward a protected group. Applying Rule 003: Again, no dehumanizing terms, violent suggestions, or group targeting. The criticism is directed at an individual without reference to group identity, fitting the exception for individual targeting. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_140_k0", "example_id": "train_140", "text": "You should use your time to arrest murderers not little kids", "label": 0, "reasoning": "Applying Rule 001: The text 'You should use your time to arrest murderers not little kids' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It criticizes law enforcement priorities without targeting any racial, gender, religious, national, or sexual orientation group. The term 'little kids' is not used as a slur or with hostile intent toward children as a protected group; it's a descriptive phrase contrasting with 'murderers'. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The criticism appears directed at institutional behavior rather than group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text lacks intent to dehumanize any identity-based community. Applying Rule 003: Same conclusion - no trigger patterns met. The language is not metaphorical slurs targeting protected groups, and there's no suggestion of elimination, inferiority, or violence toward any group. All rules indicate this should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_141_k0", "example_id": "train_141", "text": "Just kidding but I know how It feels", "label": 0, "reasoning": "Analyzing the text 'Just kidding but I know how It feels' against all three rules: Rule 001 requires dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting - none are present. Rule 002 has the same requirements - none are present. Rule 003 has the same requirements - none are present. The text contains no slurs, no group-based language, no violent suggestions, and no targeting of any protected groups. It appears to be a conversational expression of empathy preceded by 'Just kidding,' which suggests a lighthearted or ironic tone. No exceptions need to be applied since no rule triggers are present. Therefore, the text does not meet the criteria for hate speech under any provided rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_142_k0", "example_id": "train_142", "text": "I can spot a hitler in your blood. Aren’t you a German dude?", "label": 1, "reasoning": "Applying Rule 001: The text uses 'hitler' as a metaphorical slur referencing Adolf Hitler, which is derogatory toward Germans as a national group. It suggests the target has Hitler-like qualities ('in your blood'), implying inferiority or dangerous characteristics associated with that historical figure. This constitutes group targeting (Germans) with hostile intent through dehumanizing comparison. No exceptions apply - it's not reclaimed, clinical, historical analysis, or satire critiquing hate speech; it's direct targeting of an individual based on German nationality. Applying Rule 002: Similar analysis - uses derogatory generalization about a national group (Germans) through Hitler reference, suggesting elimination/inferiority. No exception for individual behavior targeting since it invokes group identity. Applying Rule 003: Same pattern - dehumanizing term ('hitler') used with group targeting (German nationality), suggesting inferior/dangerous qualities. Not metaphorical criticism of non-group entities. All three rules indicate hate speech due to derogatory group-based language with hostile intent targeting a protected national group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_144_k0", "example_id": "train_144", "text": "Men can see beauty, so they don't want to sleep with black women or make goblin babies.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about black women ('black women') and uses dehumanizing language ('goblin babies'), suggesting inferiority and linking it to a protected group (racial/ethnic). It reinforces harmful stereotypes about attractiveness and reproduction. There is group targeting (black women) with hostile intent, and no evidence of reclaimed, clinical, historical, or satirical context that critiques hate speech. The language is not metaphorical for non-group entities or directed at specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations and dehumanizing terms ('goblin babies') targeting a protected racial group, with suggestion of inferiority. It lacks exceptions for reclaimed contexts or criticism of individual behavior. Applying Rule 003: Similar to Rule 001, the text meets the trigger pattern with dehumanizing language and group targeting, without falling under exceptions for metaphorical use or individual targeting. All three rules indicate hate speech due to derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_145_k0", "example_id": "train_145", "text": "I am possessed by deamons", "label": 0, "reasoning": "Applying Rule 001: The text 'I am possessed by deamons' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It is a self-referential statement about personal experience with no group targeting, hostile intent, or reinforcement of harmful stereotypes. The term 'deamons' (likely meaning 'demons') is used in a metaphorical context about personal possession, not targeting any protected group. No exceptions apply as there is no group-based language. Applying Rule 002: No dehumanizing or derogatory group-based language is present. The statement is about the speaker's own condition with no generalization about protected groups or hostile intent toward groups. Applying Rule 003: Same analysis as Rule 001 - no group targeting, dehumanizing language, or violent suggestions toward protected groups. The text is purely self-descriptive without any hate speech indicators.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_146_k0", "example_id": "train_146", "text": "Absolutely excellent as ever, and yes, cycling is fabulous for mental health.. bike when you'¬Ä¬ôre happy, bike when you'¬Ä¬ôre sad, shout at the rain, scream inwardly at a complex hill climb and get that endorphin rush from being outside.. and smile at your fellow cyclists (and passing chickens, in my experience, a wee bwark at a chook makes many things better)", "label": 0, "reasoning": "Applying Rule 001: The text discusses cycling benefits for mental health in a positive, encouraging tone. It contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The language is metaphorical ('shout at the rain', 'scream inwardly') but targets natural phenomena and personal challenges, not groups. No group targeting, hostile intent, or harmful stereotypes are present. Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions targeting protected groups. The text promotes mental health benefits and positive social interactions ('smile at your fellow cyclists'). No intent to dehumanize or promote hostility toward any identity-based community. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The metaphorical language ('shout at the rain') criticizes non-group-based entities (weather, hill climbs). The target is individual experience and encouragement, not group identity. All rules indicate no hate speech present.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_149_k0", "example_id": "train_149", "text": "I won’t let your Allah fuck my life. Convert to Christian or make your self and kids a favour and return back to your homelands", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language targeting a religious group (Muslims) by referring to 'your Allah' in a hostile context, suggesting elimination/inferiority through demands to convert to Christianity or return to homelands. This constitutes group-based targeting with hostile intent. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about a protected religious group with hostile intent (demanding conversion/removal), meeting the trigger pattern. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text uses dehumanizing/derogatory language targeting a religious group with hostile intent (suggesting inferiority/elimination), meeting all key indicators. No exceptions apply as it's not metaphorical or individual-targeted.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_150_k0", "example_id": "train_150", "text": "My smile is beaming, my skin is gleaming! YUH", "label": 0, "reasoning": "Applying Rule 001: The text 'My smile is beaming, my skin is gleaming! YUH' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group or individual with hostile intent, nor does it reinforce harmful stereotypes. The language is positive self-description without any reference to protected groups or hostile context. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or violent suggestions present. The text lacks all key indicators for hate speech. Applying Rule 003: Same conclusion - the text contains only celebratory personal expression with no elements that would trigger any hate speech rules. All rules require dehumanizing/derogatory language with group targeting and hostile intent, none of which are present here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_151_k1", "example_id": "train_151", "text": "I wouldn’t like this girl as a police officer. I want police to keep me safe, she and every other woman cannot keep us safe they are week", "label": 1, "reasoning": "Applying Rule 001: The text targets women as a group with derogatory generalizations ('every other woman cannot keep us safe they are week'), suggesting inferiority in performing police duties. This constitutes group-based targeting of a protected gender group with hostile intent. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting specific individuals without group reference. Applying Rule 002: The comment uses derogatory generalizations about women as a group ('every other woman cannot keep us safe'), suggesting inferiority in a professional context. This meets the trigger pattern for group-based derogatory language with hostile intent. No exceptions apply as it's not targeting individual behavior or in a reclaimed context. Applying Rule 003: The text contains derogatory generalizations about women as a protected group ('every other woman cannot keep us safe they are week'), suggesting group-based inferiority in a hostile context. This triggers the rule for group-based derogatory language. No exceptions apply as it's not metaphorical for non-group entities or targeting individuals without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_153_k0", "example_id": "train_153", "text": "that was scripted right? please let that be scripted. No real human would have said any of those things", "label": 0, "reasoning": "Applying Rule 001: The text does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses disbelief about human behavior ('No real human would have said any of those things') but does not target any specific group based on race, gender, religion, nationality, or sexual orientation. The language is directed at unspecified 'things' said, not at a protected group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. Applying Rule 002: Similar analysis - no dehumanizing language or group targeting. The text criticizes unspecified statements without linking to protected groups or promoting group-based hostility. Applying Rule 003: Same conclusion - the text lacks dehumanizing terms, group targeting, or violent suggestions toward protected groups. The expression is about human behavior in general, not directed at any identity-based community. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_154_k0", "example_id": "train_154", "text": "Kill every white people mercylessly.", "label": 1, "reasoning": "Applying Rule 001: The text uses violent language ('Kill every white people mercylessly') that suggests elimination of a protected group (white people as a racial/national group). It contains group targeting ('every white people') with hostile intent, meeting key indicators of suggestion of elimination and violence toward a group. No exceptions apply - this is not reclaimed, clinical, historical, satirical, metaphorical, or individual-targeted language. Applying Rule 002: The text uses violent suggestions ('Kill') combined with group targeting of a protected racial group, meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains violent suggestions toward a protected group with clear group targeting, meeting all key indicators. No exceptions apply as this is literal, not metaphorical, and targets a group identity. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_155_k0", "example_id": "train_155", "text": "FUCK GAYS disgusting", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('disgusting') targeting a protected group (gays as a sexual orientation group) with hostile intent ('FUCK GAYS'), which constitutes group-based targeting with dehumanizing/derogatory language. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It directly targets the group identity. Applying Rule 002: The text uses derogatory language about a protected group (sexual orientation) with hostile intent, meeting the trigger pattern of group targeting with dehumanizing/derogatory language. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text uses derogatory language targeting a protected group (sexual orientation) with hostile context, meeting all key indicators. No exceptions apply for reclaimed, clinical, historical, satirical, metaphorical, or individual targeting contexts. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_157_k0", "example_id": "train_157", "text": "Every time I see her with a hijab, niqab or burka or shit I fantasising of choking her to death with that facking piece of cloth", "label": 1, "reasoning": "Applying Rule 001: The text uses violent suggestions ('fantasising of choking her to death') in combination with group targeting (Muslim women wearing religious garments like hijab, niqab, or burka). This constitutes dehumanizing language with hostile intent toward a protected religious group, as it suggests violence and elimination. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting individual behavior without group reference. Applying Rule 002: The text uses violent suggestions toward a protected religious group, meeting the trigger pattern of suggesting elimination/violence toward a group. No exceptions apply as it's not reclaimed/clinical/satirical context or targeting individual behavior without group hostility. Applying Rule 003: The text uses violent suggestions ('choking her to death') with group targeting (Muslim women), meeting all key indicators: non-literal violent suggestion, suggestion of violence toward a group, and reinforcement of harmful stereotypes in hostile context. No exceptions apply as it's not reclaimed/clinical/satirical, metaphorical for non-group entities, or targeting an individual without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_158_k0", "example_id": "train_158", "text": "People with traumatic brain injury should have the ability to get euthanatize", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'euthanatize' (a clinical term for euthanasia) in reference to 'people with traumatic brain injury' as a group. This suggests elimination/violence toward a protected group (people with disabilities). The phrase 'should have the ability to get euthanatize' implies support for allowing euthanasia specifically for this group, which could be interpreted as suggesting elimination of people with disabilities. This meets the trigger pattern: (1) suggestion of elimination toward a group, (2) targets a protected group (people with disabilities), and (3) occurs in a context that could reinforce harmful stereotypes about disability. No exceptions apply: this is not reclaimed/self-referential use, not satirical critique, not metaphorical criticism of non-group entities, and not targeting individual behavior without group reference. Applying Rule 002: Similar analysis applies - dehumanizing suggestion of elimination targeting a protected group with hostile intent (implying people with traumatic brain injuries should be eliminated). No exception for individual behavior targeting applies. Applying Rule 003: Same analysis as Rule 001 - suggestion of elimination toward protected disability group without metaphorical or reclaimed context exceptions. All three rules indicate this should be classified as hate speech due to group-targeted elimination suggestion toward a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_159_k0", "example_id": "train_159", "text": "They are forgetting Russell Crowe 's performance in A Beautiful Mind. I know schizophrenia, and it was spot-on.", "label": 0, "reasoning": "Applying Rule 001: The text discusses Russell Crowe's performance portraying schizophrenia in 'A Beautiful Mind' and states 'I know schizophrenia, and it was spot-on.' This contains no dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The reference to schizophrenia is clinical/descriptive in context of film critique, not hostile. No group targeting or harmful stereotypes are present. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The mention of schizophrenia is in context of evaluating acting performance, not stigmatizing mental illness as a group. Applying Rule 003: Same analysis - the language is neither metaphorical slurs nor suggests elimination/inferiority/violence toward any group. The context is film criticism with clinical reference, not hate speech. All rules indicate this text does not meet hate speech criteria.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_160_k0", "example_id": "train_160", "text": "Wtf I thought you had only one sibling", "label": 0, "reasoning": "Applying Rule 001: The text 'Wtf I thought you had only one sibling' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. It targets an individual's statement about family structure without any group-based hostility. The term 'Wtf' is an exclamation of surprise, not a slur targeting a protected group. No indicators of elimination, inferiority, or violence toward a group are present. The comment is directed at an individual without invoking group identity or stereotypes. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The text addresses personal information (number of siblings) without stigmatizing any identity-based community. Applying Rule 003: Same conclusion - the language is neither metaphorical criticism of non-group entities nor contains slurs in a hostile context. The text is conversational and lacks the elements required to trigger any hate speech rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_161_k0", "example_id": "train_161", "text": "Those deaf people are like rats in dark places. They wouldn’t survive a day in post apocalypse event for sure, I would kick’em off to stole their supplies", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('rats') targeting a protected group (deaf people as a disability group). It contains derogatory generalizations suggesting inferiority ('wouldn't survive a day') and violent suggestions ('I would kick'em off to stole their supplies') with group targeting ('Those deaf people'). This meets the trigger pattern of dehumanizing terms, suggestion of elimination/inferiority/violence toward a group, and reinforcement of harmful stereotypes in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: Same analysis applies - dehumanizing language targeting a protected group with hostile intent. Applying Rule 003: Same analysis applies - dehumanizing language with group targeting and hostile context. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_162_k0", "example_id": "train_162", "text": "He's got the hottest man tits i've seen.", "label": 0, "reasoning": "Applying Rule 001: The text 'He's got the hottest man tits i've seen' contains potentially derogatory language ('man tits'), but it targets an individual ('He') without reference to any protected group identity (e.g., gender, racial, religious, national, or sexual orientation groups). The language appears to be a colloquial, potentially mocking description of an individual's physical appearance rather than a generalization about a protected group. There is no suggestion of elimination, inferiority, or violence toward a group, nor reinforcement of harmful stereotypes in a hostile context. The exception for 'target is an individual without reference to group identity' applies. Applying Rule 002: Similar analysis - the comment targets an individual's physical characteristics without group-based targeting or promotion of generalized hostility toward a protected group. Applying Rule 003: The same individual targeting without group reference applies, and there is no metaphorical criticism of non-group-based entities. The language, while potentially offensive, does not meet the criteria for dehumanizing or derogatory group-based language with hostile intent as defined in all three rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_163_k0", "example_id": "train_163", "text": "This is just crazy liberal satanic crap. Don't fall for it. There are only two genders and these people are just cofused psychos", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory terms 'crazy', 'satanic', and 'psychos' in reference to people who support non-binary gender identities. This targets a protected group (sexual orientation/gender identity) with hostile intent, suggesting they are confused and promoting harmful stereotypes. The language is not reclaimed, clinical, historical, or satirical, and it generalizes about a group rather than criticizing individual behavior. Applying Rule 002: The text contains derogatory generalizations about a protected group (gender/sexual orientation) with hostile intent, using terms that suggest inferiority ('confused psychos'). It targets the group as a whole, not individual behavior. Applying Rule 003: The text uses derogatory language ('satanic crap', 'psychos') targeting a protected group (gender identity) with hostile intent, reinforcing harmful stereotypes in a hostile context. No exceptions apply as it's not metaphorical, self-referential, or critiquing hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_164_k0", "example_id": "train_164", "text": "It's that nerdy guy from the polar express.", "label": 0, "reasoning": "Applying Rule 001: The text 'It's that nerdy guy from the polar express' contains the term 'nerdy', which could be considered derogatory. However, I must check for dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The term 'nerdy' targets an individual ('that guy') based on perceived personality traits, not a protected group (racial, gender, religious, national, or sexual orientation). There is no suggestion of elimination, inferiority, or violence toward a group, nor reinforcement of harmful stereotypes in a hostile context. The language appears to be a casual description of an individual without group-based hostility. Applying Rule 002: Similar analysis applies - no dehumanizing terms targeting protected groups, no violent suggestions with group targeting. The comment targets an individual without promoting generalized hostility toward a protected identity-based community. Applying Rule 003: Again, the term 'nerdy' is used to describe an individual, not metaphorically targeting a non-group-based entity or a protected group. No evidence of hostile intent toward a protected group. All rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_165_k0", "example_id": "train_165", "text": "OMG Lucas !! Such a great kid, such a big grow", "label": 0, "reasoning": "Applying Rule 001: The text 'OMG Lucas !! Such a great kid, such a big grow' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses positive sentiment about an individual (Lucas) with terms like 'great kid' and 'big grow' (likely meaning growth). There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is complimentary and individual-focused. Applying Rule 002: Same analysis - no dehumanizing language, group-based targeting, or hostile intent toward protected groups. Applying Rule 003: Same analysis - the text lacks all trigger patterns including dehumanizing terms, group targeting, and violent suggestions. All rules indicate this should be classified as non-hateful (0) as it contains only positive commentary about an individual without any elements that would trigger hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_166_k0", "example_id": "train_166", "text": "Trumps a liar and an idiot, a douche bag , Narcissist, and Zionist boot licker.", "label": 0, "reasoning": "Applying Rule 001: The text uses derogatory terms ('idiot', 'douche bag') and negative characterizations ('liar', 'Narcissist', 'Zionist boot licker') targeting Donald Trump as an individual. These terms criticize specific personal attributes and political positions rather than targeting a protected group based on race, gender, religion, national origin, or sexual orientation. The term 'Zionist' refers to a political ideology/support for Israel, not a protected religious or ethnic group. No dehumanizing language, violent suggestions, or group-based generalizations about protected groups are present. The criticism is directed at an individual's behavior and political stance without invoking group-based hostility. Applying Rule 002: Similar analysis - the text targets individual behavior and characteristics without derogatory generalizations about protected groups. No suggestion of elimination, inferiority, or violence toward a group. Applying Rule 003: The language criticizes an individual without reference to group identity or protected characteristics. No metaphorical slurs targeting groups, no reinforcement of harmful stereotypes about protected groups in hostile context. All three rules indicate this should be classified as non-hateful (0) since it targets an individual's actions and political views rather than a protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_167_k0", "example_id": "train_167", "text": "Humans with third leg I hope to distinct soon, with much love", "label": 1, "reasoning": "Applying Rule 001: The text uses the phrase 'hope to distinct soon' which resembles 'hope to extinct soon' - a violent suggestion of elimination toward a group. The phrase 'Humans with third leg' appears to be a derogatory generalization targeting a protected group (likely referring to people with disabilities or physical differences). This combines group targeting with violent elimination suggestions. No exceptions apply: it's not reclaimed, clinical, historical, or satirical context; not metaphorical criticism of non-group entities; not targeting specific individuals without group reference; and not about faking conditions. The sarcastic 'with much love' doesn't negate the hostile intent. Applying Rule 002: The text uses violent suggestion ('hope to distinct soon') with group targeting ('Humans with third leg'), indicating elimination intent toward a protected group. No exceptions apply as it's not reclaimed context or criticism of individual behavior. Applying Rule 003: The text contains violent elimination suggestion combined with derogatory group generalization, with key indicators of non-literal slurs and suggestion of elimination toward a group. No exceptions apply for reclaimed use, metaphorical criticism, or individual targeting. All three rules indicate this is hate speech due to derogatory group-based language with hostile elimination intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_168_k1", "example_id": "train_168", "text": "Slow death to people like you", "label": 1, "reasoning": "Applying Rule 001: The text 'Slow death to people like you' contains a violent suggestion ('slow death') directed at 'people like you'. This targets a group defined by similarity to 'you' (implied group identity). The language suggests elimination/violence toward a group with hostile intent. No exceptions apply - it's not reclaimed, clinical, historical, or satirical; not metaphorical criticism of non-group entities; and targets a group rather than specific individuals without group reference. Applying Rule 002: The text uses violent suggestion ('slow death') with group targeting ('people like you'), indicating hostile intent toward a perceived group. No exceptions apply as it's not reclaimed/satirical context and targets a group rather than individual behavior. Applying Rule 003: The text contains violent suggestion ('slow death') combined with group targeting ('people like you'), meeting the trigger pattern with indicators of elimination/violence toward a group in hostile context. No exceptions apply as it's not metaphorical criticism of non-group entities or targeting individuals without group identity. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_169_k0", "example_id": "train_169", "text": "Dont do drugs kids...", "label": 0, "reasoning": "Applying Rule 001: The text 'Dont do drugs kids...' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The message appears to be general advice against drug use directed at children/young people, which is not a protected group in the context of hate speech rules. No indicators of group-based hostility, elimination rhetoric, or harmful stereotypes are present. Applying Rule 002: Similar analysis - no dehumanizing language targeting protected groups, no suggestions of violence or inferiority toward any identity-based community. The text addresses behavior (drug use) rather than attacking a protected group. Applying Rule 003: Again, no dehumanizing terms, no group targeting, no violent suggestions. The language is straightforward advice without metaphorical slurs or hostile intent toward any protected demographic. All three rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_170_k0", "example_id": "train_170", "text": "To all the white people that might read this, know that I as a black man, will not criticize you based off the color of your skin. I know that there are good and bad people in all colors. Have a good day and God bless!", "label": 0, "reasoning": "Applying Rule 001: The text does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It specifically states 'I will not criticize you based off the color of your skin' and acknowledges 'there are good and bad people in all colors.' This is non-hostile and promotes equality rather than targeting any group. No exceptions apply as there is no offensive language present. Applying Rule 002: No dehumanizing language, derogatory generalizations, or violent suggestions are present. The text explicitly rejects criticism based on skin color and recognizes diversity within all groups. No exceptions apply. Applying Rule 003: Similar analysis to Rules 001 and 002 - no triggering patterns of dehumanizing language, group targeting, or hostile intent. The message is inclusive and anti-discriminatory in nature. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_171_k0", "example_id": "train_171", "text": "Muslims want war! So take it to them first", "label": 1, "reasoning": "Applying Rule 001: The text uses group-based language targeting Muslims as a protected religious group with hostile intent ('Muslims want war! So take it to them first'). This contains: (1) a derogatory generalization suggesting all Muslims collectively desire conflict, (2) a suggestion of preemptive violence ('take it to them first'), and (3) reinforcement of harmful stereotypes about Muslims being inherently violent or warlike. No exceptions apply - this is not reclaimed, clinical, historical, satirical, metaphorical, or individual-targeted language. Applying Rule 002: Same analysis applies - dehumanizing group-based language with hostile intent targeting a protected religious group. Applying Rule 003: Same analysis applies - dehumanizing group-based language with hostile intent and no contextual safeguards. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_173_k0", "example_id": "train_173", "text": "Perfect place for Lana- China and Myanmar. No trouble there. They know how to handle those pigs.", "label": 1, "reasoning": "Applying Rule 001: The text uses the dehumanizing term 'pigs' in reference to people in China and Myanmar, which are national groups (protected groups). The phrase 'They know how to handle those pigs' suggests support for oppressive actions against these groups, indicating hostile intent. This matches the trigger pattern of dehumanizing language with group targeting and suggestion of violence/elimination. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets groups rather than specific individuals. Applying Rule 002: The text uses dehumanizing language ('pigs') targeting national groups (China and Myanmar) with implied support for oppressive handling, indicating hostile intent toward protected groups. No exceptions apply as this is not reclaimed language or criticism of individual behavior. Applying Rule 003: The text contains dehumanizing term 'pigs' targeting national groups with suggestion of violent handling, matching the trigger pattern. No exceptions apply as this is not metaphorical criticism of non-group entities or targeting of individuals without group reference. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_174_k0", "example_id": "train_174", "text": "Looks like the gay poster boy with syphilis", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('gay poster boy') that targets sexual orientation as a protected group, combined with 'with syphilis' which reinforces harmful stereotypes about LGBTQ+ individuals and disease. This constitutes derogatory generalization about a protected group with hostile intent. No exceptions apply - it's not reclaimed, clinical, historical, or satirical critique; it directly targets a group identity. Applying Rule 002: The comment uses derogatory language targeting a protected group (sexual orientation) and reinforces harmful stereotypes about disease and LGBTQ+ individuals, indicating hostile intent. No exceptions apply as it's not targeting individual behavior without group reference. Applying Rule 003: The text contains derogatory language targeting a protected group (sexual orientation) with reinforcement of harmful stereotypes, meeting the trigger pattern for dehumanizing or derogatory group-based language with hostile intent. No exceptions apply for reclaimed, clinical, historical, or satirical contexts, nor is it metaphorical criticism of non-group entities.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_175_k2", "example_id": "train_175", "text": "Fuck that shit this bitch ugly and she has a penis,oh hell nawww!!!", "label": 1, "reasoning": "Analyzing the text 'Fuck that shit this bitch ugly and she has a penis,oh hell nawww!!!' against the provided rules: 1. The text uses derogatory language ('bitch') and makes a transphobic statement ('she has a penis') that targets transgender individuals as a protected group based on gender identity. 2. The language reinforces harmful stereotypes about transgender people (specifically the stereotype that transgender women are 'men in disguise') in a hostile context with aggressive phrasing ('Fuck that shit', 'oh hell nawww'). 3. This constitutes derogatory generalization about a protected group (gender/sexual orientation) with hostile intent, as per Rule 001, Rule 002, and Rule 003. 4. No exceptions apply: the language is not reclaimed, clinical, historical, or satirical; it's not metaphorical criticism of non-group entities; and it targets a group identity rather than individual behavior without group reference. The text promotes group-based hostility toward transgender people.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_176_k0", "example_id": "train_176", "text": "MASS BLACK WORLDWIDE GENOCIDE IS OUR ONLY HOPE", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'genocide' which suggests elimination of a group (Black people worldwide), combined with 'our only hope' indicating hostile intent toward that protected racial group. This meets the trigger pattern of suggesting elimination of a group with hostile intent. No exceptions apply as this is not reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities or targeting individuals without group reference. Applying Rule 002: The text contains derogatory generalization about a protected racial group (Black people) with violent suggestion (genocide) and group targeting. This meets the trigger pattern. No exceptions apply as this is not reclaimed context or criticism of individual behavior. Applying Rule 003: The text uses language suggesting elimination ('genocide') of a protected racial group with hostile intent ('our only hope'). This meets the trigger pattern. No exceptions apply as this is not reclaimed context, metaphorical criticism of non-group entities, or individual targeting. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_177_k0", "example_id": "train_177", "text": "Homosexuality and transgenderism is a mental illness and a sexual perversion!", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('mental illness', 'sexual perversion') targeting protected groups (LGBTQ+ individuals based on sexual orientation and gender identity). It makes a derogatory generalization about these groups, suggesting inferiority by labeling them as mentally ill and perverted. This reinforces harmful stereotypes in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, or satirical critique; it's a direct group-based attack. Applying Rule 002: Same analysis - dehumanizing/derogatory language targeting protected groups with hostile intent. No exception for individual behavior targeting. Applying Rule 003: Same analysis - derogatory generalizations about protected groups with suggestion of inferiority. No metaphorical or individual targeting exceptions apply.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_181_k0", "example_id": "train_181", "text": "Its a challenge can anyone do it in reality", "label": 0, "reasoning": "Applying Rule 001: The text 'Its a challenge can anyone do it in reality' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The text appears to be a neutral statement about a challenge. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. Applying Rule 003: Same analysis - no triggering patterns present. All rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_183_k0", "example_id": "train_183", "text": "Love being roasted", "label": 0, "reasoning": "Applying Rule 001: The text 'Love being roasted' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no suggestion of elimination/inferiority/violence toward a group, and no reinforcement of harmful stereotypes. The term 'roasted' appears to be used in a colloquial, non-hostile context (likely referring to being teased or criticized in a lighthearted way). This falls under exceptions for non-group-based metaphorical use and non-hostile context. Applying Rule 002: No dehumanizing language, group targeting, or hostile intent present. The comment does not target any protected group or promote generalized hostility. Applying Rule 003: Same analysis as Rule 001 - no trigger patterns met, and the language appears metaphorical/colloquial without group targeting. All rules indicate this should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_184_k0", "example_id": "train_184", "text": "Christianity and mostly every religion was told to accept one another and give them respect doesn't mean u have to change ur religion and ur opinion just give ur respect and they are equal to u and they are human", "label": 0, "reasoning": "Applying Rule 001: The text discusses religious acceptance and respect, stating that different religions should respect each other while maintaining their own beliefs, and emphasizes equality and shared humanity. There is no dehumanizing language (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The text promotes respect and equality rather than hostility toward any group. No exceptions apply as the context is positive and non-hostile. Applying Rule 002: Similar analysis - no dehumanizing terms, group-based derogatory language, or violent suggestions are present. The text focuses on mutual respect among religions without targeting any protected group with hostility. Applying Rule 003: Again, no trigger patterns are met - the language is respectful, emphasizes equality, and lacks any indicators of hate speech such as slurs, elimination rhetoric, or harmful stereotypes. The text aligns with promoting interfaith harmony rather than derogatory group-based language.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_185_k0", "example_id": "train_185", "text": "Head looks like a big ass jelly bean", "label": 0, "reasoning": "Applying Rule 001: The text 'Head looks like a big ass jelly bean' contains potentially offensive language ('ass' as profanity) but does not use dehumanizing terms like 'pigs' or 'retarded', nor does it make derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation). There is no suggestion of elimination, inferiority, or violence toward a group, and no reinforcement of harmful stereotypes in a hostile context. The target appears to be an individual's physical appearance without reference to group identity. Applying Rule 002: Similar analysis - no dehumanizing terms targeting protected groups, no group-based hostility. Applying Rule 003: The language is metaphorical ('jelly bean') but targets an individual's physical characteristic, not a protected group. All rules indicate this does not meet the criteria for hate speech as defined in the rulebook, as it lacks group targeting, dehumanizing language toward protected groups, and hostile intent against protected identities.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_186_k0", "example_id": "train_186", "text": "How can Europe allow millions of rapists animals to go there ?", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('animals') and derogatory generalization ('rapists') targeting a group (people migrating to Europe). It suggests elimination/inferiority through the rhetorical question implying they shouldn't be allowed. This constitutes group-based targeting with hostile intent. No exceptions apply - not reclaimed, clinical, historical, or satirical context; not metaphorical criticism of non-group entities; not targeting specific individuals without group reference. Applying Rule 002: Same analysis - dehumanizing term ('animals') with group targeting and hostile implication. No exception for individual behavior targeting. Applying Rule 003: Same analysis - dehumanizing language with group targeting and hostile context. No applicable exceptions. All three rules indicate hate speech classification.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_187_k0", "example_id": "train_187", "text": "Filthy Chinese", "label": 1, "reasoning": "Applying Rule 001: The text 'Filthy Chinese' contains derogatory language ('filthy') targeting a national group ('Chinese'). This constitutes a derogatory generalization about a protected group (national origin) with hostile intent, as it implies inferiority or contamination without contextual safeguards. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory language targeting a protected national group, meeting the trigger pattern for dehumanizing/derogatory group-based language with hostile intent. No exceptions apply as it's not criticizing individual behavior or in a reclaimed context. Applying Rule 003: The text contains derogatory language ('filthy') combined with group targeting ('Chinese'), suggesting inferiority toward a protected national group in a hostile context. No exceptions apply for reclaimed use, metaphorical criticism of non-group entities, or individual targeting. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_188_k0", "example_id": "train_188", "text": "If men shouldnt hit women because we are physically stronnger... then women shouldnt talk because they are fucking louder.", "label": 1, "reasoning": "The text 'If men shouldn't hit women because we are physically stronger... then women shouldn't talk because they are fucking louder.' is analyzed using the rulebook. Rule 001, 002, and 003 all define hate speech as involving dehumanizing or derogatory group-based language with hostile intent, targeting protected groups (e.g., gender). This text targets women as a group, using derogatory language ('fucking louder') that reinforces harmful stereotypes about women being loud or talkative in a hostile context, implying they should be silenced. It does not fit exceptions: it is not reclaimed, clinical, historical, or satirical; it is not metaphorical criticism of non-group entities; and it targets a protected group (women) rather than individual behavior. Therefore, all relevant rules apply, classifying it as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_189_k0", "example_id": "train_189", "text": "Serbia should kill gays in yugoslavia and not albanians, bosnians, croatian", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('kill') combined with group targeting against a protected group (gays as a sexual orientation group). It suggests elimination/violence toward this group ('should kill gays'), which meets key indicators (2) and (3). No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it directly promotes violence against a protected group. Applying Rule 002: The text contains derogatory generalizations about a protected group (sexual orientation) with violent suggestions ('kill'), meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior but direct group targeting. Applying Rule 003: The text uses violent suggestions ('kill') in combination with group targeting against a protected group (gays), meeting all key indicators. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. The text specifically targets 'gays' as a group and advocates for their killing, which constitutes hate speech under all three rules.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_190_k0", "example_id": "train_190", "text": "I'm beginning to doubt your accuracy, I mean violent Canadians? That's just absurd.", "label": 0, "reasoning": "Analyzing the text 'I'm beginning to doubt your accuracy, I mean violent Canadians? That's just absurd.' against the rulebook: Rule 1 requires dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. This text expresses skepticism about a claim ('violent Canadians') and calls it 'absurd' but does not use dehumanizing language, make derogatory generalizations, or suggest violence toward Canadians as a protected group (national origin). The phrase 'violent Canadians' is referenced as something the speaker doubts, not endorsed. Rule 2 similarly requires hostile intent with group-based language; here, there's no evidence of hostility, elimination suggestions, or reinforcement of harmful stereotypes. Rule 3 includes the same criteria with contextual safeguards; the text lacks metaphorical slurs, group targeting with malice, or a hostile context. All rules include exceptions for non-group-based criticism or non-hostile contexts, which apply here as the comment critiques an idea rather than targeting a protected group with hateful intent. Therefore, no rule triggers a label of 1.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_191_k0", "example_id": "train_191", "text": "a homo? so you fuck your brother instead of your sister?", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('homo') targeting sexual orientation (a protected group) with hostile intent through an offensive rhetorical question suggesting incestuous behavior. This reinforces harmful stereotypes about LGBTQ+ individuals. The language is not reclaimed, clinical, historical, or satirical - it appears to be a direct insult. It targets a group (homosexual people) rather than an individual without group reference. Applying Rule 002: The text uses derogatory language ('homo') with group targeting and hostile intent, suggesting deviant behavior. It is not directed at individual behavior but makes a generalization about a protected group. Applying Rule 003: The text uses derogatory language targeting a protected group (sexual orientation) with hostile context through offensive implication. It is not metaphorical criticism of non-group entities or self-referential. All three rules indicate this meets the criteria for hate speech due to derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_192_k0", "example_id": "train_192", "text": "I feel so dumb I want to have even labeled them as disabled even if I knew them.... when I think of disabilities and especially in terms of affecting one's relationship I think of more like mental disabilities or so serious that you can't use ur body. Thank you for enlightening me and I'm sorry.", "label": 0, "reasoning": "Analyzing the text against Rule 001, Rule 002, and Rule 003: The text contains the term 'disabled' in a clinical/descriptive context about disabilities, not as a derogatory term. It discusses disabilities in terms of relationships and physical limitations without targeting any protected group with hostile intent. There is no dehumanizing language, derogatory generalizations, violent suggestions, or group-based targeting present. The speaker expresses self-reflection ('I feel so dumb'), acknowledges learning ('Thank you for enlightening me'), and apologizes, indicating a non-hostile context. All rules specify exceptions for clinical contexts and lack of group targeting, which apply here. Therefore, none of the rules trigger a hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_193_k0", "example_id": "train_193", "text": "dunno if this makes me disabled but I have asthma so if there was any running or stairs involved then il just die from suffocation in my own lungs haha xxx", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'disabled' and 'asthma' but in a self-referential, humorous context about personal physical limitations. There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions. The speaker is describing their own condition ('I have asthma') in a self-deprecating way ('haha'), not targeting any group. This falls under the exception for non-group-based, non-hostile self-reference. Applying Rule 002: No dehumanizing terms or group targeting present. The comment discusses individual health without promoting hostility toward people with disabilities as a group. Applying Rule 003: No indicators of hate speech - no slurs, elimination suggestions, or harmful stereotypes. The metaphorical language ('die from suffocation') is clearly hyperbolic self-description, not targeting others. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_194_k0", "example_id": "train_194", "text": "Lesbian chewbacca", "label": 0, "reasoning": "Analyzing the text 'Lesbian chewbacca' against the provided rulebook: 1. The text contains 'chewbacca' which is a fictional character from Star Wars, not a dehumanizing term like 'pigs' or 'retarded' as specified in the rules. 2. The term 'lesbian' refers to a sexual orientation (a protected group), but there is no derogatory generalization, violent suggestion, or hostile intent present. 3. The combination 'Lesbian chewbacca' does not suggest elimination, inferiority, or violence toward lesbians as a group. 4. There is no reinforcement of harmful stereotypes in a hostile context. 5. The text lacks key indicators from all three rules: no non-literal/metaphorical slurs targeting the group, no suggestion of harm, and no hostile context. 6. Applying exceptions: The text could be interpreted as metaphorical (comparing to a fictional character) or satirical, but even without that, it fails to meet the trigger patterns for hate speech as defined. Therefore, based on rule_001, rule_002, and rule_003, the text does not constitute hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_196_k0", "example_id": "train_196", "text": "Grow some fucking balls and take back your country, bongs. Start killing reporters, politicians, and Asians.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('bongs' as a slur for British people, which is a national group) and contains violent suggestions ('Start killing reporters, politicians, and Asians') targeting multiple groups including Asians (a racial/national group). This meets the trigger pattern of dehumanizing terms, violent suggestions toward groups, and reinforcement of harmful stereotypes in a hostile context. None of the exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting specific individuals without group reference. Applying Rule 002: The text clearly uses derogatory group-based language with hostile intent against British people and Asians, with explicit calls for violence. The exception for individual behavior targeting doesn't apply. Applying Rule 003: The text contains dehumanizing language ('bongs') and violent suggestions targeting protected groups (national and racial groups), meeting all key indicators. No exceptions apply as it's not metaphorical criticism of non-group entities or individual targeting.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_197_k0", "example_id": "train_197", "text": "I mean it's great that you're proving that Asians are devolving, but you didn't finish making my iPhone...", "label": 1, "reasoning": "Analyzing the text 'I mean it's great that you're proving that Asians are devolving, but you didn't finish making my iPhone...' using the rulebook: (1) The text contains 'Asians are devolving' - this is a derogatory generalization about a protected national/racial group (Asians) suggesting biological inferiority ('devolving'), which aligns with Rule 1's trigger pattern of derogatory generalizations about protected groups with suggestions of inferiority. (2) The context appears hostile with sarcasm ('it's great that...'), reinforcing harmful stereotypes about Asian people. (3) No exceptions apply: this is not reclaimed, clinical, historical, or satirical critique; it's not metaphorical criticism of non-group entities; and it targets Asians as a group rather than specific individuals. (4) All three rules (001, 002, 003) would trigger based on the group-based derogatory language with hostile intent. The iPhone reference reinforces a stereotype but doesn't change the core hateful content.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_198_k0", "example_id": "train_198", "text": "Anyone who listens to rap and is white is not part of the ethnostate and will be put to death.", "label": 1, "reasoning": "Applying Rule 001: The text uses group-based language targeting 'white' people who listen to rap, suggesting elimination ('will be put to death') and exclusion from an 'ethnostate'. This constitutes derogatory generalization about a racial/national group with violent suggestions toward that group. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting specific individuals without group reference. Applying Rule 002: The text uses violent suggestions ('put to death') combined with group targeting based on race and cultural consumption, promoting elimination of a protected group. No exceptions apply as it's not criticizing individual behavior without group targeting. Applying Rule 003: The text contains dehumanizing implications (exclusion from humanity via 'ethnostate') and explicit violent elimination toward a racial group, reinforcing harmful stereotypes about racial purity. No exceptions apply for reclaimed use, satire, or metaphorical criticism of non-group entities.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_199_k0", "example_id": "train_199", "text": "This fcking jew wants money? I’ll give him only my dick if he wants", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('fcking jew') targeting a religious group (Jewish people) with hostile intent. It uses a slur in a non-literal, pejorative manner and reinforces harmful stereotypes about Jewish people and money. The comment is directed at an individual ('him') but explicitly references group identity ('jew'), making it group-based targeting. None of the exceptions apply: it's not reclaimed, clinical, historical, or satirical; it's not metaphorical criticism of non-group entities; and it's not merely criticizing individual behavior without group reference. Applying Rule 002: The text uses derogatory group-based language ('jew' as a slur) with hostile intent, suggesting inferiority through the offensive response. It targets a protected religious group. The exception for individual behavior criticism doesn't apply because the hostility is tied to group identity. Applying Rule 003: The text contains dehumanizing language targeting a religious group with hostile context. The violent/sexual suggestion ('I'll give him only my dick') combined with group-based derogation meets the trigger pattern. No exceptions apply as this isn't metaphorical criticism of non-group entities or individual-only targeting.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_200_k0", "example_id": "train_200", "text": "Tell me now \"Whose the terrorists again \"???", "label": 0, "reasoning": "Analyzing the text 'Tell me now \"Whose the terrorists again \"???' against the rulebook: 1. The text contains a grammatically incorrect phrase 'Whose the terrorists again' (likely meaning 'Who's the terrorists again') with multiple question marks indicating emphasis. 2. There are no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions present. 3. The text does not target any specific racial, gender, religious, national, or sexual orientation group - 'terrorists' refers to a behavioral category, not a protected identity group. 4. There is no suggestion of elimination, inferiority, or violence toward a group, nor reinforcement of harmful stereotypes. 5. The text appears to be rhetorical questioning about terrorism without targeting protected groups or using hateful language as defined in Rules 001, 002, and 003. Since none of the trigger patterns apply and there are no protected groups targeted with hostile intent, the text does not meet criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_201_k0", "example_id": "train_201", "text": "Really, I hope she get raped in the future. Raping women should be legal I think", "label": 1, "reasoning": "Applying Rule 001: The text contains violent suggestions ('hope she get raped', 'Raping women should be legal') that target women as a protected gender group. This suggests elimination of rights and violence toward a group, with hostile intent. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It directly promotes violence against women as a group. Applying Rule 002: The text uses violent suggestions ('rape') with group targeting (women), indicating hostile intent toward a protected group. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains violent suggestions combined with group targeting of women, reinforcing harmful stereotypes in a hostile context. No exceptions apply for reclaimed, clinical, historical, satirical, metaphorical, or individual targeting contexts. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_202_k0", "example_id": "train_202", "text": "I don't understand why people get mad at the things that he says he has  A right to his opinion Just because he doesn't agree with you that does not make him a monster or evil person. It's annoying in 2018 on you to 2019 people are operating with an extremely sensitive Ignorant mindset if you don't agree with them", "label": 0, "reasoning": "Applying Rule 001: The text criticizes people who get mad at others for having different opinions, describing them as having 'an extremely sensitive Ignorant mindset.' This targets individuals based on their behavior (being sensitive and ignorant when others disagree) rather than any protected group identity. The language 'monster or evil person' is used in a hypothetical context to defend someone's right to opinion, not to dehumanize a protected group. No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions are present. The criticism is directed at individual mindset and behavior without group-based targeting. Applying Rule 002: Similar analysis - no dehumanizing language targeting protected groups, no suggestions of elimination or violence toward groups, and no reinforcement of harmful stereotypes in a hostile context. The text addresses individual attitudes toward disagreement. Applying Rule 003: The language is not metaphorical slurs targeting groups, nor does it suggest elimination, inferiority, or violence toward any protected group. The context is about opinion differences, not group-based hostility. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_203_k0", "example_id": "train_203", "text": "Well this is like exactly how I feel. Except I don't want to be straight.", "label": 0, "reasoning": "Analyzing the text 'Well this is like exactly how I feel. Except I don't want to be straight.' using the provided rulebook: 1) The text contains no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. 2) There is no group targeting - the statement appears to be personal and self-referential about sexual orientation preferences. 3) The phrase 'don't want to be straight' could be interpreted as expressing a personal identity preference rather than hostility toward straight people as a group. 4) Applying Rule 001: No dehumanizing language with hostile intent, no group-based targeting, and the context appears personal/self-referential. 5) Applying Rule 002: No derogatory generalizations about protected groups and no suggestion of elimination, inferiority, or violence toward any group. 6) Applying Rule 003: No metaphorical slurs, no reinforcement of harmful stereotypes in hostile context. The text lacks all key indicators specified in the rules for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_204_k0", "example_id": "train_204", "text": "Don' worry guys men can easily win femmenism ..... Trust me every shit that invented by men was patterned by men .... There is no way women Gina win in future .....it's just smoke before fire", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about women ('femmenism' likely referring to feminism, 'women Gina win in future') and uses dehumanizing language ('shit'). However, it targets women as a gender group with hostile intent, suggesting women cannot win and dismissing feminism as 'smoke before fire' which reinforces harmful stereotypes about women's inferiority. This meets the trigger pattern of derogatory generalizations about a protected group (gender) with hostile context. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis applies - the text uses derogatory language about women as a group with hostile intent. No exceptions apply as it targets a protected group rather than individual behavior. Applying Rule 003: Same conclusion - derogatory group-based language about women with hostile intent, no applicable exceptions. All three rules indicate hate speech due to gender-based derogatory generalizations with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_205_k0", "example_id": "train_205", "text": "Humiliating this Str8 guy. str8 guys like him doing dumb things", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'dumb things' which could be considered derogatory, but it targets 'str8 guys' (straight men) as a group. However, Rule 001 requires dehumanizing terms, derogatory generalizations about protected groups with hostile intent, or violent suggestions combined with group targeting. 'Str8 guys' is not a protected group under typical definitions (racial, gender, religious, national, sexual orientation - straight is a sexual orientation but not typically protected in the same way as LGBTQ+ groups). The language 'dumb things' is offensive but not dehumanizing (like 'pigs' or 'retarded') and lacks suggestions of elimination, inferiority, or violence toward the group. No harmful stereotypes are reinforced in a hostile context beyond mild criticism. Applying Rule 002: Similar analysis - lacks dehumanizing terms, violent suggestions, or clear group-based hostility toward a protected group. Applying Rule 003: Same conclusion - the text does not meet the trigger pattern for dehumanizing or derogatory group-based language with hostile intent. The criticism appears directed at behavior ('doing dumb things') rather than promoting systemic hostility toward straight men as an identity group. Therefore, none of the rules apply to classify this as hate speech (label 1).", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_207_k0", "example_id": "train_207", "text": "Send em home in a metal crate. They're on probation for 20 years. Crime? Straight home. Too many kids? Straight home. Bye.", "label": 0, "reasoning": "Applying Rule 001: The text uses the phrase 'Send em home in a metal crate' which could be interpreted as a violent suggestion. However, it targets individuals ('They're on probation', 'Too many kids?') based on specific behaviors (criminal activity, having too many children) rather than a protected group identity (racial, gender, religious, national, sexual orientation). The language appears to criticize individual actions without invoking group-based hostility or stereotypes about protected groups. The term 'metal crate' might be metaphorical for deportation or strict enforcement, but it doesn't use dehumanizing terms like 'pigs' or 'retarded' against protected groups. Applying Rule 002: Similar analysis - the text lacks derogatory generalizations about protected groups and focuses on individual behavior (criminal violations, probation conditions). No suggestion of elimination, inferiority, or violence toward a protected group is present. Applying Rule 003: The text doesn't contain the specific dehumanizing terms or group targeting described in the trigger patterns. The criticism appears directed at individual circumstances rather than group identity. Therefore, none of the rules apply to classify this as hate speech (label 1).", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_208_k0", "example_id": "train_208", "text": "I think black and white are just labels. People can live together in piece despite colour dismatch", "label": 0, "reasoning": "Applying Rule 001: The text discusses racial labels ('black and white') but does not use dehumanizing terms, derogatory generalizations, or violent suggestions. It promotes harmony ('live together in piece despite colour dismatch') with no hostile intent toward protected groups. No exceptions apply as the context is positive. Applying Rule 002: Similar analysis - no dehumanizing language or group-based hostility present; the text advocates for coexistence. Applying Rule 003: Again, no trigger patterns met - the text uses racial terms descriptively without stereotypes or violence, and context is non-hostile. All rules indicate the text lacks key indicators for hate speech: no slurs, elimination suggestions, inferiority claims, or harmful stereotypes in hostile context.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_209_k0", "example_id": "train_209", "text": "I remember that scene from the X-Files and it made me so mad √∞¬ü¬ò¬° Mulder WHY", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses personal frustration ('made me so mad') about a fictional TV show character using an emoji (√∞¬ü¬ò¬°), with no group targeting or hostile intent toward any protected identity. The frustration is directed at an individual fictional character (Mulder) without reference to group identity. Applying Rule 002: No dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups are present. The comment targets an individual fictional character's actions in a specific scene, not any protected group. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting are present. The language is colloquial frustration directed at an individual character, not metaphorical criticism of group-based entities. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_210_k0", "example_id": "train_210", "text": "Damn that made me laugh!", "label": 0, "reasoning": "Applying Rule 001: The text 'Damn that made me laugh!' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence toward any group, and no reinforcement of harmful stereotypes. The language is colloquial and non-hostile, targeting no specific individual or group. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. There is no criticism of individual behavior linked to protected groups. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The language is not metaphorical criticism of non-group entities and targets no individual with group reference. All rules indicate this is non-hateful speech as it lacks all trigger patterns for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_211_k0", "example_id": "train_211", "text": "The safest most civilised society in the world - Japan - has banned Islam.. coincidence?", "label": 0, "reasoning": "Applying Rule 001: The text references Japan banning Islam, which targets a religious group (Muslims/Islam). However, it uses the phrasing 'coincidence?' which suggests a rhetorical question rather than explicit dehumanizing terms, derogatory generalizations, or violent suggestions. The text lacks indicators like non-literal slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes in a hostile context. It does not contain terms like 'pigs' or 'retarded', nor does it explicitly advocate for harm. The exception for non-group-based criticism applies as the comment appears to reference a policy decision (banning Islam) rather than targeting individuals or promoting group-based hostility. Applying Rule 002 and Rule 003: Similar analysis applies - no dehumanizing language, violent suggestions, or derogatory generalizations about protected groups with hostile intent are present. The text questions a societal action without using hostile language toward Muslims as a group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_212_k0", "example_id": "train_212", "text": "Beware LBGQ community Shari Law is coming you guys will have to go back in closet to save your heads.", "label": 1, "reasoning": "Applying Rule 001: The text targets the 'LBGQ community' (likely meaning LGBTQ) as a protected group based on sexual orientation. It uses threatening language ('Shari Law is coming', 'you guys will have to go back in closet to save your heads') that suggests violence or oppression specifically toward this group. This constitutes derogatory generalizations with hostile intent, suggesting elimination or forced concealment of identity. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Same analysis applies - dehumanizing/threatening language targeting a protected group (LGBTQ community) with hostile intent. Applying Rule 003: Same analysis applies - the text meets all trigger patterns: targets a protected group, uses threatening language suggesting violence/oppression, and reinforces harmful stereotypes in a hostile context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_213_k0", "example_id": "train_213", "text": "I would love to watch tearing apart every christian or muslim", "label": 1, "reasoning": "Applying Rule 001: The text uses violent language ('tearing apart') targeting religious groups ('christian or muslim'), which are protected groups. This suggests elimination/violence toward groups with hostile intent, meeting the trigger pattern. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting individuals without group reference. Applying Rule 002: Same analysis - dehumanizing/violent language targeting protected religious groups with hostile intent. No exceptions for reclaimed use or individual behavior targeting. Applying Rule 003: Same analysis - violent suggestion targeting religious groups with hostile intent. No exceptions for reclaimed use, metaphorical criticism, or individual targeting. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_215_k0", "example_id": "train_215", "text": "SEE THE BLACKS IN PARIS? THEY TRY TO PRETEND THEY ARE FRENCH,  the''men'' want one thing--to pimp out girls and women. The black women desire white men to pretend they are like white french wives but they are Africans. THEY DO NOT BLEND IN WITH WHITE SOCIETY.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about a protected group (Black people) with hostile intent. It uses dehumanizing language ('pimp out girls and women'), reinforces harmful stereotypes about Black men and women, suggests inferiority ('THEY DO NOT BLEND IN WITH WHITE SOCIETY'), and targets the group based on race/national origin. None of the exceptions apply: it's not reclaimed/clinical/satirical context, not metaphorical criticism of non-group entities, and not targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected racial group with hostile intent, suggesting elimination from society ('THEY DO NOT BLEND IN WITH WHITE SOCIETY') and reinforcing harmful stereotypes. No exceptions apply as it's not about individual behavior criticism. Applying Rule 003: The text contains dehumanizing terms and derogatory generalizations about a protected racial group with hostile context, suggesting group-based inferiority and non-assimilation. No exceptions apply as it's not metaphorical or individual-targeted. All three rules indicate hate speech due to group-based dehumanization, derogatory stereotypes, and hostile intent toward Black people as a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_216_k0", "example_id": "train_216", "text": "Finally figured out where that voiceclip came from... I'¬Ä¬ôm so happy", "label": 0, "reasoning": "Applying Rule 001: The text 'Finally figured out where that voiceclip came from... I'm so happy' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The text expresses personal happiness about discovering a voiceclip source, with no hostile context. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent present. The comment is purely personal and positive. Applying Rule 003: Same analysis - no trigger patterns are met. The text contains metaphorical criticism of non-group entities, targets individuals without group reference, or uses reclaimed/satirical contexts. All rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_217_k0", "example_id": "train_217", "text": "I see the depression caused her to gain more weight.", "label": 0, "reasoning": "Analyzing the text 'I see the depression caused her to gain more weight.' against the provided rules: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text mentions 'depression' (a mental health condition) and weight gain, but does not use dehumanizing language like 'pigs' or 'retarded', make derogatory generalizations about people with depression as a group, or suggest violence, elimination, or inferiority. It appears to be an observation about an individual's situation without hostile intent or group-based targeting. No exceptions apply as the text lacks the required trigger patterns. Therefore, none of the rules classify this as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_218_k0", "example_id": "train_218", "text": "and we can all make america grea- ..... make america better", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text 'and we can all make america grea- ..... make america better' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), and no violent suggestions. It appears to be an incomplete or corrected patriotic statement about improving America, with no hostile intent or group-based targeting. The text does not trigger any rule patterns, and none of the exceptions need to be considered since no rule conditions are met. Therefore, it does not qualify as hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_219_k0", "example_id": "train_219", "text": "Whites smoke to much ciggssss and drugs shot those co. Down.. Just say no to drugs kids", "label": 1, "reasoning": "Analyzing the text 'Whites smoke to much ciggssss and drugs shot those co. Down.. Just say no to drugs kids' using the rulebook: Rule 1, 2, and 3 all share similar trigger patterns for hate speech detection, focusing on dehumanizing/derogatory group-based language with hostile intent. The text targets 'Whites' as a racial group, making a derogatory generalization about their drug use ('smoke to much ciggssss and drugs'). The phrase 'shot those co. Down' suggests violent action against this group. This meets key indicators: (1) non-literal slurs or derogatory terms (though 'Whites' itself isn't a slur, the context is derogatory), (2) suggestion of violence toward a group ('shot those... Down'), and (3) reinforcement of harmful stereotypes (linking racial group to excessive drug use). No exceptions apply: this isn't reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets a protected racial group collectively, not individual behavior. The final part 'Just say no to drugs kids' doesn't negate the group-based hostility. Therefore, all relevant rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_220_k0", "example_id": "train_220", "text": "Why do negroes tear down their own neighborhoods when a black thug gets killed by law enforcement? Must be because of low IQ.", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'negroes' which is a derogatory racial slur targeting Black people as a protected group. It makes a derogatory generalization about Black people ('tear down their own neighborhoods') and reinforces harmful stereotypes about low IQ, suggesting group-based inferiority. The context appears hostile, criticizing collective behavior after police incidents. No exceptions apply - this is not reclaimed usage, clinical discussion, satire, or individual targeting. The text targets Black people as a group with dehumanizing language and harmful stereotypes. Applying Rule 002: Same analysis - derogatory group-based language with hostile intent targeting a protected racial group. Applying Rule 003: Same analysis - dehumanizing group-based language with hostile intent. All three rules indicate this meets the criteria for hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_221_k0", "example_id": "train_221", "text": "LILLY SINGH IS A QUEEN! Yay but when will be the next episode", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It praises an individual (Lilly Singh) using positive language ('queen') and asks about a future episode. No group targeting, hostile intent, or harmful stereotypes are present. The exceptions for metaphorical use or individual targeting without group reference do not apply as the text is purely positive. Applying Rule 002: Similar analysis - no dehumanizing language, group-based derogatory generalizations, or violent suggestions targeting protected groups. The text focuses on an individual without promoting hostility toward any identity-based community. Applying Rule 003: Again, no trigger patterns are met - no slurs, elimination suggestions, or reinforcement of harmful stereotypes in hostile context. The text uses celebratory language toward a specific person without group implications. All three rules indicate this is non-hateful speech as it lacks the required elements of dehumanizing group-based language with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_222_k0", "example_id": "train_222", "text": "That fucking black cunt gets fucking cross hairs on the fucking head! Look I owe not shit to anyone who dosent owe me!!! LOOK WHORE!! FUCK YOU TO DEATH!!! 11 PERCENTILE AND FALLING!! WHORE BLACK RACIST WHORE! TAKE THE RED PILL!", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('cunt', 'whore') and derogatory language targeting a protected group based on race ('black'). It includes violent suggestions ('FUCK YOU TO DEATH', 'cross hairs on the fucking head') combined with group targeting ('BLACK RACIST WHORE'). This meets the trigger pattern of using non-literal slurs, suggesting violence toward a group, and reinforcing harmful stereotypes in a hostile context. No exceptions apply as the language is not reclaimed, clinical, historical, or satirical; it directly targets a racial group with hostility. Applying Rule 002: Similar analysis confirms dehumanizing terms and violent suggestions targeting a protected racial group without exceptions for reclaimed or individual behavior contexts. Applying Rule 003: Confirms the same pattern with no applicable exceptions for metaphorical use or individual targeting. The text clearly promotes group-based hostility and violence against a racial group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_223_k0", "example_id": "train_223", "text": "I'm a bisexual but never had sex. I'm 31.", "label": 0, "reasoning": "Applying Rule 001: The text 'I'm a bisexual but never had sex. I'm 31.' contains a reference to a protected group (bisexual as a sexual orientation). However, it lacks dehumanizing terms, derogatory generalizations, or violent suggestions. The statement is self-referential and factual, not hostile. It does not suggest elimination, inferiority, or violence toward any group, nor reinforce harmful stereotypes. The context is personal disclosure, not criticism or promotion of hate. Exceptions apply as it is self-referential and non-hostile. Applying Rule 002: Similar analysis - no dehumanizing language, group targeting with hostile intent, or violent suggestions. The text does not target a protected group derogatorily but rather self-identifies. Applying Rule 003: Again, no indicators of hate speech - no slurs, elimination suggestions, or hostile stereotypes. The statement is neutral and personal. All rules indicate the text is non-hateful as it lacks the required elements of dehumanization, derogatory generalization, or hostile intent toward a group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_224_k0", "example_id": "train_224", "text": "These people do not represent Islam!!", "label": 0, "reasoning": "Applying Rule 001: The text 'These people do not represent Islam!!' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. It targets 'these people' as individuals without specifying their group identity, and it defends Islam rather than promoting hostility toward it. The exception for non-group-based targeting applies. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations, or violent suggestions toward a protected group. It criticizes individuals ('these people') without linking them to a broader protected group or promoting group-based hostility. The exception for targeting individual behavior applies. Applying Rule 003: Similar to Rules 001 and 002, the text does not trigger the pattern as it uses no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. It metaphorically criticizes individuals ('these people') without reference to group identity, falling under the exception. Overall, the text is defensive of Islam and targets specific individuals, not a protected group, with no hostile intent or harmful stereotypes.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_225_k0", "example_id": "train_225", "text": "Depends on whether or not Ryan Reynolds is in the room", "label": 0, "reasoning": "Applying Rule 001: The text 'Depends on whether or not Ryan Reynolds is in the room' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The text appears to be a humorous or conversational statement about actor Ryan Reynolds, with no hostile intent or group-based targeting. All exceptions in Rule 001 apply - this is not hate speech. Applying Rule 002: The text lacks dehumanizing language, group targeting, and hostile intent toward protected groups. It focuses on an individual celebrity without invoking group identity or promoting stereotypes. Applying Rule 003: The text contains no slurs, suggestions of elimination/violence, or reinforcement of harmful stereotypes. It is metaphorical only in a non-group context (referring to Ryan Reynolds' presence), with no protected group targeting. All three rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_226_k0", "example_id": "train_226", "text": "Much love to you, thank you for your courage. Keep speaking your truth", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text 'Much love to you, thank you for your courage. Keep speaking your truth' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), and no violent suggestions (e.g., 'gas yourself'). It expresses positive sentiment with phrases like 'much love', 'thank you', and 'courage', and encourages the recipient to 'keep speaking your truth'. There is no indication of group targeting, hostile intent, or reinforcement of harmful stereotypes. Therefore, none of the rules trigger, and the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_227_k0", "example_id": "train_227", "text": "Germans need to quit blaming themselves for the atrocities committed by the Nazi's. The same thing (shame) is happening here in the U.S. because of the past because of slavery and \"stealing\" the land from the Indians. People are getting sick of hearing that shit and the left is constantly saying how bad \"white\" Americans are.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes collective guilt narratives and expresses frustration with political rhetoric, but does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It mentions 'Germans', 'white Americans', and historical groups, but these references are contextual discussions of historical responsibility rather than hostile group targeting. The language 'getting sick of hearing that shit' expresses frustration but targets political discourse rather than protected groups. No exceptions apply as there is no group-based dehumanization or violence suggestion. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations with hostile intent, or violent suggestions toward protected groups. The text discusses historical narratives without promoting group-based inferiority or violence. Applying Rule 003: Again, no trigger patterns present. The text uses descriptive language about historical events and political criticism without metaphorical slurs, elimination suggestions, or harmful stereotypes in a hostile context. All rules indicate this is not hate speech under their definitions.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_229_k0", "example_id": "train_229", "text": "You really think that European People will like you if you humiliate Muslims? I think that's a big mistake because you're an Indian. I mean, they don' like you either so don' try to look cute. By the way, your accent sucks terribly my friend.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language targeting Muslims as a religious group ('humiliate Muslims') and Indians as a national/ethnic group ('you're an Indian', 'they don't like you either'). This constitutes group-based targeting of protected groups (religious and national). The language suggests inferiority ('your accent sucks terribly') and hostility ('don't try to look cute'). No exceptions apply - this is not reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities or targeting of specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about Muslims and Indians with hostile intent, suggesting these groups are disliked and inferior. No exception applies as this targets protected groups rather than individual behavior. Applying Rule 003: The text contains derogatory group-based language targeting Muslims and Indians with hostile context, including suggestions of dislike and inferiority. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_230_k0", "example_id": "train_230", "text": "There was one facility opened in the US to provide shelter for abused men. Feminist protested until it was closed. Now there are none.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes feminists for protesting against a men's shelter, but does not use dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The target appears to be feminists as a group, but feminists are not a protected group based on immutable characteristics like race, gender, religion, national origin, or sexual orientation - they are individuals who advocate for gender equality. The language is factual reporting of events without hostile intent, non-literal slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The criticism targets feminists' actions regarding a specific facility, not a protected group identity. Applying Rule 003: Same conclusion - the text lacks the trigger patterns of dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The statement presents information without the hostile context indicators specified in all three rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_231_k0", "example_id": "train_231", "text": "I don't care what people say these two fuckers are lying,the Facts are stacked against them I hope they going to pay for this smere campaign", "label": 0, "reasoning": "Applying Rule 001: The text uses offensive language ('fuckers') and expresses hostility ('I hope they going to pay'), but targets specific individuals ('these two') without reference to any protected group identity (racial, gender, religious, national, sexual orientation). The criticism is directed at perceived individual behavior ('lying', 'smere campaign') rather than making derogatory generalizations about a group. No dehumanizing terms, violent suggestions toward groups, or reinforcement of harmful stereotypes are present. The exception for 'target is an individual without reference to group identity' applies. Applying Rule 002: Similar analysis - the language targets individual behavior without group-based hostility. Applying Rule 003: The offensive language is directed at specific individuals, not a protected group, so the exception for individual targeting applies. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_232_k0", "example_id": "train_232", "text": "STOP PUTTING THIS IN MY RECOMMEND WTF I'M NOT GAY", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'gay' in a negative context ('STOP PUTTING THIS IN MY RECOMMEND WTF I'M NOT GAY'), which could be interpreted as derogatory toward a protected group (sexual orientation). However, examining the exceptions: (1) The language appears to be self-referential ('I'M NOT GAY') rather than targeting a broader group, (2) There is no suggestion of elimination, inferiority, or violence toward LGBTQ+ people as a group, (3) The hostility seems directed at content recommendations rather than at gay people as a protected class. The text lacks group-based targeting or reinforcement of harmful stereotypes about gay people. Applying Rule 002 and Rule 003 yields similar analysis: While the term 'gay' is used negatively, the comment targets individual identity denial ('I'M NOT GAY') rather than making derogatory generalizations about gay people as a group. No dehumanizing language, violent suggestions, or group-based hostility are present. The text expresses frustration with algorithmic recommendations, not hate toward a protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_233_k0", "example_id": "train_233", "text": "Terrorism has no religion Terrorism is a cancer need to be wipe out. RIP to all victims", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'cancer' metaphorically to describe terrorism, not targeting any protected group. Terrorism is an ideology/action, not a protected identity group. The statement 'Terrorism has no religion' explicitly separates terrorism from religious groups. The phrase 'need to be wipe out' refers to eliminating terrorism as a concept, not targeting people based on protected characteristics. No dehumanizing terms targeting protected groups, no derogatory generalizations about protected groups, and no violent suggestions toward protected groups are present. The context is condemning terrorism and expressing sympathy for victims. Applying Rule 002: Similar analysis - no dehumanizing language targeting protected groups, no group-based hostility. The criticism is directed at terrorism as a phenomenon, not at protected identity groups. Applying Rule 003: The metaphorical use of 'cancer' targets terrorism (an ideology/action), not a protected group. No indicators of non-literal slurs, elimination suggestions toward groups, or reinforcement of harmful stereotypes about protected groups in hostile context. All rules indicate this does not meet hate speech criteria as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_234_k0", "example_id": "train_234", "text": "Disability centres all around the world. That’s were our money goes. Let’s take em down", "label": 1, "reasoning": "Applying Rule 001: The text mentions 'Disability centres all around the world' which refers to a protected group (people with disabilities). The phrase 'Let's take em down' suggests elimination or violent action toward these centers and by extension the people they serve. This constitutes group targeting with hostile intent. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory targeting of disability centers (representing a protected group) with elimination language ('take em down'), indicating hostile intent toward people with disabilities as a group. Applying Rule 003: The text targets disability centers globally, representing a protected group, with language suggesting elimination ('take em down'), meeting the trigger pattern for dehumanizing or derogatory group-based language with hostile intent. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_236_k0", "example_id": "train_236", "text": "ABU DA BI ABA DU BA BA HAMUD! See? I’m an arab priest too. This is how they sound. right? They are jokes", "label": 1, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text contains derogatory language about Arab people ('ABU DA BI ABA DU BA BA HAMUD!') presented in a mocking manner, followed by 'They are jokes' which constitutes a derogatory generalization about a protected national/ethnic group (Arab people). This meets the trigger patterns of all three rules: (1) uses non-literal/mocking language that reinforces harmful stereotypes, (2) suggests inferiority ('They are jokes'), and (3) targets a protected group based on national/ethnic identity. The context is hostile and mocking rather than reclaimed, clinical, historical, or satirical critique. No exceptions apply as this is not self-referential, metaphorical criticism of non-group entities, or targeting of individual behavior without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_237_k0", "example_id": "train_237", "text": "IM GAY AND FUCKING PROUD FUCK BITCHES LIKE THESE PEOPLE", "label": 0, "reasoning": "Applying Rule 001: The text contains offensive language ('FUCK BITCHES') but targets 'THESE PEOPLE' without specifying a protected group identity. The phrase 'THESE PEOPLE' appears to refer to unspecified individuals rather than making derogatory generalizations about a protected group based on race, gender, religion, national origin, or sexual orientation. The speaker identifies as gay ('IM GAY AND FUCKING PROUD'), which could suggest the target might be homophobic individuals, but the language doesn't dehumanize or target a protected group with hostile intent. The offensive language is directed at unspecified individuals without invoking group-based hostility or stereotypes. Applying Rule 002: Similar analysis - while containing offensive language, the text lacks dehumanizing terms targeting protected groups or suggestions of elimination, inferiority, or violence toward a group. The criticism appears directed at unspecified individuals ('THESE PEOPLE') rather than a protected group. Applying Rule 003: The text doesn't use dehumanizing terms like 'pigs' or 'retarded' in combination with group targeting. The phrase 'FUCK BITCHES' is offensive but targets unspecified individuals, not a protected group with hostile intent. The speaker's self-identification as gay doesn't constitute hate speech against others. No protected group is targeted with derogatory generalizations or violent suggestions.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_238_k0", "example_id": "train_238", "text": "Im very glad to have friends", "label": 0, "reasoning": "Applying Rule 001: The text 'Im very glad to have friends' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses personal gratitude without any group targeting, hostile intent, or harmful stereotypes. No exceptions apply as there is no offensive language present. Applying Rule 002: The text lacks dehumanizing language, group-based targeting, and hostile intent. It focuses on personal relationships without targeting any protected groups or promoting hostility. Applying Rule 003: The text contains no slurs, suggestions of elimination or violence, or reinforcement of harmful stereotypes. It is a positive personal statement without metaphorical criticism or group references. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_239_k0", "example_id": "train_239", "text": "Lady Gaga is the Freddie Mercury of our generation", "label": 0, "reasoning": "Applying Rule 001: The text 'Lady Gaga is the Freddie Mercury of our generation' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes a positive comparison between two musicians without targeting any racial, gender, religious, national, or sexual orientation group. The language is complimentary and artistic in nature. No exceptions need to be considered as the rule doesn't trigger. Applying Rule 002: The text contains no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. It's a cultural comparison between individual artists without group-based hostility. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It's a metaphorical comparison between two musicians that doesn't target any protected group identity. The comparison is positive and artistic rather than hostile. All three rules indicate this text doesn't meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_242_k1", "example_id": "train_242", "text": "This cop had to get him under arrest for walking like that freely out in public. Problematics must be stay home locked. Sue her parents.", "label": 0, "reasoning": "Applying Rule 001: The text contains the term 'Problematics' which appears to be a derogatory generalization targeting a group, potentially referring to people with problematic behavior. However, examining the context: (1) The text criticizes an individual ('him') for specific behavior ('walking like that freely out in public'), (2) The term 'Problematics' seems to refer to individuals with problematic behavior rather than a protected group based on race, gender, religion, national origin, or sexual orientation, (3) There is no clear dehumanizing language like 'pigs' or 'retarded', (4) The suggestion to 'stay home locked' targets behavior management rather than elimination or violence toward a protected group identity. Applying Rule 002: Similar analysis applies - the criticism appears directed at individual behavior ('walking like that') without targeting a protected group. The term 'Problematics' lacks clear connection to protected group characteristics. Applying Rule 003: The language does not contain the specific dehumanizing terms or violent suggestions mentioned in the trigger patterns. The context suggests criticism of individual behavior and parental responsibility rather than group-based hostility. All three rules indicate this does not meet the criteria for hate speech as it targets individual behavior without protected group targeting or dehumanizing language with hostile intent toward a protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_243_k0", "example_id": "train_243", "text": "no fucking way a machine would recognize that shit LOL", "label": 0, "reasoning": "Analyzing the text 'no fucking way a machine would recognize that shit LOL' against the rulebook: Rule 1, Rule 2, and Rule 3 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. The text contains profanity ('fucking', 'shit') but no dehumanizing terms like 'pigs' or 'retarded', no references to any protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. The context appears to be a casual expression of disbelief about machine recognition capabilities, not targeting any group or promoting hostility. All rules include exceptions for non-group-based criticism or individual targeting, which applies here as the criticism is directed at machine capabilities, not people or protected groups. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_244_k0", "example_id": "train_244", "text": "Some of the lyrics are wrong", "label": 0, "reasoning": "Applying Rule 001: The text 'Some of the lyrics are wrong' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The text appears to be a neutral statement about lyrics without any hostile intent or reference to protected groups. Applying Rule 002: Same analysis - no dehumanizing language, no group-based derogatory generalizations, no violent suggestions, and no group targeting. The text lacks all key indicators mentioned in the rule. Applying Rule 003: Same analysis - no trigger patterns are present. The text is a simple statement about lyrics being wrong, with no metaphorical slurs, elimination suggestions, or group-based hostility. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_245_k0", "example_id": "train_245", "text": "Trans people=gays and loosers", "label": 1, "reasoning": "Applying the rules from the rulebook: Rule 001, Rule 002, and Rule 003 all define hate speech as involving dehumanizing or derogatory group-based language with hostile intent, targeting protected groups such as racial, gender, religious, national, or sexual orientation groups. The text 'Trans people=gays and loosers' includes derogatory terms ('loosers', likely a misspelling of 'losers') and links 'Trans people' to 'gays', which are protected groups based on gender identity and sexual orientation. This constitutes a derogatory generalization that reinforces harmful stereotypes (e.g., implying inferiority or negative traits) in a hostile context, as it groups and insults these identities without nuance. There is no indication of reclaimed, clinical, historical, or satirical context, nor is it metaphorical or targeting individuals without group reference. Therefore, all relevant rules trigger, and no exceptions apply.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_246_k0", "example_id": "train_246", "text": "Everyone hates you because you're gay", "label": 1, "reasoning": "Applying Rule 001: The text 'Everyone hates you because you're gay' contains derogatory language targeting a protected group (sexual orientation - gay individuals). It makes a generalization ('Everyone hates you') that reinforces harmful stereotypes about hostility toward gay people, suggesting group-based inferiority or social rejection. This meets the trigger pattern of derogatory generalizations about a protected group with hostile intent. No exceptions apply: it's not reclaimed/self-referential (targets 'you' not self), not clinical/historical/satirical, not metaphorical criticism of non-group entities, and clearly targets group identity rather than individual behavior alone. Applying Rule 002: Same analysis applies - derogatory generalization about protected group (sexual orientation) with hostile context. Applying Rule 003: Same analysis applies - derogatory language targeting protected group with hostile intent. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_248_k0", "example_id": "train_248", "text": "destroy islam", "label": 1, "reasoning": "Applying Rule 001: The text 'destroy islam' contains a violent suggestion ('destroy') targeting a religious group ('islam'), which is a protected group. This meets the trigger pattern of suggesting elimination or violence toward a group with hostile intent. There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it. The target is explicitly group-based (Islam as a religion/religious community), not individual behavior or non-group entities. Applying Rule 002: The text uses violent language ('destroy') directed at a protected religious group, fulfilling the trigger pattern of violent suggestions with group targeting. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: Similar analysis applies - violent suggestion targeting a protected group without metaphorical use or individual targeting. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_249_k3", "example_id": "train_249", "text": "Fucking Canada...stupid. I think the cold shrinks their brains.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('stupid') and makes a generalization about people from Canada ('their brains'), suggesting inferiority. However, Canada as a nationality is a protected group under the rules. The language is hostile ('Fucking Canada') and makes a group-based generalization about intelligence. No exceptions apply - it's not reclaimed, clinical, historical, or satirical; not metaphorical criticism of non-group entities; and targets the group collectively rather than specific individuals. Applying Rule 002: Similar analysis - uses derogatory language with group targeting (Canadians) and suggests inferiority ('cold shrinks their brains'), indicating hostile intent toward the group. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: Same pattern - dehumanizing suggestion about intelligence ('shrinks their brains') targeting a national group with hostile language. All three rules indicate this meets the criteria for hate speech due to derogatory group-based language with hostile intent targeting a protected group (nationality).", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_250_k0", "example_id": "train_250", "text": "Islam is  the home of terriorism .", "label": 1, "reasoning": "Applying Rule 001: The text 'Islam is the home of terrorism' makes a derogatory generalization about a protected religious group (Islam/Muslims). It suggests that terrorism is inherent to the religion, which reinforces harmful stereotypes about Muslims as a group. This meets the trigger pattern of 'derogatory generalizations about a protected group' with hostile intent by linking an entire religion to terrorism. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's a direct group-based generalization. Applying Rule 002: The text uses derogatory language about a protected religious group (Islam) by associating it with terrorism, which suggests inferiority and reinforces harmful stereotypes in a hostile context. No exceptions apply as this is not targeting individual behavior. Applying Rule 003: The text contains derogatory generalizations about a protected religious group (Islam) by claiming it is 'the home of terrorism,' which suggests group-based inferiority and reinforces harmful stereotypes. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this is hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_251_k0", "example_id": "train_251", "text": "America is the greatest country. That aint lie you know that I know that", "label": 0, "reasoning": "Applying Rule 001: The text 'America is the greatest country. That aint lie you know that I know that' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses positive sentiment about a country without targeting any racial, gender, religious, national, or sexual orientation group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. Applying Rule 002: The text lacks dehumanizing language or group-based targeting. It praises America without making derogatory comparisons to other groups. Applying Rule 003: The text uses no metaphorical slurs or group targeting. It's a straightforward expression of national pride without hostility toward any protected group. All three rules indicate this is non-hateful as it contains no protected group targeting, dehumanizing language, or hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_253_k0", "example_id": "train_253", "text": "Can' you all see how absurd it is? Calling all white people racist, calling all black people criminals, it's all the same. Why does race even matter? Why can' we judge terrible people not terrible white people?", "label": 0, "reasoning": "Applying Rule 001: The text criticizes generalizations about racial groups ('calling all white people racist, calling all black people criminals') but does so to argue against racial stereotyping and promote individual judgment ('judge terrible people not terrible white people'). It uses no dehumanizing terms, violent suggestions, or derogatory language targeting protected groups. The context is anti-stereotyping rather than promoting group-based hostility. Applying Rule 002: The text mentions racial groups but in a context that critiques racial generalizations, not with hostile intent toward any group. It lacks dehumanizing language, violent suggestions, or reinforcement of harmful stereotypes. Applying Rule 003: Similar analysis - the text discusses racial groups but in a manner that argues against group-based judgments, using no slurs, elimination rhetoric, or hostile stereotypes. The exception for criticism of group-based thinking applies here as the text promotes individual assessment over racial generalizations.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_254_k0", "example_id": "train_254", "text": "The next time I like up in front of one like him I will shout to his left ear that he is a trash and worthless! HAHAHHAA. I know I’m a bad man. IM BADMAN", "label": 0, "reasoning": "Applying Rule 001: The text contains offensive language ('trash and worthless') directed at an individual ('him'), but does not use dehumanizing terms targeting a protected group, make derogatory generalizations about a group, or suggest violence toward a group. The target appears to be a specific individual without reference to group identity (e.g., race, gender, religion). The speaker's self-description as 'a bad man' suggests individual hostility rather than group-based animus. No protected group is mentioned or implied. Exceptions apply as this is non-generalizing language directed at a specific individual without invoking group-based hostility. Applying Rule 002: Similar analysis - the text lacks group targeting, dehumanizing group-based language, or suggestions of elimination/inferiority toward a protected group. The criticism appears directed at individual behavior/character. Applying Rule 003: Same conclusion - the language targets an individual without group reference, and the metaphorical use of 'trash' criticizes an individual rather than a protected group entity. All rules indicate this does not meet the threshold for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_255_k0", "example_id": "train_255", "text": "My parents are homophobes. :(", "label": 0, "reasoning": "Applying Rule 001: The text 'My parents are homophobes. :(' expresses personal disappointment about parents' attitudes toward LGBTQ+ individuals. It does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The term 'homophobes' criticizes specific individuals (the parents) for their views, not a protected group. This falls under the exception for language targeting individuals without reference to group identity or promoting group-based hostility. Applying Rule 002: The text lacks dehumanizing language, group targeting, or hostile intent toward a protected group. It criticizes individual behavior (parents' homophobia) without making derogatory generalizations about any group. Applying Rule 003: Similar to Rule 001, the text does not trigger the rule as it targets specific individuals metaphorically (describing attitudes) rather than a protected group with hostile intent. No rules indicate hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_256_k0", "example_id": "train_256", "text": "Hope you fucking die bitches gay people should not exist all you do is lick one another's ass", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('fucking die'), derogatory generalizations about a protected group (gay people), and violent suggestions ('should not exist'). It targets a protected group (sexual orientation) with hostile intent, suggesting elimination and using offensive stereotypes ('all you do is lick one another's ass'). None of the exceptions apply: it's not reclaimed/clinical/satirical context, not metaphorical criticism of non-group entities, and not targeting individual behavior without group reference. Applying Rule 002: Same analysis applies - dehumanizing language targeting a protected group with hostile intent. Applying Rule 003: Same analysis applies - all three key indicators are present: (1) non-literal slurs ('bitches'), (2) suggestion of elimination ('should not exist'), (3) reinforcement of harmful stereotypes in hostile context. No exceptions apply as this is direct group-based hostility.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_257_k0", "example_id": "train_257", "text": "One people. One nation. End migration.", "label": 0, "reasoning": "Applying Rule 001: The text 'One people. One nation. End migration.' contains language that could be interpreted as promoting exclusion of migrants, which might target a national or ethnic group. However, it does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations, or violent suggestions as specified in the trigger pattern. The phrase lacks explicit group-based hostility, elimination rhetoric, or reinforcement of harmful stereotypes in a hostile context. It expresses a political stance on migration policy without targeting a protected group with derogatory language. Applying Rule 002: Similar analysis applies—no dehumanizing terms, derogatory generalizations, or violent suggestions are present. The text does not meet the key indicators of non-literal slurs, suggestion of elimination/inferiority/violence toward a group, or hostile stereotype reinforcement. Applying Rule 003: Again, no dehumanizing terms, derogatory generalizations, or violent suggestions are used. The language is not metaphorical in a way that criticizes a protected group, and there is no clear reference to group identity with hostile intent. The text advocates for ending migration but does so in a slogan-like manner without explicit hate speech elements as defined by the rules. All rules emphasize exceptions for non-hostile contexts or lack of group targeting; here, the absence of specific derogatory language places it outside the trigger patterns.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_259_k0", "example_id": "train_259", "text": "Michael Jackson sick man and sick fans.", "label": 0, "reasoning": "Applying Rule 001: The text 'Michael Jackson sick man and sick fans' contains the term 'sick' used derogatorily, but it targets specific individuals (Michael Jackson and his fans) rather than a protected group based on race, gender, religion, national origin, or sexual orientation. There is no dehumanizing language (e.g., 'pigs', 'retarded'), no suggestion of elimination, inferiority, or violence toward a group, and no reinforcement of harmful stereotypes in a hostile context. The criticism appears directed at individual behavior/character without invoking group-based hostility. Applying Rule 002: Similar analysis - the text lacks group targeting of protected groups and does not use dehumanizing terms or violent suggestions toward such groups. The derogatory language targets specific individuals (Michael Jackson and his fans) rather than making generalizations about a protected identity group. Applying Rule 003: Again, the text targets individuals (a specific celebrity and his fans) without reference to protected group identity. The term 'sick' is used metaphorically to criticize individuals, not a protected group, and there is no evidence of hostile intent toward a protected group. All three rules indicate this should be classified as non-hateful (0) because it targets individuals without group-based hostility toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_260_k0", "example_id": "train_260", "text": "I just love hypocrisy. Am I sick?", "label": 0, "reasoning": "Applying Rule 001: The text 'I just love hypocrisy. Am I sick?' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The term 'sick' is used in a self-referential, colloquial manner to question one's own enjoyment of hypocrisy, not to dehumanize or derogate a protected group. There is no hostile intent, group targeting, or reinforcement of harmful stereotypes. The exceptions in Rule 001 apply as the language is non-group-based and directed at the individual speaker without invoking group-based hostility. Applying Rule 002: No dehumanizing terms or derogatory generalizations about protected groups are present. The comment is self-focused and does not target any group with hostile intent. Applying Rule 003: Similar analysis as Rule 001 - no group targeting, dehumanizing language, or violent suggestions. The self-referential use of 'sick' falls under exceptions for non-group-based individual expression. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_261_k0", "example_id": "train_261", "text": "You look like someone who would do an electric wheelchair race with Stephen Hawking.", "label": 0, "reasoning": "Applying Rule 001: The text uses 'electric wheelchair race with Stephen Hawking' which could potentially reference disability, but it targets an individual ('you') without making derogatory generalizations about people with disabilities as a protected group. There is no dehumanizing language, violent suggestions, or reinforcement of harmful stereotypes toward a group. The context appears to be a metaphorical or humorous comparison to an individual's appearance or behavior, not group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment targets individual characteristics without promoting generalized hostility toward people with disabilities. Applying Rule 003: The language is metaphorical (comparing someone's appearance to a hypothetical scenario) and targets an individual without reference to group identity. No indicators of elimination, inferiority, or violence toward a group. All three rules indicate this does not meet the criteria for hate speech due to individual targeting, metaphorical use, and absence of group-based derogatory language with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_262_k0", "example_id": "train_262", "text": "Her smile is SO beautiful omg! Continue being who you are!", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It praises an individual ('Her smile is SO beautiful') and offers encouragement ('Continue being who you are!') without any group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is positive and individual-focused. Applying Rule 002: No dehumanizing language, group-based derogatory generalizations, or violent suggestions are present. The comment targets an individual with praise, not a protected group. Applying Rule 003: No trigger patterns are met - no slurs, elimination suggestions, or group-based hostility. The text is complimentary and supportive toward an individual. All rules indicate this is non-hateful speech as it lacks all key indicators of hate speech: no protected group targeting, no dehumanizing language, no violent suggestions, and positive intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_263_k0", "example_id": "train_263", "text": "What a wonderful Angel wife. She is sooo beautiful inside and out. And he is very nice man too. This lady and a lady she is , has the most beautiful laughter i have ever heard in my whole life. This couple is what love is made of. Thankyou for this wonderful video.", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It praises individuals without any group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is positive and complimentary. Applying Rule 002: No dehumanizing language, group-based targeting, or hostile intent is present. The text focuses on individual appreciation without any derogatory content. Applying Rule 003: The text lacks all trigger patterns including dehumanizing terms, group targeting, and hostile context. It expresses admiration for specific individuals in a positive manner. All rules indicate this is non-hateful speech as it contains no elements that would trigger hate speech classification under any of the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_264_k0", "example_id": "train_264", "text": "Should have been sterilised upon arrival. Now your future doesn't exist.", "label": 0, "reasoning": "Applying Rule 001: The text uses language suggesting elimination ('should have been sterilised') and implies a negative future outcome ('Now your future doesn't exist'). However, it lacks clear group targeting - it doesn't specify any protected group (racial, gender, religious, national, or sexual orientation). The target appears to be an individual ('your') without reference to group identity. According to Rule 001 exceptions, this rule does not apply when 'the target is an individual without reference to group identity.' Applying Rule 002: Similar analysis - the text contains elimination language but lacks group targeting toward a protected group. The exception about targeting individual behavior applies here. Applying Rule 003: Again, while the language suggests elimination ('sterilised'), it targets an individual ('your') without group reference, falling under the exception for individual targeting. None of the rules trigger because all require combination with group targeting toward protected groups, which is absent in this text.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_265_k0", "example_id": "train_265", "text": "Look at these gay ass niggas. lol. Acting like they some bitches.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory terms ('gay ass niggas', 'bitches') targeting sexual orientation and racial groups. It uses group-based generalizations ('these gay ass niggas') with hostile intent through demeaning language ('Acting like they some bitches'), reinforcing harmful stereotypes about LGBTQ+ individuals and Black people. No exceptions apply - the language is not reclaimed (uses slurs from an outsider perspective), not clinical/historical/satirical critique, and directly targets protected groups rather than individual behavior or non-group entities. Applying Rule 002: Same analysis - dehumanizing/derogatory group-based language with hostile intent targeting protected groups (sexual orientation, race). No exception for individual behavior targeting applies. Applying Rule 003: Same analysis - derogatory group-based language with hostile intent, no applicable exceptions. All three rules indicate hate speech due to: (1) use of slurs targeting protected groups, (2) suggestion of inferiority through demeaning comparisons, (3) reinforcement of harmful stereotypes in hostile context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_266_k0", "example_id": "train_266", "text": "lesbians cant do math fucking mood lmao", "label": 1, "reasoning": "Analyzing the text 'lesbians cant do math fucking mood lmao' against the rulebook: 1. The text targets 'lesbians' as a group based on sexual orientation (a protected group). 2. It makes a derogatory generalization ('cant do math') that reinforces harmful stereotypes about intellectual ability. 3. The language includes profanity ('fucking') and dismissive tone ('lmao') indicating hostile context rather than reclaimed or satirical critique. 4. No exceptions apply: This is not self-referential, clinical, historical, or targeting individual behavior without group reference. The text promotes group-based inferiority through stereotyping. Therefore, Rule 001, Rule 002, and Rule 003 all trigger as it uses derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_267_k0", "example_id": "train_267", "text": "What about a global massacre of men? Pussiezzz only girls", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('pussiezzz' as a derogatory term for men) and suggests a 'global massacre of men', which implies elimination/violence toward a gender-based group. This meets the trigger pattern of dehumanizing/derogatory language with violent suggestions toward a protected group (gender). No exceptions apply: it's not reclaimed/satirical context, not metaphorical criticism of non-group entities, and clearly targets men as a group rather than specific individuals. Applying Rule 002: Same analysis applies - derogatory generalization about a gender group with violent suggestion. Applying Rule 003: Same analysis applies - dehumanizing language with violent suggestion toward a protected group. All three rules indicate hate speech due to group-targeting violent suggestion combined with derogatory language.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_268_k0", "example_id": "train_268", "text": "I have started writing a book.", "label": 0, "reasoning": "Applying Rule 001: The text 'I have started writing a book' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The text is a neutral statement about personal activity. Applying Rule 002: The text contains no dehumanizing language, group-based targeting, or hostile intent toward any protected group. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, violent suggestions, or group targeting. All rules indicate this text does not meet any trigger patterns for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_269_k0", "example_id": "train_269", "text": "Syria war is over they can go back its safe now.", "label": 0, "reasoning": "Applying Rule 001: The text 'Syria war is over they can go back its safe now' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It makes a factual claim about the Syrian war ending and suggests return is safe, without targeting any racial, gender, religious, national, or sexual orientation group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The text is neutral and informational, lacking hostile intent or group-based targeting. Applying Rule 002: Similar analysis applies - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The comment does not criticize individual behavior in a way that stigmatizes a protected group. Applying Rule 003: Again, no trigger patterns are met - the language is literal and factual, not metaphorical or slur-based, and targets no group identity. All rules indicate this is non-hateful speech as it lacks the required elements of dehumanizing language, group targeting, and hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_270_k0", "example_id": "train_270", "text": "The fear of approaching a girl while not being a lesbian is so real. You're spot on. You want to be flirty and everything but at the back of your head you always have \"what if she's not cool with me not being a lesbian\". I'm pan, but I kinda gave up on relationships with women (both born women and trans women) quite some time ago, because the amount of \"you're gonna leave me for a guy\", or constant \"are you sure you like girls and it's not a phase?\" or \"I can' be with someone who is not true to themselves (as in I'm actually a lesbian but I don' want to admit it)\" and other bs was just too much. They were never worried about another woman btw, it was always either about men or questioning validity of my sexuality. It's really quite sad, because other than that each of my exes were really strong, confident women. Except when it was about my sexuality.", "label": 0, "reasoning": "Applying Rule 001: The text discusses personal experiences with relationships and sexuality, using terms like 'lesbian', 'pan', 'trans women', and 'women' in a descriptive, non-derogatory manner. There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The author expresses frustration with specific behaviors ('you're gonna leave me for a guy', questioning validity of sexuality) but targets individual experiences and attitudes rather than making hostile generalizations about lesbians, pansexual people, or women as protected groups. The context is personal reflection, not promoting group-based inferiority or violence. Applying Rule 002: Similar analysis applies—no dehumanizing language or group-based hostility is present. The criticism is directed at individual behaviors and attitudes in relationships, not at protected groups with intent to dehumanize or promote violence. Applying Rule 003: The language is not metaphorical slurs or suggestions of elimination toward groups. The text describes personal relationship challenges without targeting group identities in a hostile context. All rules indicate the text does not meet the trigger patterns for hate speech, as it lacks dehumanizing terms, derogatory generalizations about protected groups, violent suggestions, and hostile intent toward groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_272_k0", "example_id": "train_272", "text": "The mountain is near the black sea, no wonder we are called caucasian", "label": 0, "reasoning": "Applying Rule 001: The text 'The mountain is near the black sea, no wonder we are called caucasian' contains the term 'caucasian' which refers to a racial group. However, this appears to be a factual or descriptive statement about geographic origins of the term 'Caucasian' rather than using dehumanizing language, derogatory generalizations, or violent suggestions with hostile intent. The term is used in a neutral, descriptive context without indicators of (1) non-literal/metaphorical slurs, (2) suggestions of elimination/inferiority/violence toward the group, or (3) reinforcement of harmful stereotypes in hostile context. No exceptions apply as this is not reclaimed, clinical, historical, or satirical context but rather appears to be a neutral observation. Applying Rule 002: Similar analysis - the text lacks dehumanizing terms, derogatory generalizations about protected groups with hostile intent, or violent suggestions. The reference to 'caucasian' is descriptive rather than derogatory. Applying Rule 003: Same conclusion - the text does not trigger the pattern of dehumanizing or derogatory group-based language with hostile intent. The language is factual/geographic rather than metaphorical criticism of non-group-based entities or individual targeting. Therefore, none of the rules indicate hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_273_k0", "example_id": "train_273", "text": "I would order a bucket of ice cold water so I can pour it on him", "label": 0, "reasoning": "Analyzing the text 'I would order a bucket of ice cold water so I can pour it on him' against the provided rulebook: Rule 001, 002, and 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text mentions pouring ice cold water on 'him' (an individual), but contains no dehumanizing language (e.g., 'pigs', 'retarded'), no references to protected groups (racial, gender, religious, national, sexual orientation), no violent suggestions beyond a prank-like action, and no group-based targeting or hostile intent toward a protected class. The action described could be interpreted as aggressive but targets an individual without invoking group identity or promoting stereotypes. According to exceptions in all rules: when language targets an individual without reference to group identity or uses metaphorical criticism of non-group entities, the rules do not apply. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_274_k0", "example_id": "train_274", "text": "As having friends whom are part of the LGBT+ community and being a supporter of them and I think this is awsome and in middle school", "label": 0, "reasoning": "Applying Rule 001: The text expresses support for the LGBT+ community ('being a supporter of them') and describes this as 'awsome' (likely 'awesome'). There is no dehumanizing language, derogatory generalizations, violent suggestions, or group targeting with hostile intent. The language is positive and supportive. No exceptions apply as this is clearly not hate speech. Applying Rule 002: Same analysis - no trigger patterns present. The text lacks dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses personal support rather than hostility. Applying Rule 003: Same analysis - no indicators of hate speech. The text describes personal relationships and support for the LGBT+ community without any hostile context, stereotypes, or targeting. All rules consistently indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_275_k0", "example_id": "train_275", "text": "Love the videos", "label": 0, "reasoning": "Applying Rule 001: The text 'Love the videos' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses positive sentiment without any group targeting, hostile intent, or reinforcement of harmful stereotypes. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: The text lacks dehumanizing language, group-based targeting, or suggestions of elimination/inferiority/violence toward any group. It contains no slurs or stereotypes. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions directed at protected groups. It is a simple positive statement without metaphorical slurs or group targeting. All rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_277_k0", "example_id": "train_277", "text": "Brown people love white countries", "label": 0, "reasoning": "Applying Rule 001: The text 'Brown people love white countries' contains a generalization about 'brown people' as a group, which could be considered a racial/ethnic protected group. However, the statement does not use dehumanizing terms (like 'pigs' or 'retarded'), does not suggest elimination, inferiority, or violence toward the group, and does not reinforce harmful stereotypes in a hostile context. The statement appears to be a generalization about preferences rather than a derogatory or hostile attack. No exceptions apply as this is not reclaimed, clinical, historical, or satirical context. Applying Rule 002: Similar analysis - the text makes a group-based generalization but lacks dehumanizing language, violent suggestions, or hostile intent to dehumanize or promote violence against the group. Applying Rule 003: Same conclusion - while the text references a protected group ('brown people'), it does not meet the trigger pattern requirements of using dehumanizing terms, suggesting elimination/inferiority/violence, or reinforcing harmful stereotypes in a hostile context. The statement is a generalization but not clearly derogatory or hostile in intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_278_k0", "example_id": "train_278", "text": "These were the days!", "label": 0, "reasoning": "Applying Rule 001: The text 'These were the days!' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The text appears nostalgic or reflective without any hostile context. Applying Rule 002: The text lacks dehumanizing language, group-based targeting, and hostile intent. It does not target any protected group or promote generalized hostility. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions directed at groups. It is not metaphorical criticism of non-group entities and targets no individual or group identity. All three rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_279_k0", "example_id": "train_279", "text": "After all this time the african americans are the people with most crime rate", "label": 1, "reasoning": "Applying Rule 001: The text makes a statistical generalization about 'african americans' as a racial group, linking them to 'most crime rate'. This constitutes a derogatory generalization about a protected racial group that reinforces harmful stereotypes. The statement lacks contextual safeguards - it's presented as a factual claim rather than satire, academic discussion, or self-reference. It targets the group as a whole rather than specific individuals. No exceptions apply as this is group-based targeting with potential to promote group-based inferiority. Applying Rule 002: The text uses a derogatory generalization about a protected racial group (African Americans) by making a broad statistical claim about crime rates. This reinforces harmful stereotypes in what appears to be a hostile context (implying inherent criminality). No exceptions apply as this is not targeting individual behavior or in a reclaimed/satirical context. Applying Rule 003: The text makes a group-based generalization about African Americans and crime rates, which constitutes a derogatory generalization about a protected racial group. This reinforces harmful stereotypes in a context that suggests group inferiority. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this should be classified as hate speech due to derogatory group-based generalization about a protected racial group that reinforces harmful stereotypes.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_281_k0", "example_id": "train_281", "text": "Just nuke the entire shi*hole country", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language 'shi*hole country' which is derogatory toward a national group. It suggests violent elimination ('nuke the entire') with hostile intent toward that country's population as a group. This meets the trigger pattern of dehumanizing terms combined with group targeting and suggestion of elimination/violence. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets an entire country/national group rather than specific individuals. Applying Rule 002: The text uses derogatory language about a national group with violent suggestions ('nuke the entire'), meeting the trigger pattern for dehumanizing group-based language with hostile intent. No exceptions apply as this promotes violence against a protected group. Applying Rule 003: The text contains dehumanizing term 'shi*hole country' targeting a national group and violent suggestion 'nuke the entire', meeting all key indicators: non-literal slur, suggestion of elimination/violence toward a group, and hostile context. No exceptions apply as this is not metaphorical criticism of non-group entities or targeting individuals without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_282_k0", "example_id": "train_282", "text": "WTF this teacher should be expelled. That's no way to treat a disabled kid, specially an autistic one!", "label": 0, "reasoning": "Applying Rule 001: The text criticizes a teacher's treatment of a disabled child, specifically mentioning autism. It uses strong language ('WTF') but does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The target is an individual teacher's behavior toward a specific child, not a protected group. The mention of 'disabled kid' and 'autistic one' describes the child's identity but does so in a protective context rather than promoting hostility, inferiority, or violence toward disabled or autistic people as a group. The intent appears to advocate for better treatment, not to dehumanize or stereotype. No exceptions apply as the language is not reclaimed, clinical, historical, or satirical in a hate-promoting way. Applying Rule 002: Similar analysis—no dehumanizing terms, group-based derogatory generalizations, or violent suggestions with hostile intent toward a protected group. The criticism is directed at individual behavior (the teacher's actions) without targeting a protected group or promoting generalized hostility. Applying Rule 003: Same conclusion—no trigger patterns met; the language focuses on individual conduct and lacks group targeting or hostile context against protected groups. Overall, the text expresses outrage at mistreatment but does not constitute hate speech under the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_283_k0", "example_id": "train_283", "text": "Children have no business developing their 'sexuality\". THEY ARE CHILDREN! LET THEM BE KIDS!", "label": 0, "reasoning": "Applying Rule 001: The text expresses strong disapproval of children developing sexuality, using emphatic language ('THEY ARE CHILDREN! LET THEM BE KIDS!'). However, it does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The target appears to be the concept of childhood sexuality development rather than a specific protected group based on race, gender, religion, national origin, or sexual orientation. No suggestion of elimination, inferiority, or violence toward a group is present. No harmful stereotypes about protected groups are reinforced in a hostile context. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text criticizes a concept (childhood sexuality development) rather than targeting individuals based on protected characteristics. Applying Rule 003: Same conclusion - the language expresses a viewpoint about child development but lacks the key indicators of hate speech: no non-literal slurs, no suggestion of elimination/inferiority/violence toward a group, and no reinforcement of harmful stereotypes about protected groups in a hostile context. The text does not meet any trigger patterns from the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_284_k0", "example_id": "train_284", "text": "Every publicity is good publicity ha ? I'm here after watching leaving neverland i don't know he is guilty or not but in music he is a legend and no one can take that from him", "label": 0, "reasoning": "Applying Rule 001: The text discusses Michael Jackson's legacy after watching 'Leaving Neverland' documentary, stating uncertainty about guilt but acknowledging musical legend status. No dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions are present. No group targeting occurs - the text references an individual celebrity and general public perception. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes in hostile context. Exceptions: The text is neutral commentary on a public figure, not satirical or reclaimed language context. Applying Rule 002: Same analysis - no dehumanizing language, group-based targeting, or hostile intent toward protected groups. The text focuses on individual artistic legacy, not group identity. Applying Rule 003: Same analysis - no metaphorical slurs targeting groups, no suggestions of violence or inferiority toward protected groups. The text is conversational about celebrity culture without hateful elements. All rules indicate no hate speech present.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_285_k0", "example_id": "train_285", "text": "lowlife black animals", "label": 1, "reasoning": "Applying Rule 001: The text 'lowlife black animals' contains dehumanizing terms ('animals') and derogatory generalizations about a protected racial group ('black'). This combination shows group targeting with hostile intent, as it suggests inferiority and reinforces harmful stereotypes. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting specific individuals without group reference. Applying Rule 002: The text uses dehumanizing language ('animals') with derogatory generalizations about a racial group ('black'), showing group targeting with hostile intent. No exceptions apply as it's not reclaimed/clinical/satirical context and doesn't target individual behavior. Applying Rule 003: The text contains dehumanizing terms ('animals') and derogatory generalizations about a protected racial group ('black'), showing group targeting with hostile intent. No exceptions apply as it's not reclaimed/clinical/satirical context, metaphorical for non-group entities, or targeting individuals without group reference. All three rules indicate hate speech due to dehumanizing group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_286_k0", "example_id": "train_286", "text": "Im going to choke you with your cross necklace idiotic religious pig", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('pig') and derogatory language ('idiotic') targeting a religious group through reference to a 'cross necklace', which is a Christian symbol. This constitutes group targeting with hostile intent through violent suggestion ('choke you'). No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's direct hostile speech against a religious group. Applying Rule 002: The text uses dehumanizing language ('pig') with violent suggestion ('choke you') targeting a religious group, meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior but group-based hostility. Applying Rule 003: The text contains dehumanizing terms ('pig'), violent suggestions ('choke you'), and targets a religious group through religious symbolism, meeting all key indicators. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_287_k0", "example_id": "train_287", "text": "The most peaceful religions came from India like Buddhism, jainism etc.", "label": 0, "reasoning": "Applying Rule 001: The text mentions religions from India (Buddhism, Jainism) in a positive context ('most peaceful'), with no dehumanizing terms, derogatory generalizations, violent suggestions, or hostile intent toward any protected group. No indicators of slurs, elimination rhetoric, or harmful stereotypes are present. The statement appears descriptive and complimentary rather than hostile. Applying Rule 002: Same analysis - no dehumanizing language, group-based targeting with hostile intent, or promotion of violence against protected groups. The text discusses religions positively without targeting any group for derogatory treatment. Applying Rule 003: Same conclusion - the language is factual and positive about specific religions, not metaphorical slurs or hostile generalizations. No exceptions apply as the context is neither reclaimed, clinical, historical, nor satirical in a way that would require special consideration for hate speech detection. All rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_288_k0", "example_id": "train_288", "text": "I don’t think you have the right to write comments or even express your opinion freely. Free speech is a human right. Autistics aren’t 100% humans", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('Autistics aren't 100% humans') targeting a protected group (people with autism/neurodivergent individuals). This suggests inferiority toward the group by implying they are less than fully human. The statement is a derogatory generalization about autistics as a group, not targeting specific individuals. There's no indication of reclaimed, clinical, historical, or satirical context - it appears as a direct statement about the group's humanity. The first part about free speech rights doesn't mitigate the dehumanizing group-based language. Applying Rule 002: The text uses dehumanizing language ('aren't 100% humans') targeting a protected group (autistics) with implied inferiority. This meets the trigger pattern for derogatory generalizations about a protected group. No exceptions apply as this isn't targeting individual behavior or in a reclaimed/satirical context. Applying Rule 003: The text contains dehumanizing language targeting a protected group (autistics) with suggestion of inferiority ('aren't 100% humans'). This is group targeting, not metaphorical criticism of non-group entities or individual targeting. No exceptions for reclaimed/clinical/satirical context apply. All three rules indicate this should be classified as hate speech due to dehumanizing group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_289_k0", "example_id": "train_289", "text": "ABUSERS ARE NOT JUST MEN. THEY CAN BE WOMEN TOO", "label": 0, "reasoning": "Applying Rule 001: The text states 'ABUSERS ARE NOT JUST MEN. THEY CAN BE WOMEN TOO'. This does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It makes a factual statement about gender distribution among abusers without targeting any protected group with hostile intent. No exceptions apply as there is no group-based hostility, metaphorical slurs, or suggestions of elimination/inferiority. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. It discusses abusers in general without targeting specific protected groups. Applying Rule 003: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The statement is neutral about gender without promoting stereotypes or hostility toward any group. All rules indicate this is not hate speech as it lacks the required elements of dehumanizing language, group-based targeting with hostile intent, or reinforcement of harmful stereotypes.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_292_k0", "example_id": "train_292", "text": "I can smell the failure through my phone screen", "label": 0, "reasoning": "Analyzing the text 'I can smell the failure through my phone screen' against the rulebook: Rule 001, 002, and 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text contains no dehumanizing language (e.g., 'pigs', 'retarded'), no references to protected groups (racial, gender, religious, national, sexual orientation), no violent suggestions, and no group targeting. It appears to be a metaphorical criticism of an unspecified individual or situation ('failure'), not directed at any protected group. The metaphorical use targets non-group-based entities or individual behavior without invoking group-based hostility, which falls under exceptions in all rules. Therefore, no rule triggers for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_293_k0", "example_id": "train_293", "text": "fucking monkeys kill them all", "label": 1, "reasoning": "Applying Rule 001: The text 'fucking monkeys kill them all' contains dehumanizing language ('monkeys') and violent suggestions ('kill them all') with group targeting. The term 'monkeys' is commonly used as a racial slur against Black people, which constitutes derogatory generalization about a protected racial group. The phrase 'kill them all' suggests elimination and violence toward that group. There is no indication of reclaimed, clinical, historical, or satirical context that would exempt this under the rule's exceptions. The language is not metaphorical criticism of non-group entities nor targeting specific individuals without group reference. Applying Rule 002: The text uses dehumanizing terms ('monkeys') and violent suggestions ('kill them all') with clear group targeting, meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior without group targeting. Applying Rule 003: The text contains dehumanizing language and violent suggestions with group targeting, meeting all key indicators. No exceptions apply for reclaimed, clinical, historical, satirical contexts, metaphorical use, or individual targeting. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_294_k0", "example_id": "train_294", "text": "Lauren is SAVAGE. love her", "label": 0, "reasoning": "Applying Rule 001: The text 'Lauren is SAVAGE. love her' contains the term 'SAVAGE', which could potentially be considered derogatory if used as a slur against indigenous or ethnic groups. However, examining the context: (1) The term appears to be used as contemporary slang meaning 'fierce', 'bold', or 'impressively direct' rather than as a dehumanizing slur against a protected group. (2) There is no group targeting - the comment is directed at an individual named Lauren without reference to any racial, gender, religious, national, or sexual orientation group. (3) There is no suggestion of elimination, inferiority, or violence toward any group. (4) The phrase 'love her' indicates positive sentiment rather than hostile intent. This falls under the exception for metaphorical/non-group-based usage. Applying Rule 002: The text lacks dehumanizing terms with hostile intent toward protected groups. The term 'SAVAGE' is not used in combination with group targeting. Applying Rule 003: Similar analysis - the term is used metaphorically to describe an individual's behavior/character, not to criticize or target a protected group. No derogatory generalizations about protected groups are present. All rules indicate this should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_295_k0", "example_id": "train_295", "text": "If your face was used on the inside of a jack-in-the-box there would be an epidemic of children dying from shock and disgust.", "label": 0, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('dying from shock and disgust') and suggests violence toward children, but it targets an individual's appearance rather than a protected group. The comment is directed at 'your face' (individual) without reference to racial, gender, religious, national, or sexual orientation groups. No derogatory generalizations about protected groups are present. Applying Rule 002: Similar analysis - while offensive and violent in suggestion, the target is individual appearance, not a protected group. No group-based hostility or stereotypes are reinforced. Applying Rule 003: The language is metaphorical and hyperbolic criticism of an individual's appearance, not targeting a protected group. The violent suggestion ('dying') is directed at the hypothetical reaction to an individual's face, not advocating actual violence against a group. All three rules indicate this does not meet the criteria for hate speech as it lacks group targeting of protected identities.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_296_k0", "example_id": "train_296", "text": "the girl in glasses is so freaking cute! what's her channel??", "label": 0, "reasoning": "Applying Rule 001: The text 'the girl in glasses is so freaking cute! what's her channel??' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It describes an individual ('the girl in glasses') positively with 'cute' and inquires about her channel, showing no group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is non-hostile and individual-focused, fitting the exception for targeting specific individuals without invoking group-based hostility. Applying Rule 002: No dehumanizing terms or derogatory generalizations about protected groups are present. The comment targets an individual's appearance and channel inquiry, not a protected group, and lacks intent to dehumanize or promote generalized hostility. Applying Rule 003: Similar to Rule 001, the text uses no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. It metaphorically or literally describes an individual without reference to group identity, fitting the exception for individual targeting. All rules indicate no hate speech due to the absence of group-based derogatory language, hostile intent, and protected group targeting.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_297_k0", "example_id": "train_297", "text": "We'll walk right up to the sun hand in hand..", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text 'We'll walk right up to the sun hand in hand..' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, or sexual orientation), and no violent suggestions (e.g., 'gas yourself', 'hope to distinct soon'). It does not target any group, use slurs, suggest elimination or inferiority, or reinforce harmful stereotypes. The text appears poetic and metaphorical about walking to the sun together, with no hostile intent or group-based targeting. Therefore, none of the rules trigger, and the exceptions do not apply as there is no offensive language to evaluate in reclaimed, clinical, historical, or satirical contexts. The text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_298_k0", "example_id": "train_298", "text": "only people to come in must be able to contribute to society not a drain on us must be able to support themselves with a trade we do not need people living off the rest of us", "label": 0, "reasoning": "Applying Rule 001: The text discusses immigration criteria based on economic contribution, using terms like 'drain on us' and 'living off the rest of us' to describe those who cannot support themselves. This targets a socioeconomic category (people unable to contribute economically) rather than a protected group based on race, gender, religion, nationality, or sexual orientation. No dehumanizing terms (e.g., 'pigs', 'retarded') are used, and there is no suggestion of elimination, violence, or reinforcement of harmful stereotypes about protected groups. The criticism is directed at economic dependency behavior, not group identity. Applying Rule 002: Similar analysis applies - the text lacks dehumanizing language targeting protected groups and focuses on individual economic behavior. Applying Rule 003: The text does not use metaphorical slurs or target protected groups, and the context is economic policy discussion rather than hostile intent toward identity-based groups. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_299_k0", "example_id": "train_299", "text": "We are not these bodies. We are spirit souls.", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all define hate speech as requiring dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text 'We are not these bodies. We are spirit souls.' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), no violent suggestions, and no group targeting. It makes a philosophical/spiritual statement about human nature without hostility, stereotypes, or targeting of any identity-based group. None of the trigger patterns in the rules apply, and no exceptions need to be invoked since the text lacks all key indicators specified in the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_300_k0", "example_id": "train_300", "text": "I failed one little test and my mom got scared and said, \"You're moving with your auntie and uncle in Alaska.\"", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It describes a personal family situation with no group targeting. No exceptions apply as there is no offensive language present. Applying Rule 002: No dehumanizing language or group-based hostility is present. The text discusses individual family dynamics without targeting any protected group. Applying Rule 003: The text lacks all trigger patterns including dehumanizing terms, derogatory generalizations, and violent suggestions. It is a narrative about personal experience without group targeting or hostile intent. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_301_k0", "example_id": "train_301", "text": "there's nowhere in the world where woman are equal. how about in all the places where they are president or prime minister or queen... how about in America, Australia, Canada, Britain, Scandinavia, France... shall I go on? Like honestly woman u live in an equal world. Stop being so self-obsessed and stop refusing to look at the facts. Women are already equal to men and have been for a long time.", "label": 0, "reasoning": "Applying Rule 001: The text makes generalizations about women as a protected gender group, but does not use dehumanizing terms ('pigs', 'retarded'), violent suggestions, or promote elimination, inferiority, or violence toward the group. It argues women are already equal, which while potentially dismissive of gender inequality concerns, lacks hostile intent and does not reinforce harmful stereotypes in a hostile context. The language targets women as a group but criticizes perceived self-obsession and refusal to acknowledge facts, not the group's inherent worth. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis - no dehumanizing terms, violent suggestions, or promotion of group-based hostility. The comment targets women's perceived behavior (self-obsession, refusing facts) without dehumanizing the group or suggesting inferiority. Applying Rule 003: Same conclusion - no triggering patterns of dehumanization, violence, or derogatory generalizations with hostile intent. The text expresses disagreement with claims of inequality but does not use slurs or suggest harm. Overall, while the text may be contentious or dismissive, it does not meet the criteria for hate speech under any rule as it lacks dehumanizing language, violent suggestions, and hostile intent toward women as a protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_302_k0", "example_id": "train_302", "text": "the first step is to remove Romanians, they're no good anywhere they wash up", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('no good') targeting Romanians as a national group, suggesting removal ('the first step is to remove Romanians'), which implies elimination or exclusion. This constitutes group-based targeting with hostile intent. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalization about a protected national group (Romanians) with suggestion of removal, meeting the trigger pattern. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text uses derogatory language targeting a national group with suggestion of removal, meeting the trigger pattern. No exceptions apply as it's not metaphorical or individual targeting. All three rules indicate hate speech due to group-based derogatory language with hostile intent toward a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_304_k0", "example_id": "train_304", "text": "I hate being alone at night. Its fucking creepy", "label": 0, "reasoning": "Applying Rule 001: The text uses strong language ('fucking creepy') but does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The target is the situation of being alone at night, not any group or individual based on protected characteristics. No group targeting, elimination rhetoric, or harmful stereotypes are present. The language expresses personal discomfort rather than hostility toward a protected group. Applying Rule 002: Similar analysis - no dehumanizing terms targeting protected groups, no derogatory generalizations, and no violent suggestions with group targeting. The comment is about a personal experience without reference to any protected identity. Applying Rule 003: Again, no dehumanizing language targeting protected groups, no group-based derogatory generalizations, and no violent suggestions. The expression 'fucking creepy' is colloquial and directed at an abstract situation, not at any protected group or individual based on group identity. All rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_305_k0", "example_id": "train_305", "text": "Thanks god at least you have music to pale the pain being blind. Oh what you can’t hear too. Haha", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'blind' and references hearing impairment ('can't hear too') in a mocking context ('Haha'). However, this appears to target an individual's specific conditions rather than making derogatory generalizations about people with visual or hearing impairments as protected groups. There is no suggestion of elimination, inferiority, or violence toward these groups, nor reinforcement of harmful stereotypes in a hostile context. The language seems directed at an individual's perceived limitations without invoking group-based hostility. Applying Rule 002: Similar analysis - while potentially offensive, the comment targets individual circumstances without promoting generalized hostility toward protected identity groups. Applying Rule 003: The text lacks dehumanizing terms, violent suggestions, or group targeting that would trigger this rule. The mocking tone targets individual characteristics rather than protected group identities.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_307_k0", "example_id": "train_307", "text": "Even after just getting out of surgery you look like a bomb ass BITCHHH!! Love you and hope you'¬Ä¬ôre recovering fast!", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The phrase 'bomb ass BITCHHH' is used as a compliment in a friendly context, not as a derogatory term targeting any protected group. The text expresses affection and well-wishes ('Love you and hope you're recovering fast'), indicating positive intent. No group targeting, hostile context, or harmful stereotypes are present. Applying Rule 002: No dehumanizing language or group-based hostility is present. The text focuses on an individual without reference to group identity. Applying Rule 003: No elements match the trigger patterns for dehumanizing or derogatory group-based language. The language is colloquial and affectionate, not hostile or group-targeting. All rules indicate the text does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_308_k0", "example_id": "train_308", "text": "Omg, Macklemore is iconic and I love him.", "label": 0, "reasoning": "Applying Rule 001: The text 'Omg, Macklemore is iconic and I love him' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses positive admiration for an individual artist without any group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is complimentary and personal, not metaphorical in a derogatory sense. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: The text lacks dehumanizing language, group-based targeting, or hostile intent toward any protected group. It focuses on individual appreciation without stigmatizing any identity. Applying Rule 003: Similar analysis - no trigger patterns are present. The text is a positive statement about an individual without any elements that would classify as hate speech under any of the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_309_k0", "example_id": "train_309", "text": "I really don’t like your accent. I don’t want to call support and call to rats like you. I want a cute lady with British accent to answer my call. You are third world pieces with no job to this planet", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('rats', 'third world pieces') targeting a group based on national/regional identity (implied by accent criticism). It suggests inferiority ('no job to this planet') and uses derogatory generalizations about people with certain accents. The hostile intent is clear from 'I don't want to call support and call to rats like you.' This meets the trigger pattern of dehumanizing language with group targeting. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It specifically targets a protected group (national/regional identity) rather than individual behavior alone. Applying Rule 002: Same analysis applies - dehumanizing terms ('rats', 'third world pieces') with group targeting based on accent/nationality, suggesting inferiority and exclusion. No exception for individual behavior targeting applies since the criticism extends to a group ('rats like you', 'third world pieces'). Applying Rule 003: Same analysis applies - dehumanizing language with group targeting and hostile intent. No exceptions for reclaimed use, clinical context, or metaphorical criticism of non-group entities apply. All three rules indicate hate speech due to dehumanizing group-based language with hostile intent targeting protected characteristics (national/regional identity).", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_310_k0", "example_id": "train_310", "text": "This literally made my emotional bi ass cry", "label": 0, "reasoning": "Applying Rule 001: The text contains the term 'bi' which could refer to bisexuality (a sexual orientation protected group). However, examining the context: (1) The term is used in a self-referential manner ('my emotional bi ass'), not targeting others. (2) There is no dehumanizing language, derogatory generalizations, or violent suggestions. (3) The tone appears emotional/expressive rather than hostile. (4) This could be considered reclaimed/self-referential context (similar to LGBTQ+ self-reference exception). Applying Rule 002: The text lacks group targeting, dehumanizing terms, or suggestions of elimination/inferiority/violence toward a protected group. The term 'bi' is used descriptively about oneself. Applying Rule 003: Similar analysis - no group-based hostility, no harmful stereotypes, no metaphorical slurs used against others. The self-referential use falls under exceptions for reclaimed context. All three rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_311_k0", "example_id": "train_311", "text": "Nice concept, good story but poor act. Try harder next time", "label": 0, "reasoning": "Applying Rule 001: The text 'Nice concept, good story but poor act. Try harder next time' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It targets an individual's performance (acting) without reference to group identity. No indicators of group targeting, elimination, inferiority, or violence toward a protected group are present. The criticism is directed at individual behavior (acting quality) without invoking group-based hostility. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. It critiques individual performance without targeting a protected group or promoting generalized hostility. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. The language is used to criticize individual performance without metaphorical slurs or group-based stereotypes. All rules indicate this is non-hateful speech as it targets individual behavior without group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_312_k0", "example_id": "train_312", "text": "God bless you dears", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. The text 'God bless you dears' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), and no violent suggestions (e.g., 'gas yourself', 'hope to distinct soon'). It expresses a positive, non-hostile sentiment ('God bless you') with an affectionate term ('dears') that does not target any group. No exceptions apply as there is no offensive language to evaluate for context. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_313_k0", "example_id": "train_313", "text": "Anyone should leave their partner at the very first sign of abuse", "label": 0, "reasoning": "Applying Rule 001: The text 'Anyone should leave their partner at the very first sign of abuse' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. The statement offers general advice about relationship safety without targeting any specific group or individual based on protected characteristics. It lacks indicators such as non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context. The advice is directed at 'anyone' in abusive relationships, which is not a protected group under the rule definitions. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context, nor metaphorical criticism of non-group entities. Applying Rule 002: Similarly, no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting are present. The text addresses individual behavior (leaving abusive partners) without targeting a protected group or promoting generalized hostility. Applying Rule 003: The same analysis holds - no trigger patterns are met, and no exceptions apply. The text is non-hateful advice about personal safety in relationships.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_314_k0", "example_id": "train_314", "text": "They'll get to know homosexuality anyways. I don't get what's wrong with most of the people nowadays. If you don't teach about homosexuality then stop teaching about heterosexuality also.", "label": 0, "reasoning": "Applying Rule 001: The text discusses homosexuality and heterosexuality in educational contexts without using dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It advocates for equal treatment of both sexual orientations in education, which aligns with LGBTQ+ rights discourse rather than promoting hostility. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The context appears to be advocating for inclusivity, not targeting any group with hostility. Applying Rule 002: Similar analysis - no dehumanizing language or group-based derogatory generalizations are used. The text focuses on educational policy rather than attacking protected groups. Applying Rule 003: Again, no trigger patterns are met. The language is not metaphorical criticism of non-group entities nor individual targeting; it discusses concepts (homosexuality/heterosexuality) in a comparative manner that promotes equality. All rules indicate this does not meet hate speech criteria as it lacks hostile intent toward protected groups and instead advocates for balanced representation.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_315_k0", "example_id": "train_315", "text": "Fat bastard we won' forget you. Vets will kick your ass when caught", "label": 0, "reasoning": "Applying Rule 001: The text uses 'fat bastard' which could be considered derogatory, but it targets an individual ('you') without reference to any protected group identity (racial, gender, religious, national, sexual orientation). The threat of violence ('kick your ass') is directed at this specific individual rather than a group. No dehumanizing terms targeting protected groups, derogatory generalizations about groups, or suggestions of elimination/inferiority toward groups are present. The language appears to be directed at an individual's behavior or characteristics without invoking group-based hostility. Applying Rule 002: Similar analysis - while offensive, the comment targets an individual ('you') rather than a protected group. No group targeting or promotion of generalized hostility toward identity-based communities. Applying Rule 003: The derogatory language ('fat bastard') is used toward an individual, not metaphorically toward non-group entities or with group reference. The threat is individual-specific. All three rules indicate this does not meet the criteria for hate speech as defined by the rulebook, which requires group targeting of protected groups with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_316_k1", "example_id": "train_316", "text": "Feminism is just about women crying about the fabricated bullshit they go through. It's a JOKE! They should just man up!", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about women as a protected gender group ('women crying about fabricated bullshit'), suggesting inferiority ('should just man up') in a hostile context. It reinforces harmful stereotypes about feminists and women. No exceptions apply - it's not reclaimed, clinical, historical, satirical critique, metaphorical non-group targeting, or individual-focused criticism. Applying Rule 002: The text uses derogatory generalizations about women/feminists with hostile intent, suggesting they're fabricating issues and should adopt traditionally masculine traits ('man up'), implying inferiority. No exceptions apply as it targets a protected group rather than individual behavior. Applying Rule 003: The text contains derogatory generalizations about women/feminists with hostile intent, suggesting inferiority and reinforcing stereotypes. No exceptions apply for reclaimed use, metaphorical non-group targeting, or individual focus. All three rules indicate hate speech due to group-based derogatory language with hostile intent targeting a protected gender group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_317_k0", "example_id": "train_317", "text": "Hindus take my ass please", "label": 1, "reasoning": "Applying Rule 001: The text 'Hindus take my ass please' contains a derogatory reference to Hindus, which is a religious protected group. The phrase 'take my ass please' suggests a sexualized, demeaning request directed at this religious group, which constitutes derogatory language with hostile intent. This is not metaphorical, self-referential, or targeting individual behavior without group reference. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or directed at non-group entities. Applying Rule 002: The text uses derogatory language targeting Hindus as a religious group with hostile intent, meeting the trigger pattern. No exceptions apply as it's not criticizing individual behavior or in a reclaimed context. Applying Rule 003: The text contains derogatory group-based language targeting Hindus with hostile intent. No exceptions apply as it's not metaphorical criticism of non-group entities or individual targeting without group reference. All three rules indicate this is hate speech due to derogatory language targeting a protected religious group with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_318_k2", "example_id": "train_318", "text": "I didn't know future gay gym teachers had to take AIDS tests.", "label": 1, "reasoning": "Analyzing the text 'I didn't know future gay gym teachers had to take AIDS tests.' against the rulebook: Rule 001, 002, and 003 all define hate speech as involving dehumanizing/derogatory language targeting protected groups with hostile intent. This text references 'gay gym teachers' as a group and links them to AIDS tests, which reinforces harmful stereotypes about gay people and HIV/AIDS. The statement implies a generalization about gay individuals (specifically gym teachers) and medical testing, which can be interpreted as promoting stigma and inferiority toward the LGBTQ+ community. There's no indication this is reclaimed, clinical, historical, satirical, or self-referential context; it appears to be a derogatory generalization about a protected group (sexual orientation) with potential hostile undertones. Therefore, all relevant rules apply, classifying this as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_319_k0", "example_id": "train_319", "text": "I hate white flour and white sugar. Are two of the three white deaths!!", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'white deaths' metaphorically to criticize white flour and white sugar as unhealthy food items. This is not targeting a protected racial group (white people) but rather referring to food products. There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions toward any group. The context is nutritional criticism, not group-based hostility. The exception for metaphorical use to criticize non-group-based entities applies. Applying Rule 002: No dehumanizing terms or group targeting present. The criticism is directed at food items, not individuals or protected groups. Applying Rule 003: Similar analysis to Rule 001 - metaphorical criticism of non-group entities without hostile intent toward protected groups. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_321_k0", "example_id": "train_321", "text": "Roses are red. Your sweatshirt is blue. When a white girl gets raped, the suspect for sure is you!", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about a protected group (racial group) with hostile intent. It suggests that 'you' (implied to be a person of color based on racial stereotypes) is automatically the suspect when a white girl gets raped, reinforcing harmful stereotypes about criminality based on race. This constitutes group targeting with hostile context. No exceptions apply as this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about a racial group with hostile intent, suggesting elimination/inferiority through criminal suspicion. It targets a protected group rather than individual behavior. Applying Rule 003: The text contains derogatory generalizations about a protected group (racial) with hostile intent, reinforcing harmful stereotypes in a hostile context about criminal suspicion based on race. No exceptions apply as this is not metaphorical or individual-targeted without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_322_k0", "example_id": "train_322", "text": "Lgbt now spread in asia. Many anti lgbt in asian worried their culture are ruined cuz this virus", "label": 1, "reasoning": "Applying Rule 001: The text uses 'virus' as a dehumanizing term to describe LGBTQ+ people, which is a protected group based on sexual orientation. This suggests inferiority and harmful stereotypes by equating LGBTQ+ identity with a disease. The text targets the group broadly ('Lgbt now spread in asia') rather than specific individuals, and the context appears hostile rather than satirical or reclaimed. No exceptions apply as this is not self-referential, clinical, or metaphorical criticism of non-group entities. Applying Rule 002: The derogatory generalization about LGBTQ+ people as a 'virus' spreading in Asia constitutes group-based dehumanizing language with hostile intent. The comment reinforces harmful stereotypes about LGBTQ+ people corrupting culture. No exceptions apply as this is not targeting individual behavior. Applying Rule 003: The text uses 'virus' as a metaphorical slur suggesting elimination or inferiority of a protected group (LGBTQ+), combined with group targeting ('Lgbt now spread in asia'). The context is hostile, promoting negative stereotypes. No exceptions apply for reclaimed, clinical, or satirical contexts, nor is this targeting individuals without group reference. All three rules indicate this text meets the criteria for hate speech due to dehumanizing group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_323_k0", "example_id": "train_323", "text": "Handsome woman, eww..", "label": 0, "reasoning": "Applying Rule 001: The text 'Handsome woman, eww..' contains the term 'eww' which expresses disgust, but it targets an individual woman without using dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. There is no indication of group targeting, elimination, inferiority, violence, or reinforcement of harmful stereotypes toward a protected group. The comment appears to criticize an individual's appearance without invoking group-based hostility. According to Rule 001 exceptions, this does not apply as it targets an individual without reference to group identity. Applying Rule 002: Similar analysis applies - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment targets individual appearance, not a protected group. Applying Rule 003: Same conclusion - no dehumanizing language with group targeting, and the target is an individual without group reference. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_325_k0", "example_id": "train_325", "text": "Because everyone knows this islam men is the devil", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'devil' which is a dehumanizing term with strong negative connotations. It targets 'islam men' which refers to Muslim men as a religious group (Islam is a protected religious group). The phrase 'the devil' suggests inherent evil or malevolence, reinforcing harmful stereotypes about Muslim men as inherently dangerous or immoral. This constitutes derogatory generalization about a protected religious group with hostile intent. No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets the group identity rather than individual behavior. Applying Rule 002: Similar analysis applies - dehumanizing language ('devil') targeting a protected religious group (Muslim men) with hostile generalization. No exceptions for reclaimed use or individual behavior targeting. Applying Rule 003: Same pattern - dehumanizing term targeting protected religious group with hostile generalization. No exceptions for metaphorical use or individual targeting. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_327_k0", "example_id": "train_327", "text": "Islam is pig shit", "label": 1, "reasoning": "Applying Rule 001: The text 'Islam is pig shit' contains dehumanizing language ('pig shit') targeting a protected religious group (Islam). This constitutes derogatory generalization about a religious group with hostile intent, as it uses a non-literal slur that suggests inferiority and reinforces harmful stereotypes in a hostile context. The language is not used in a reclaimed, clinical, historical, or satirical context that critiques hate speech. It directly targets the religious group as a whole rather than individual behavior or non-group entities. Applying Rule 002: The text uses dehumanizing terms ('pig shit') targeting a protected religious group (Islam), which meets the trigger pattern for derogatory generalizations with hostile intent. It is not exempt as it targets the group itself rather than individual behavior. Applying Rule 003: The text contains dehumanizing language targeting a protected religious group with hostile intent, using metaphorical slurs that suggest inferiority. It is not exempt as it targets the group identity rather than non-group entities or individuals without group reference. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_328_k0", "example_id": "train_328", "text": "the only thing that annoys me is noisy neighbours and their music.", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'noisy neighbours and their music' but does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. It targets specific individuals (neighbours) based on behavior (noise and music) without invoking group identity or stereotypes. This falls under the exception for non-group-based targeting of individuals. Applying Rule 002: Similar analysis; no dehumanizing language or group-based hostility is present, and the criticism is directed at individual behavior without targeting a protected group. Applying Rule 003: Again, no dehumanizing terms or group targeting; the language is not metaphorical in a harmful context and focuses on individual annoyance. All rules indicate the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_329_k0", "example_id": "train_329", "text": "You can see the country is fertile and green.  just need the right governance", "label": 0, "reasoning": "Applying Rule 001: The text does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It discusses governance in a country without targeting any racial, gender, religious, national, or sexual orientation group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The language is neutral and constructive. Applying Rule 002: Similar analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The comment focuses on governance improvement without stigmatizing any identity-based community. Applying Rule 003: Again, no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The text uses metaphorical language ('fertile and green') to describe a country's potential, not to criticize protected groups. All rules indicate this is non-hateful as it lacks the required elements for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_330_k1", "example_id": "train_330", "text": "Wallmart employees are cunts. Hate them all", "label": 0, "reasoning": "Applying Rule 001: The text uses the derogatory term 'cunts' targeting 'Wallmart employees' as a group. This constitutes derogatory group-based language with hostile intent ('Hate them all'), suggesting generalized hostility toward all employees of this company. However, Rule 001 specifies exceptions for non-group-based entities or when targeting individuals without reference to group identity. Walmart employees do not constitute a protected group (racial, gender, religious, national, sexual orientation) as defined in the rulebook. The language is offensive and hostile but targets a professional/occupational group rather than a protected identity-based group. Applying Rule 002: Similar analysis applies - the derogatory term and hostile statement target Walmart employees as a group, but this is not a protected group as defined in the rule. The rule requires targeting of protected groups (racial, gender, religious, national, sexual orientation). Applying Rule 003: Same analysis as Rule 001 - while the language is derogatory and hostile toward a group, Walmart employees are not a protected group as specified in the rule's trigger pattern. All three rules focus on protected identity-based groups, and occupational groups do not fall under this protection according to the provided rule definitions.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_331_k0", "example_id": "train_331", "text": "Anyone who can' cope as the gender they are born needs SERIOUS psychological therapy!!!", "label": 0, "reasoning": "Applying Rule 001: The text targets individuals who cannot 'cope as the gender they are born' and suggests they need 'SERIOUS psychological therapy.' This references transgender or gender non-conforming people as a protected group based on gender identity. However, the language does not use dehumanizing terms (e.g., 'pigs,' 'retarded'), violent suggestions, or derogatory generalizations about the group as a whole. It focuses on individual coping and therapy needs without promoting elimination, inferiority, or violence toward the group. The criticism is directed at perceived individual behavior (inability to cope) rather than making hostile generalizations about transgender people as a group. No exceptions apply as the context is not reclaimed, clinical, historical, or satirical critique of hate speech. Applying Rule 002: Similar analysis—the text lacks dehumanizing language, violent suggestions, or group-based derogatory generalizations. It targets individual coping without promoting systemic hostility toward a protected group. Applying Rule 003: Same conclusion—no dehumanizing terms, violent suggestions, or group-targeted derogatory language are present. The text metaphorically criticizes individual behavior without reference to group identity in a hostile context. Therefore, based on all relevant rules, the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_332_k0", "example_id": "train_332", "text": "When your squad is complete shit in PUBG", "label": 0, "reasoning": "Applying Rule 001: The text 'When your squad is complete shit in PUBG' uses potentially derogatory language ('complete shit') but targets a gaming squad's performance in a video game (PUBG), not a protected group based on race, gender, religion, nationality, or sexual orientation. The language is metaphorical criticism of gameplay ability, directed at specific individuals (the squad) without invoking group-based hostility or stereotypes. No dehumanizing terms, violent suggestions, or group targeting of protected characteristics are present. Applying Rule 002: Similar analysis - the derogatory term 'shit' is used colloquially to criticize performance, not to target a protected group with hostile intent. No suggestion of elimination, inferiority, or violence toward a group. Applying Rule 003: The language criticizes non-group-based entities (gaming squad performance) metaphorically, not protected groups. All rules indicate this does not meet hate speech criteria due to lack of protected group targeting and non-hostile context.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_333_k0", "example_id": "train_333", "text": "Don't live where you’re not wanted. Deport Jews and Muslims", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory group-based language targeting Jews and Muslims as protected religious groups, with hostile intent through the suggestion of deportation. This constitutes group targeting with implied elimination/support for oppressive actions. No exceptions apply - this is not reclaimed, clinical, historical, satirical, metaphorical, or individual-focused. Applying Rule 002: The text uses derogatory generalizations about protected religious groups (Jews and Muslims) with hostile intent through deportation suggestion. No exceptions apply as this clearly targets protected groups rather than individual behavior. Applying Rule 003: The text uses derogatory group-based language targeting protected religious groups with hostile intent (deportation suggestion). No exceptions apply as this is not metaphorical, reclaimed, or individual-focused. All three rules indicate hate speech due to group targeting, derogatory language, and hostile intent toward protected groups.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_334_k0", "example_id": "train_334", "text": "build that wall deport them all", "label": 1, "reasoning": "Applying Rule 001: The text 'build that wall deport them all' contains group targeting ('them all') which appears to refer to immigrants or specific national groups, combined with a call for deportation (suggesting elimination/removal of a group). This meets the trigger pattern of derogatory generalizations about a protected group (national origin) with hostile intent. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses group targeting with a suggestion of elimination (deportation) toward what appears to be a protected national group, meeting the trigger pattern. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text contains group targeting ('them all') with a suggestion of elimination (deportation) and potentially reinforces harmful stereotypes about immigrants, meeting the trigger pattern. No exceptions apply for reclaimed usage or metaphorical criticism of non-group entities. All three rules indicate this should be classified as hate speech due to derogatory group-based language with hostile intent targeting what appears to be a protected national group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_335_k0", "example_id": "train_335", "text": "that girl who pushed her needs to pay personally for all the family's medical bills lol. only fair", "label": 0, "reasoning": "Applying Rule 001: The text targets 'that girl who pushed her' - an individual rather than a protected group. The language ('needs to pay personally', 'only fair lol') expresses a personal opinion about individual responsibility and justice, not dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. No indicators of group targeting, elimination rhetoric, or reinforcement of harmful stereotypes are present. The criticism is directed at specific individual behavior without invoking group-based hostility. Applying Rule 002: Similar analysis - the comment focuses on individual accountability for specific actions, not protected group characteristics. No dehumanizing language or group-based derogatory generalizations. Applying Rule 003: Again, the target is an individual ('that girl'), not a protected group. The language is literal (discussing financial responsibility) rather than metaphorical slurs, and lacks suggestions of elimination, inferiority, or violence toward any group. All three rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_337_k0", "example_id": "train_337", "text": "As an SJW, it is the right of black people to rob and kill me. To not allow them is a white privilege.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about black people ('it is the right of black people to rob and kill me') which suggests violent actions toward a racial group. This meets the trigger pattern of derogatory generalizations about a protected group (racial) with suggestions of violence. The text also reinforces harmful stereotypes about black people being violent criminals. There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech - rather, it appears to promote hostility. The targeting is group-based (black people) rather than individual. Applying Rule 002: The text uses derogatory generalizations about a racial group with suggestions of violence ('rob and kill'), meeting the trigger pattern. The context is hostile, not critical or educational. Applying Rule 003: The text contains derogatory generalizations about a protected racial group with violent suggestions, meeting all key indicators. No exceptions apply as the language is not metaphorical, not targeting individuals, and not in a reclaimed or satirical context. The text promotes harmful stereotypes about black people as violent criminals who have a 'right' to commit crimes, which constitutes hate speech under all three rules.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_338_k0", "example_id": "train_338", "text": "People get views of a religion from other people opinion and deeds, just focus on yourself. This business is between you and your god. People who say islam is not peace, that's wrong. God didn't want this, it's not mentioned anywhere.", "label": 0, "reasoning": "Applying Rule 001: The text discusses religion (Islam) but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It states 'People who say islam is not peace, that's wrong' - this is defending Islam rather than attacking it. The text focuses on personal faith ('focus on yourself', 'between you and your god') and corrects misconceptions without targeting any group with hostility. No indicators of slurs, elimination rhetoric, or harmful stereotypes are present. The context is educational/corrective rather than hostile. Applying Rule 002: Similar analysis - no dehumanizing language, no group-based targeting with hostile intent. The text actually defends a religious group (Muslims/Islam) against criticism. Applying Rule 003: Again, no trigger patterns are met. The language is not metaphorical in a derogatory way, and there's no suggestion of violence or inferiority toward any protected group. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_339_k0", "example_id": "train_339", "text": "Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.", "label": 1, "reasoning": "Applying Rule 001: The text contains 'filthy Caucasian' which is a derogatory term targeting a racial group (Caucasian/white people). This constitutes derogatory group-based language with hostile intent. The phrase 'Please don't come back' suggests exclusion or elimination of this group. There's no indication of reclaimed, clinical, historical, or satirical context that would justify this as critique rather than promotion of hate. The language is not metaphorical criticism of non-group entities nor targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory language ('filthy') targeting a protected racial group with hostile intent ('don't come back'), meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains dehumanizing/derogatory language targeting a racial group with hostile exclusionary intent, meeting all key indicators. No exceptions apply for reclaimed, clinical, historical, satirical, metaphorical, or individual targeting contexts. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_340_k0", "example_id": "train_340", "text": "I hate every religion, but because of you I hate most of all your religion and its stupid theories about God and shits", "label": 1, "reasoning": "Applying Rule 001: The text expresses hatred toward religions as groups ('I hate every religion', 'your religion') and uses derogatory language ('stupid theories about God and shits'). This targets protected religious groups with hostile intent. No exceptions apply: it's not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets groups rather than specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about religious groups with hostile intent, meeting the trigger pattern. No exceptions apply as it's not critiquing hate speech or targeting individual behavior. Applying Rule 003: Similar analysis applies - dehumanizing/derogatory language targeting religious groups with hostile intent, and no applicable exceptions. All three rules indicate hate speech due to group-based derogatory language with hostile intent toward protected religious groups.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_341_k0", "example_id": "train_341", "text": "Tell me where to ship this comfy electric chair for your kid", "label": 0, "reasoning": "Applying Rule 001: The text uses the phrase 'electric chair' which could be interpreted as a violent suggestion, but it lacks group targeting. The text appears to be directed at an individual ('your kid') rather than a protected group. There's no use of dehumanizing terms, derogatory generalizations about protected groups, or reinforcement of harmful stereotypes. The context suggests this might be sarcastic or metaphorical criticism of an individual's parenting, not targeting a group identity. Applying Rule 002: Similar analysis - no group-based language or targeting of protected groups. The violent suggestion ('electric chair') is not combined with group targeting. Applying Rule 003: Again, no group targeting present. The text targets an individual ('your kid') without reference to group identity. All three rules require combination of violent suggestions with group targeting to trigger hate speech classification, which is absent here. The exceptions in all rules apply since this appears to be metaphorical criticism directed at an individual without invoking group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_342_k0", "example_id": "train_342", "text": "The world before white people. 1 word 8 letters. PEACEFUL", "label": 1, "reasoning": "Applying Rule 001: The text 'The world before white people. 1 word 8 letters. PEACEFUL' makes a generalization about white people as a group, suggesting that the world was peaceful before their existence. This implies inferiority or negative impact of white people as a racial/national group, which aligns with derogatory generalizations about a protected group (racial/national) with hostile intent. The text uses the phrase 'white people' to target a group based on race/nationality, not individuals. There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech; it appears to promote a negative stereotype about white people. No exceptions apply as the language is group-targeting and reinforces harmful stereotypes in a hostile context. Applying Rule 002: Similar analysis applies; the text uses derogatory generalization about white people as a protected group, suggesting elimination or inferiority (i.e., the world was better without them). No exceptions for individual behavior or reclaimed context. Applying Rule 003: The text fits the trigger pattern of derogatory generalizations about a protected group (racial/national) with hostile intent, implying violence or inferiority through the contrast with 'PEACEFUL'. No metaphorical use or individual targeting exceptions apply. Therefore, all relevant rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_344_k0", "example_id": "train_344", "text": "he may be in a wheelchair but he's not at all bad looking! forget the trolls dude", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'in a wheelchair' which references disability, but does not use dehumanizing terms like 'retarded', make derogatory generalizations about people with disabilities as a protected group, or suggest violence/elimination. The comment is complimentary ('not at all bad looking') and supportive ('forget the trolls dude'), lacking hostile intent. It targets an individual without group-based hostility. Applying Rule 002: No dehumanizing language or derogatory generalizations about protected groups are present. The reference to wheelchair is descriptive rather than derogatory, and there's no suggestion of inferiority or violence toward people with disabilities. Applying Rule 003: The text does not contain slurs, elimination suggestions, or reinforcement of harmful stereotypes in a hostile context. The mention of disability is neutral/descriptive within a positive and supportive message directed at an individual.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_345_k0", "example_id": "train_345", "text": "Fuck off corbyn... Die or retire..", "label": 0, "reasoning": "Applying Rule 001: The text uses hostile language ('Fuck off', 'Die or retire') directed at an individual (Jeremy Corbyn), a specific politician. It does not use dehumanizing terms like 'pigs' or 'retarded', nor does it target a protected group based on race, gender, religion, nationality, or sexual orientation. The criticism is directed at an individual's political role/actions without invoking group-based hostility or stereotypes. Applying Rule 002: The text lacks dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions toward a group. The hostility is aimed at an individual politician, not a protected group identity. Applying Rule 003: Similar to Rule 001, the text targets an individual (Corbyn) without reference to group identity. The language, while offensive, is metaphorical/colloquial criticism of a political figure, not dehumanizing group-based language with hostile intent toward a protected group. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_346_k2", "example_id": "train_346", "text": "Deport him in military aircraft and dump him back where he is originated from. Him and his family", "label": 0, "reasoning": "Applying Rule 001: The text uses 'dump him back where he is originated from' which implies deportation based on origin, targeting an individual and their family with group-based implications (national/ethnic origin). However, it lacks dehumanizing terms like 'pigs' or 'retarded', and while hostile, it targets specific individuals ('him and his family') rather than making derogatory generalizations about a protected group. The language suggests removal but not elimination, inferiority, or violence toward a group. Exceptions apply as it criticizes individuals without invoking group-based hostility or stereotypes. Applying Rule 002: Similar analysis - no dehumanizing terms or group-based derogatory generalizations; targets individual behavior (presumably immigration status) without promoting hostility toward a protected group. Applying Rule 003: No dehumanizing terms, metaphorical slurs, or suggestions of elimination/inferiority/violence toward a group; targets individuals, not a protected group. All rules indicate classification as 0 due to individual targeting and absence of group-based hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_347_k0", "example_id": "train_347", "text": "This fuckhead makes me ashamed of being Jewish. Shit people like him are destroying everything", "label": 0, "reasoning": "Applying Rule 001: The text contains offensive language ('fuckhead', 'shit people') directed at an individual ('him') and expresses personal shame about being Jewish. However, it does not use dehumanizing terms targeting a protected group, make derogatory generalizations about Jews as a group, suggest violence or elimination toward Jews, or reinforce harmful stereotypes about Jews. The criticism appears directed at an individual's behavior ('makes me ashamed', 'destroying everything') without invoking group-based hostility toward Jews. Applying Rule 002: Similar analysis - while offensive, the language targets an individual's perceived negative impact rather than making group-based derogatory statements about Jews. The expression of personal shame about one's own identity doesn't constitute hate speech toward that group. Applying Rule 003: The text lacks the key indicators for hate speech: no dehumanizing terms targeting protected groups, no suggestions of elimination/inferiority/violence toward Jews as a group, and no reinforcement of harmful stereotypes in a hostile context. The target is an individual ('him') without reference to group identity beyond the speaker's personal feelings.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_348_k0", "example_id": "train_348", "text": "Is that the dude who walked into the room, kissed the girl on the cheek, then left?", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It describes a neutral sequence of actions without any group targeting, hostile intent, or reinforcement of harmful stereotypes. No exceptions apply as there is no offensive language present. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations, or violent suggestions directed at any protected group. It describes individual behavior without group-based hostility. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. It focuses on specific individual actions without metaphorical slurs or suggestions of elimination/inferiority toward any group. All rules indicate this is non-hateful speech as it contains no elements triggering hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_349_k0", "example_id": "train_349", "text": "stone throwing must be legal when against women", "label": 1, "reasoning": "I will analyze the text 'stone throwing must be legal when against women' using all three rules from the rulebook. Rule 001, 002, and 003 all share the same trigger pattern: dehumanizing/derogatory group-based language with hostile intent, targeting protected groups. The text explicitly targets 'women' as a protected gender group and advocates for violence ('stone throwing') against them. This meets key indicators: (1) it suggests violence toward a group, (2) it reinforces harmful stereotypes by implying women deserve violence, and (3) it has hostile intent by calling for legalization of violence. None of the exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; it's not targeting individual behavior without group reference. Therefore, all three rules apply, classifying this as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_350_k0", "example_id": "train_350", "text": "I ship you guys please get back together", "label": 0, "reasoning": "Applying Rule 001: The text 'I ship you guys please get back together' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses a positive sentiment about wanting people to reunite ('ship' meaning support for a relationship). There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is colloquial and affectionate, not hostile. Applying Rule 002: No dehumanizing language or group-based derogatory generalizations are present. The text targets no protected group and lacks intent to dehumanize any identity-based community. Applying Rule 003: No trigger patterns are met - no slurs, elimination suggestions, or hostile stereotypes. The context is supportive and personal, not hateful. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_351_k0", "example_id": "train_351", "text": "Thank you John, for sharing this experience with us, people. What I wanna say to refugees is, stay strong! Although our current president is... failing to help you, I will be there at Washington DC protesting for you. The people who suffered the most should be saved from evil!", "label": 0, "reasoning": "Applying Rule 001: The text expresses support for refugees, using encouraging language ('stay strong') and promising advocacy ('protesting for you'). It criticizes a political figure ('current president is... failing to help you') but this is directed at an individual in a role, not a protected group. No dehumanizing terms, derogatory generalizations, violent suggestions, or group targeting are present. The text promotes helping refugees ('should be saved from evil'), which aligns with positive intent toward the group. Rule 001 exceptions apply as the criticism is of an individual (the president) without group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text targets individual political failure rather than a protected group identity. Applying Rule 003: Same conclusion - no trigger patterns are met; the language is supportive rather than hostile, and any criticism is directed at an individual political figure, not a protected group. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_352_k0", "example_id": "train_352", "text": "My car is my love of my life. I fucking love this bitch. It's fast and it makes me feel complete", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'bitch' which could potentially be considered derogatory language. However, examining the context: (1) The term 'bitch' is used metaphorically to refer to a car, not targeting any protected group (racial, gender, religious, national, or sexual orientation). (2) There is no suggestion of elimination, inferiority, or violence toward any group. (3) The language expresses affection toward an inanimate object ('my car is my love of my life'), not hostility toward people. This falls under the exception for metaphorical use targeting non-group-based entities. Applying Rule 002: Similar analysis applies - the term 'bitch' is not used in a group-targeting manner with hostile intent. The text expresses personal affection for a car, not derogatory generalizations about protected groups. Applying Rule 003: Again, the term is used metaphorically (referring to a car), not targeting any protected group identity. The context is clearly non-hostile and expresses positive sentiment. All three rules indicate this should be classified as non-hate speech due to metaphorical use targeting a non-group entity (a car) without any group-based hostility or dehumanizing intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_353_k0", "example_id": "train_353", "text": "Equal pay message, um, says the guy who want socialism in the United States of America", "label": 0, "reasoning": "Applying Rule 001: The text criticizes an individual ('the guy') for advocating socialism while discussing equal pay. There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The target is an individual's political stance without reference to group identity (e.g., nationality, race, gender). The language is not metaphorical slurs, does not suggest elimination/inferiority/violence toward a group, and does not reinforce harmful stereotypes in a hostile context. Exceptions apply as this targets an individual without invoking group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The criticism is directed at individual behavior (political advocacy) without targeting a protected group or promoting generalized hostility. Applying Rule 003: Same conclusion - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The language criticizes an individual without reference to group identity. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_354_k0", "example_id": "train_354", "text": "Anxiety is is the definition of a human meme. Anxiety disorders are an excuse. No such thing.", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'meme' metaphorically to describe anxiety and states 'anxiety disorders are an excuse' and 'no such thing.' This targets individuals with anxiety disorders, but does not use dehumanizing terms like 'pigs' or 'retarded,' nor does it make derogatory generalizations about a protected group (e.g., racial, gender, religious). The criticism is directed at the concept of anxiety disorders and perceived individual behavior (using it as an 'excuse'), without linking to a broader protected group or promoting group-based inferiority, violence, or dehumanization. It lacks hostile intent toward a protected group and does not reinforce harmful stereotypes in a hostile context. Applying Rule 002: Similar analysis applies; the text does not use dehumanizing terms or target a protected group, focusing instead on individual behavior related to mental health conditions without generalized hostility. Applying Rule 003: The text uses metaphorical language ('human meme') but targets anxiety disorders, not a protected group, and lacks elements like slurs, suggestions of elimination, or violence toward a group. Therefore, none of the rules trigger a label of 1, as the text is non-hateful under the exceptions for individual behavior criticism without group-based targeting.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_355_k0", "example_id": "train_355", "text": "I want to draw you something but I do not know where to send it. Do you have an instagram? ^^", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms ('pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It is a friendly inquiry about sharing artwork via Instagram, with no group targeting or hostile intent. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no trigger patterns present. The text lacks any indicators of dehumanizing language, group-based targeting, or hostile context. Applying Rule 003: Same analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions. The text targets no individual or group with hostility. All rules indicate the text is non-hateful as it contains none of the specified trigger patterns.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_356_k0", "example_id": "train_356", "text": "HE SHOT THE KID!?!? HE SHOT THE EFFIN KID!!!! BOI YOU BETTER SLEEP WITH ONE EYE OPEN BECAUSE IMMA WHOOP YOUR STUPID LITTLE BUTT TILL YOU WISH YOU WERE NEVER BORN YA HERE ME!!!! WITHERED SHALL BE AVENGED!!!!", "label": 0, "reasoning": "Analyzing the text using all relevant rules from the rulebook: 1. The text contains aggressive language ('IMMA WHOOP YOUR STUPID LITTLE BUTT TILL YOU WISH YOU WERE NEVER BORN') and threats ('BETTER SLEEP WITH ONE EYE OPEN'). 2. Rule 001, 002, and 003 all require: (a) dehumanizing/derogatory terms targeting a protected group, (b) violent suggestions with group targeting, or (c) reinforcement of harmful stereotypes about protected groups. 3. The text targets an individual ('YOU') based on a specific action ('HE SHOT THE KID'), not a protected group identity (racial, gender, religious, national, or sexual orientation). 4. The language, while violent and threatening, is directed at an individual perpetrator without invoking group-based hostility or stereotypes. 5. No dehumanizing terms like 'pigs' or 'retarded' are used against protected groups. 6. The exception in all rules applies: 'if the target is an individual without reference to group identity' or 'if the language criticizes individuals... without linking them to a broader protected group.' Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_357_k0", "example_id": "train_357", "text": "why am i watching this", "label": 0, "reasoning": "Applying Rule 001: The text 'why am i watching this' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence toward any group, and no reinforcement of harmful stereotypes. The text appears to be a personal expression of confusion or boredom about content consumption, targeting no individual or group. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. There is no indication of hostile intent toward any protected group. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. The language is not metaphorical criticism of non-group entities and targets no individual with group identity references. All rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_358_k0", "example_id": "train_358", "text": "For the static sound - what do you use for editing? I know it'¬Ä¬ôs annoying but if you use premiere pro you should be able to use decrackling to help a bit", "label": 0, "reasoning": "Applying Rule 1: The text discusses technical editing advice for static sound in video editing software (Premiere Pro), specifically mentioning 'decrackling' as a solution. There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting. The language is technical and instructional. Applying Rule 2: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions toward any group. It focuses on technical editing advice. Applying Rule 3: The text has no dehumanizing language, group-based targeting, or hostile intent. It's a neutral technical discussion about audio editing. None of the rules trigger because the content is purely technical and unrelated to hate speech indicators.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_359_k0", "example_id": "train_359", "text": "What type of question it is???????", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text 'What type of question it is???????' contains no dehumanizing language, no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), no violent suggestions, and no group targeting. It is a neutral inquiry about question classification with no hostile intent or context. None of the trigger patterns in any rule apply, and there are no exceptions to consider since the text lacks any offensive content. Therefore, based on all rules, this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_360_k0", "example_id": "train_360", "text": "Red pill activism should be a thing.", "label": 0, "reasoning": "Analyzing the text 'Red pill activism should be a thing.' using the provided rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text mentions 'red pill activism,' which is a metaphorical reference to political or ideological awakening (often associated with anti-establishment or conservative movements), but does not contain any dehumanizing language (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), or violent suggestions. There is no indication of targeting a protected group, promoting elimination, inferiority, or violence toward a group, or reinforcing harmful stereotypes in a hostile context. The language is metaphorical but criticizes non-group-based entities (activism or ideologies), not a protected group. Therefore, none of the rules apply, and the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_361_k0", "example_id": "train_361", "text": "He seems like the very talkative taxi driver", "label": 0, "reasoning": "Applying Rule 001: The text 'He seems like the very talkative taxi driver' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It describes an individual's behavior (being talkative) in a specific role (taxi driver) without any group targeting, hostile intent, or reinforcement of harmful stereotypes. The term 'taxi driver' refers to a profession, not a protected group. No exceptions apply as there is no offensive language present. Applying Rule 002: No dehumanizing language, group-based targeting, or hostile intent is present. The comment is about individual behavior without targeting any protected group. Applying Rule 003: No triggers are met - no slurs, suggestions of elimination/inferiority/violence, or harmful stereotypes in hostile context. The language is descriptive and neutral, targeting an individual in a professional role without group reference. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_362_k0", "example_id": "train_362", "text": "So sorry about this bombing attack in Manchester. Innocent people just died", "label": 0, "reasoning": "Applying Rule 001: The text expresses sympathy for victims of a bombing attack in Manchester, stating 'Innocent people just died.' There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions. The text does not target any group with hostile intent, use slurs, suggest elimination/inferiority/violence toward a group, or reinforce harmful stereotypes. It is a compassionate statement about victims of violence. Applying Rule 002: Same analysis - no dehumanizing terms, group-based derogatory language, or violent suggestions with group targeting. The text lacks indicators like non-literal slurs or suggestions of elimination toward groups. Applying Rule 003: Same analysis - the text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. It does not metaphorically criticize non-group entities in a hateful way. All three rules indicate this is not hate speech as it lacks the required elements of group-based hostility, dehumanization, or violent intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_363_k0", "example_id": "train_363", "text": "GUN SHOT INA YU HEAD! NO MERCY!", "label": 0, "reasoning": "Applying Rule 001: The text contains violent suggestions ('GUN SHOT INA YU HEAD! NO MERCY!') but lacks group targeting. There is no mention of protected groups (racial, gender, religious, national, sexual orientation), no dehumanizing terms targeting groups, and no reinforcement of harmful stereotypes about groups. The violent language appears directed at an unspecified individual or general target without group-based hostility. According to Rule 001 exceptions, this does not apply as it targets individuals without reference to group identity. Applying Rule 002: Similar analysis - violent suggestions exist but without group targeting or derogatory generalizations about protected groups. The exception for individual targeting applies. Applying Rule 003: Same analysis - violent language without group targeting or protected group references. The exception for individual targeting without group identity applies. All three rules require combination of violent suggestions with group targeting to trigger hate speech classification, which is absent here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_365_k0", "example_id": "train_365", "text": "Now the sea is filled with disgusting dead filth like them. Ruined my Mediterranean vacations", "label": 0, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('disgusting dead filth') and targets 'them' as a group. However, it lacks specific reference to a protected group (racial, gender, religious, national, sexual orientation) - 'them' could refer to various entities like pollution, marine debris, or unspecified individuals. Without clear group targeting of a protected class, this falls under the exception for non-group-based entities or individual targeting. The hostile context appears directed at ruining vacations rather than promoting violence/elimination against a protected group. Applying Rule 002: Similar analysis - while derogatory language is present, there's no clear targeting of a protected group with hostile intent toward that group's identity. Applying Rule 003: The metaphorical use of 'filth' targets unspecified entities ruining vacations, not a protected group. All rules indicate this doesn't meet the threshold for hate speech classification as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_366_k0", "example_id": "train_366", "text": "It’s not “genderless” they just look like GIRLS", "label": 0, "reasoning": "Analyzing the text 'It’s not “genderless” they just look like GIRLS' against the provided rulebook: \n1. Rule 001: The text does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It comments on appearance and gender presentation without targeting a protected group with hostile intent. No exceptions apply as there is no group-based hostility.\n2. Rule 002: Similar to Rule 001, the text lacks dehumanizing language, derogatory generalizations, or violent suggestions toward a protected group. It focuses on individual or general appearance without promoting group-based inferiority or violence.\n3. Rule 003: The text does not trigger this rule as it does not contain slurs, suggestions of elimination, or reinforcement of harmful stereotypes in a hostile context. The mention of 'GIRLS' is not used in a derogatory or dehumanizing manner toward a gender group.\nOverall, the text expresses an opinion about gender presentation but does not meet the criteria for hate speech under any rule, as it lacks group targeting, hostile intent, dehumanizing language, or violent suggestions.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_367_k0", "example_id": "train_367", "text": "Beautiful in every way!", "label": 0, "reasoning": "Applying Rule 001: The text 'Beautiful in every way!' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It lacks group targeting, hostile intent, and does not reinforce harmful stereotypes. The language is positive and complimentary without any indication of metaphorical slurs or suggestions of elimination, inferiority, or violence toward any group. No exceptions need to be considered as the rule does not trigger. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. It does not use non-literal or metaphorical slurs, suggest elimination or inferiority toward a group, or reinforce harmful stereotypes in a hostile context. The rule does not apply. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. It lacks key indicators such as non-literal slurs, suggestions of elimination or violence toward a group, or reinforcement of harmful stereotypes. The rule does not apply. All rules consistently indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_368_k0", "example_id": "train_368", "text": "well it's clear now why europeans can't differ niggers and shitskins from human", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing terms 'niggers' and 'shitskins' which are derogatory racial slurs targeting protected groups. It makes a derogatory generalization about Europeans' ability to distinguish these groups from humans, implying inferiority and dehumanization. This is group-based targeting with hostile intent, not metaphorical, reclaimed, clinical, historical, satirical, or individual-focused. No exceptions apply. Applying Rule 002: Same analysis - dehumanizing terms, derogatory generalizations about racial groups, suggestion of inferiority in hostile context. No exceptions apply as this is not about individual behavior. Applying Rule 003: Same analysis - dehumanizing terms, group targeting, hostile context reinforcing harmful stereotypes. No exceptions apply. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_369_k0", "example_id": "train_369", "text": "Should'¬Ä¬ôve set a bug bomb off and locked them in", "label": 0, "reasoning": "Applying Rule 001: The text 'Should'¬Ä¬ôve set a bug bomb off and locked them in' contains violent suggestions ('set a bug bomb off and locked them in') which could imply elimination or harm. However, the target 'them' is ambiguous and not explicitly linked to any protected group (racial, gender, religious, national, sexual orientation). Without clear group targeting or dehumanizing terms toward a protected group, this does not meet the trigger pattern. The exceptions apply as the language appears metaphorical or directed at unspecified individuals rather than promoting group-based hostility. Applying Rule 002: Similar analysis - lacks derogatory generalizations about a protected group or clear group targeting. The violent suggestion is present but not combined with group-based language as defined. Applying Rule 003: Same conclusion - no dehumanizing terms or group targeting toward protected groups identified. The text may be offensive but does not meet the criteria for hate speech under these rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_370_k0", "example_id": "train_370", "text": "It numbs them to the disgusting degeneracy and fruitless hedonism of faggot sex", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'faggot', which is a derogatory slur targeting the LGBTQ+ community (a protected group based on sexual orientation). The language describes their sexuality as 'disgusting degeneracy and fruitless hedonism', which reinforces harmful stereotypes and suggests inferiority and moral condemnation toward the group. This meets the trigger pattern of using derogatory generalizations about a protected group with hostile intent. No exceptions apply - this is not reclaimed usage (not self-referential), not clinical/historical context, not satirical critique of hate speech, and not targeting individuals without group reference. The text clearly targets the LGBTQ+ community as a group with dehumanizing language. Applying Rule 002: Same analysis applies - derogatory term targeting protected group with hostile intent, no exceptions for individual behavior targeting. Applying Rule 003: Same analysis applies - derogatory group-based language with hostile intent, no exceptions for metaphorical use or individual targeting. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_372_k0", "example_id": "train_372", "text": "So, in other words, women's rights are freedom from responsibility and men's rights are responsibility. Is she serious?", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text 'So, in other words, women's rights are freedom from responsibility and men's rights are responsibility. Is she serious?' does not trigger any of the rules. It contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. The comment criticizes a perceived viewpoint about gender roles but does so without using hostile language, suggesting elimination or inferiority, or reinforcing harmful stereotypes in a hostile context. The target appears to be an individual's statement ('Is she serious?') rather than a protected group as a whole. While the content involves gender, it lacks the group-based targeting with hostile intent required by all three rules. The exceptions in all rules apply as the language is not dehumanizing, derogatory, or violent toward a protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_373_k0", "example_id": "train_373", "text": "Every time that blonde lady talks I loose twenty brain cells", "label": 0, "reasoning": "Applying Rule 001: The text uses the phrase 'blonde lady' which could potentially reference gender (women) or hair color. However, the criticism targets an individual ('that blonde lady') based on perceived intelligence ('I loose twenty brain cells'), not a protected group. There is no dehumanizing language, derogatory generalizations about women as a group, violent suggestions, or reinforcement of harmful stereotypes. The comment appears to criticize an individual's speech patterns without invoking group-based hostility. Rule 001 exceptions apply as this targets an individual without reference to group identity. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions toward a group. The criticism is directed at individual behavior (speaking style) without targeting a protected group. Applying Rule 003: Same conclusion - metaphorical criticism of an individual's intelligence, not group-based targeting. No protected group is being dehumanized or subjected to hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_374_k1", "example_id": "train_374", "text": "citronella is a great venezuelan repellent", "label": 0, "reasoning": "Applying Rule 001: The text 'citronella is a great venezuelan repellent' contains the term 'venezuelan' which refers to a national group. However, I must check if it meets the trigger pattern: (1) It does not use dehumanizing terms like 'pigs' or 'retarded', (2) It does not suggest elimination, inferiority, or violence toward Venezuelans as a group, (3) It does not reinforce harmful stereotypes in a hostile context. The phrase appears to be a play on words comparing Venezuelans to insects that citronella repels, but without clear hostile intent or derogatory generalization. No exceptions apply as this is not reclaimed, clinical, historical, or satirical critique. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The comment lacks indicators of hostile intent toward Venezuelans as a protected group. Applying Rule 003: Same conclusion - while 'venezuelan repellent' could be interpreted metaphorically, it targets a national group but without the required elements of dehumanization, violence, or harmful stereotype reinforcement in a hostile context. The text is ambiguous but does not clearly meet the threshold for hate speech under any rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_375_k0", "example_id": "train_375", "text": "No body can change their biological sex, but they can change their gender.", "label": 0, "reasoning": "Analyzing the text 'No body can change their biological sex, but they can change their gender.' against the provided rulebook: Rule 1, Rule 2, and Rule 3 all require dehumanizing terms, derogatory generalizations about protected groups, violent suggestions, or reinforcement of harmful stereotypes with hostile intent. The text makes a factual statement about biological sex versus gender identity without using any dehumanizing language (no terms like 'pigs', 'retarded'), no derogatory generalizations about protected groups (no targeting of racial, gender, religious, national, or sexual orientation groups), no violent suggestions, and no hostile context. It does not suggest elimination, inferiority, or violence toward any group. The statement is neutral in tone and could be interpreted as acknowledging gender identity separate from biological sex. None of the rules trigger because there is no group-based targeting with hostile intent, no slurs, and no harmful stereotypes being reinforced. Therefore, applying all relevant rules, this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_376_k0", "example_id": "train_376", "text": "In a world full of hate remember to light up the darkness, as this world is but temporary.", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. The text 'In a world full of hate remember to light up the darkness, as this world is but temporary' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, or sexual orientation), and no violent suggestions (e.g., 'gas yourself'). It does not target any group, reinforce harmful stereotypes, or show hostile intent. Instead, it promotes positivity ('light up the darkness') and reflects on the temporary nature of the world. None of the rule triggers apply, and no exceptions are relevant as there is no offensive language to evaluate. Therefore, the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_377_k0", "example_id": "train_377", "text": "So can I put a wig and run with girls?", "label": 0, "reasoning": "Applying Rule 001: The text 'So can I put a wig and run with girls?' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It does not target any racial, gender, religious, national, or sexual orientation group with hostile intent. The phrase 'run with girls' could be interpreted as referring to women or girls, but there is no language suggesting elimination, inferiority, violence, or reinforcement of harmful stereotypes. The context appears to be a hypothetical question about cross-dressing or participation, lacking hostile group-based targeting. Applying Rule 002: No dehumanizing terms or derogatory generalizations about protected groups are present. The text does not suggest violence or elimination toward any group. Applying Rule 003: Similar to Rule 001, the text lacks dehumanizing language, group targeting with hostile intent, or suggestions of violence. The question format and absence of slurs or stereotypes indicate it is not hate speech under any rule. All rules require dehumanizing terms, derogatory generalizations, or violent suggestions combined with group targeting, none of which are present here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_378_k0", "example_id": "train_378", "text": "They hate: dogs, women, gays, christians, jews and infidels. Sure, let them all in. Only 250,000,000 want to kill us.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory generalizations about multiple protected groups (women, gays, Christians, Jews) in combination with group targeting. It suggests elimination ('want to kill us') and reinforces harmful stereotypes about these groups having hostile intent. There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech. The language is not metaphorical criticism of non-group entities, nor is it targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about protected groups with hostile intent, specifically suggesting violence toward 'us' (implied group). There is no targeting of individual behavior without group reference. Applying Rule 003: The text uses derogatory group-based language with hostile intent, suggesting elimination and violence toward protected groups. No exceptions apply as the context is not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or individual-focused. All three rules indicate this is hate speech due to derogatory generalizations about protected groups combined with violent suggestions and group targeting.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_379_k0", "example_id": "train_379", "text": "What would the abuser doing to her around the neck? Stupid dick (the abuser)", "label": 0, "reasoning": "Applying Rule 001: The text contains derogatory language ('stupid dick') directed at an individual (the abuser) without reference to any protected group identity. The target is a specific person based on their abusive behavior, not a racial, gender, religious, national, or sexual orientation group. There is no dehumanizing group-based language, violent suggestions toward a group, or reinforcement of harmful stereotypes about protected groups. The exception for 'individual without reference to group identity' applies. Applying Rule 002: The derogatory term targets individual behavior (abuse) without targeting a protected group or promoting generalized hostility toward an identity-based community. Applying Rule 003: The language criticizes an individual (the abuser) without group targeting or metaphorical use against protected groups. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_382_k0", "example_id": "train_382", "text": "Awful. Such a terror coming from nowhere. Felt for him", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms ('pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. The terms 'awful' and 'terror' appear to describe a situation or event, not target any group. There is no indication of group targeting, elimination rhetoric, or reinforcement of harmful stereotypes. The phrase 'felt for him' suggests empathy rather than hostility. Applying Rule 002: Similar analysis - no dehumanizing language targeting protected groups, no suggestions of violence toward groups, and no hostile intent directed at identity-based communities. Applying Rule 003: Again, no dehumanizing terms with group targeting, no metaphorical slurs used against protected groups, and the language appears to describe an event or situation rather than target individuals based on group identity. All three rules indicate this text does not meet the criteria for hate speech as it lacks the required elements of dehumanizing group-based language with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_383_k0", "example_id": "train_383", "text": "sons of bitches", "label": 0, "reasoning": "Applying Rule 001: The text 'sons of bitches' contains derogatory language ('bitches'), but it lacks group targeting toward a protected group (racial, gender, religious, national, sexual orientation). The phrase is a general insult without specifying any protected group identity or making generalizations about such groups. There is no indication of hostile intent toward a protected group, no suggestion of elimination, inferiority, or violence toward a group, and no reinforcement of harmful stereotypes in a hostile context. The language could be directed at individuals or non-group entities. Applying Rule 002: Similar analysis - the text uses derogatory language but without group targeting or hostile intent toward a protected group. No dehumanizing terms are applied to a protected group. Applying Rule 003: Same conclusion - while the language is offensive, it does not meet the trigger pattern of targeting a protected group with hostile intent. The phrase is a general insult that could be directed at individuals without reference to group identity.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_384_k0", "example_id": "train_384", "text": "It should be humanity first before any country", "label": 0, "reasoning": "Applying Rule 001: The text 'It should be humanity first before any country' does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses a philosophical position about prioritizing human welfare over national interests without targeting any specific group. There is no use of slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes. The statement is general and abstract, not hostile toward any protected identity. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The text discusses concepts rather than attacking identities. Applying Rule 003: Same analysis - the language is not metaphorical criticism of non-group entities nor individual targeting; it's a neutral statement about values. None of the rules trigger because the text lacks all key indicators: (1) no non-literal/metaphorical slurs, (2) no suggestion of elimination/inferiority/violence toward groups, (3) no reinforcement of harmful stereotypes in hostile context. The exceptions don't apply as there's no offensive language to begin with.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_385_k0", "example_id": "train_385", "text": "To say that black lives matter, is not racist statement. But the B.L.M. organization itself is racist group. If they could just quit hating white people and turn that energy towards their own community, the biggest group of black oppressors there is, they might make a difference.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes the BLM organization, not black people as a protected group. It makes claims about the organization's alleged racism toward white people and suggests they redirect energy toward 'their own community' and 'black oppressors.' While this contains negative commentary about an organization, it does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The criticism targets organizational behavior and perceived hypocrisy, not black people as a racial group. No suggestion of elimination, inferiority, or violence toward a protected group is present. The phrase 'black oppressors' refers to specific individuals within the community, not a generalization about all black people. Applying Rule 002: Similar analysis - no dehumanizing language or group-based hostility toward protected groups. The text discusses organizational racism and community issues without promoting violence or stereotypes against protected identities. Applying Rule 003: Again, no dehumanizing terms, violent suggestions, or derogatory generalizations about protected groups. The criticism remains focused on an organization and specific community dynamics rather than attacking racial, gender, religious, national, or sexual orientation groups. All rules indicate this does not meet the threshold for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_386_k0", "example_id": "train_386", "text": "The girl in the dress reminds me of opal from bird box", "label": 0, "reasoning": "Applying Rule 001: The text 'The girl in the dress reminds me of opal from bird box' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes a neutral comparison to a fictional character from a movie ('bird box' likely refers to the film 'Bird Box'). There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is descriptive and non-hostile. Applying Rule 002: No dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups are present. The comment is about an individual ('the girl') without reference to group identity. Applying Rule 003: Same analysis as Rule 001 - no trigger patterns are met, and the language is not metaphorical criticism of non-group entities. All rules indicate this text does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_387_k0", "example_id": "train_387", "text": "I hate mentally disabled people trying to touch my kids.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('mentally disabled people') targeting a protected group (people with disabilities) with hostile intent ('I hate...') and implies a harmful stereotype about them being dangerous to children ('trying to touch my kids'). This constitutes group-based targeting with dehumanizing implications. None of the exceptions apply: it's not reclaimed/self-referential, not clinical/historical discussion, not satirical critique, not metaphorical criticism of non-group entities, and not targeting individual behavior without group reference. Applying Rule 002: Same analysis applies - derogatory generalization about protected group with hostile intent. No exception for individual behavior targeting since it generalizes about 'mentally disabled people' as a group. Applying Rule 003: Same analysis applies - group targeting with derogatory language and hostile context. No exceptions for metaphorical use or individual targeting without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_388_k0", "example_id": "train_388", "text": "Islam is hell .  We Asian hate isalm...Islam bring only destruction..killing.  rape... rufugee.... Islam is hell .. Asian thought √∞¬ü¬ò¬Ç√∞¬ü¬ò¬Çsorry...but is true", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about a protected religious group (Islam) with hostile intent. It uses dehumanizing language ('Islam is hell'), makes sweeping negative claims ('Islam bring only destruction..killing. rape... rufugee'), and reinforces harmful stereotypes about Muslims. The statement 'We Asian hate isalm' indicates group-based targeting. None of the exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected religious group with hostile intent, suggesting inferiority and harm. The exceptions don't apply as this isn't criticism of individual behavior. Applying Rule 003: The text contains dehumanizing language ('Islam is hell') and derogatory generalizations about a protected religious group with hostile context. No exceptions apply as this isn't metaphorical criticism of non-group entities or individual targeting. All three rules indicate this is hate speech due to group-based derogatory language with hostile intent targeting a protected religious group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_389_k0", "example_id": "train_389", "text": "I visited Melbourne from Los Angeles the first time in 2012.  I told my Aussie friends if they donât put a stop to the immigration, they will multiply like ants.   They laughed at me saying Oz is a big country.  I told them they have to look at it in terms of 50 years from now.  Being from LA, I see what the Mexicans have done to to this city.  Awful.   They multiply like ants and suck up the resources. $$$", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about immigrants ('Mexicans') using dehumanizing language ('multiply like ants', 'suck up the resources') with hostile intent. This targets a national/ethnic group (Mexicans) and reinforces harmful stereotypes about resource consumption and reproduction. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The comparison to ants is dehumanizing and suggests elimination/inferiority. Applying Rule 002: Same analysis - dehumanizing terms targeting a protected group (national origin) with hostile generalizations. Applying Rule 003: Same analysis - derogatory group-based language with hostile intent targeting Mexicans as a group. The text expresses clear group-based hostility toward immigrants/Mexicans rather than criticizing individual behavior.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_390_k0", "example_id": "train_390", "text": "Good for him! That's an EDUCATED man, right there!", "label": 0, "reasoning": "Applying Rule 001: The text 'Good for him! That's an EDUCATED man, right there!' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It praises an individual ('him') with positive language ('Good for him!', 'EDUCATED man') without any group targeting, hostile intent, or reinforcement of harmful stereotypes. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing terms, group-based derogatory language, or violent suggestions targeting protected groups. The comment focuses on individual praise without group hostility. Applying Rule 003: Same analysis - no trigger patterns present. The text is positive and individual-focused without metaphorical slurs, elimination suggestions, or stereotypical hostility toward any protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_391_k0", "example_id": "train_391", "text": "they could have shot him in the legs no one gets in risk of dying", "label": 0, "reasoning": "Analyzing the text 'they could have shot him in the legs no one gets in risk of dying' against the rulebook: 1. The text discusses shooting someone in the legs as an alternative to potentially lethal force, but does not use dehumanizing terms like 'pigs' or 'retarded'. 2. There is no mention of protected groups (racial, gender, religious, national, sexual orientation) - the target appears to be an individual 'him'. 3. No derogatory generalizations about groups are present. 4. No violent suggestions targeting groups (e.g., 'gas yourself', 'hope to distinct soon'). 5. The language is literal discussion of police/defensive tactics, not metaphorical slurs. 6. No suggestion of elimination, inferiority, or violence toward a protected group. 7. No reinforcement of harmful stereotypes in hostile context. 8. The text targets an individual scenario without group-based hostility. According to Rule 001: Does not apply as no dehumanizing/derogatory group-based language with hostile intent. According to Rule 002: Does not apply as no dehumanizing terms or group targeting. According to Rule 003: Does not apply as no dehumanizing language targeting protected groups. The text discusses use of force against an individual, not hate speech against protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_392_k0", "example_id": "train_392", "text": "relax and do something...wink wink. hahahahaha! totally enjoying your videos! you both are super yummy!", "label": 0, "reasoning": "Applying Rule 001: The text uses casual, flirtatious language ('wink wink', 'super yummy') directed at individuals ('you both') without any dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is playful and complimentary, not hostile. Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions are present. The text targets specific individuals in a positive manner without any group-based hostility. Applying Rule 003: Similar to Rule 001, the text lacks dehumanizing language, group targeting, or hostile context. The metaphorical use of 'yummy' is affectionate and directed at individuals, not a protected group. All rules indicate the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_393_k0", "example_id": "train_393", "text": "It's simple. Ask a person if they're Asian. If the first words out of their mouths are anything other than yes, they are not Asian", "label": 0, "reasoning": "Applying Rule 001: The text makes a generalization about Asian people, suggesting a test to determine if someone is Asian based on their immediate response. This could be interpreted as reinforcing stereotypes about Asian identity or behavior. However, the text does not use dehumanizing terms (like 'pigs' or 'retarded'), does not suggest elimination, inferiority, or violence toward the group, and lacks hostile intent. The statement appears to be making an observation or generalization rather than expressing hostility. The exception for non-group-based targeting or non-hostile context may apply here, as the text seems descriptive rather than derogatory. Applying Rule 002: Similar analysis - the text references a protected group (Asian/national origin) but does not use derogatory language or suggest harm. The exception for criticism directed at individual behavior without group-based hostility applies, as the text focuses on a hypothetical individual's response rather than attacking the group. Applying Rule 003: Again, while referencing a protected group, the text lacks dehumanizing terms, violent suggestions, or hostile context. The metaphorical/satirical exception doesn't clearly apply, but the text doesn't meet the trigger pattern's requirements for hostility or derogatory intent. Overall, the text makes a generalization but without the key indicators of hate speech as defined in the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_394_k0", "example_id": "train_394", "text": "This reminds me of me & my husband. I have rheumatoid arthritis & permanent damage in my ankles. I could not walk for 4 days recently AT ALL. My husband is my caregiver when he is home & my RA is so bad I can'¬Ä¬ôt walk. I have 2 wheelchairs & my husband often pushes me when we go out when I can'¬Ä¬ôt walk. I have canes EVERYWHERE. These 2 are SO CUTE! She is lucky to have him to reassure her. He'¬Ä¬ôs lucky to have her to laugh with.", "label": 0, "reasoning": "Applying Rule 001: The text describes personal experiences with rheumatoid arthritis and disability, using terms like 'wheelchairs' and 'canes' in a factual, non-derogatory context. There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions. The text expresses positive sentiments about relationships and support, with no hostile intent toward any group. The language is self-referential and descriptive of individual circumstances without targeting any protected group. Applying Rule 002: The text discusses disability in a personal context without derogatory generalizations or suggestions of elimination, inferiority, or violence. It lacks group targeting and hostile intent. Applying Rule 003: Similar analysis - no dehumanizing terms, no group-based hostility, and the context is personal narrative rather than hateful commentary. All rules indicate this is non-hateful as it contains no triggering patterns and falls under exceptions for non-hostile, individual-focused content.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_395_k0", "example_id": "train_395", "text": "I work 10 hour shifts starting at 4 am. I don't know if I can effectively cut caffeine.", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses personal work hours and caffeine consumption without targeting any group or individual with hostile intent. No exceptions apply as there is no offensive language present. Applying Rule 002: The text lacks dehumanizing language, group targeting, or suggestions of violence/elimination. It focuses on individual work experience without reference to protected groups. Applying Rule 003: The text contains no slurs, stereotypes, or hostile context toward any group. It is a personal statement about work schedule and caffeine use. All rules indicate this is non-hateful speech as it contains no elements triggering hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_396_k0", "example_id": "train_396", "text": "The wheelchaired woman was actually scary", "label": 0, "reasoning": "Applying Rule 001: The text 'The wheelchaired woman was actually scary' contains a reference to disability ('wheelchaired'), but does not use dehumanizing terms like 'pigs' or 'retarded', nor does it contain derogatory generalizations about people with disabilities as a protected group. The text describes an individual woman's appearance as 'scary' without suggesting elimination, inferiority, or violence toward disabled people as a group. It lacks hostile intent, reinforcement of harmful stereotypes, or group targeting. The criticism appears directed at an individual's appearance/behavior without invoking group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions targeting a protected group. The comment targets an individual ('the woman') without promoting generalized hostility toward people with disabilities. Applying Rule 003: Same conclusion - the language describes an individual without group targeting, metaphorical slurs, or suggestions of elimination/inferiority toward a protected group. None of the rules trigger as the text lacks the required elements of dehumanizing language with hostile intent toward a protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_397_k0", "example_id": "train_397", "text": "buddhism and its people reminds off cows.", "label": 1, "reasoning": "Applying Rule 001: The text 'buddhism and its people reminds off cows' uses dehumanizing language ('cows') targeting a religious group (Buddhism and its followers). This constitutes derogatory generalization about a protected group (religious) with implied inferiority. No exceptions apply - it's not reclaimed, clinical, historical, or satirical context; not metaphorical criticism of non-group entities; and targets the group collectively rather than specific individuals. Applying Rule 002: Same analysis - dehumanizing term ('cows') targeting religious group with implied inferiority. No exception for individual behavior targeting applies. Applying Rule 003: Same analysis - dehumanizing language targeting religious group with implied inferiority. No exceptions for reclaimed use or metaphorical non-group criticism apply. All three rules indicate hate speech due to dehumanizing group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_398_k0", "example_id": "train_398", "text": "I would prefer a phallic world", "label": 0, "reasoning": "Applying the rulebook: Rule 001, Rule 002, and Rule 003 all focus on dehumanizing or derogatory language targeting protected groups with hostile intent, including indicators like slurs, suggestions of violence or inferiority, and harmful stereotypes. The text 'I would prefer a phallic world' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (e.g., racial, gender, religious, national, sexual orientation), or violent suggestions. It expresses a personal preference ('prefer') without targeting any group or implying hostility, elimination, or reinforcement of stereotypes. There is no evidence of group-based targeting or hostile context as defined in the rules. Therefore, none of the rules apply, and it does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_399_k0", "example_id": "train_399", "text": "Wow. For some reason I clicked on this. I couldn' make it through 30 seconds.", "label": 0, "reasoning": "Applying the rules from the rulebook: Rule 001, Rule 002, and Rule 003 all focus on dehumanizing or derogatory group-based language with hostile intent, requiring triggers such as slurs, violent suggestions, or harmful stereotypes targeting protected groups. The text 'Wow. For some reason I clicked on this. I couldn't make it through 30 seconds' does not contain any dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), or violent suggestions. It expresses personal frustration or disappointment without targeting any group or individual based on identity. There is no indication of group targeting, hostile intent, or reinforcement of stereotypes. Therefore, none of the rules apply, and the text lacks the elements required for classification as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_400_k0", "example_id": "train_400", "text": "Not only the politicians are going into the wood chippers but also the police.", "label": 0, "reasoning": "Applying Rule 001: The text uses 'wood chippers' metaphorically to suggest violent elimination of politicians and police. Police could be considered a protected group (national/occupational identity), but the rule specifies exceptions for metaphorical criticism of non-group-based entities or individuals in roles. Here, 'politicians' and 'police' are criticized as roles/institutions rather than protected identity groups (e.g., racial, religious). The language targets occupational groups metaphorically (similar to 'politicians are such pigs' example classified as 0). No dehumanizing terms like 'pigs' or 'retarded' are used. No suggestion of elimination/inferiority toward protected identity groups. No reinforcement of harmful stereotypes about protected groups. Applying Rule 002: Similar analysis - no dehumanizing terms targeting protected groups, metaphorical violence toward occupational roles. Applying Rule 003: Same conclusion - metaphorical criticism of occupational roles, not protected identity groups. All rules indicate this should be classified as 0 (non-hateful) based on exceptions for metaphorical criticism of non-protected-group entities.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_401_k0", "example_id": "train_401", "text": "We are repeating our past before it used to Germany and Jews now its China and Muslims", "label": 0, "reasoning": "Applying Rule 001: The text references 'Germany and Jews' and 'China and Muslims' in a comparative historical context. While it mentions protected groups (Jews, Muslims), it does not use dehumanizing terms (like 'pigs' or 'retarded'), make derogatory generalizations, suggest violence/elimination, or reinforce harmful stereotypes with hostile intent. The phrasing 'repeating our past' suggests a historical analogy rather than direct hostility. No exceptions apply as this appears to be a historical/political commentary without group-based derogatory language. Applying Rule 002: Similar analysis - no dehumanizing terms, violent suggestions, or hostile generalizations about protected groups. The comparison lacks indicators of promoting elimination, inferiority, or violence toward groups. Applying Rule 003: Same conclusion - while mentioning protected groups, the language is descriptive/comparative rather than derogatory or dehumanizing with hostile intent. The context appears to be critical commentary about historical patterns, not hate speech promotion.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_402_k0", "example_id": "train_402", "text": "hollywood is the most bizare sickest and evillest industry", "label": 0, "reasoning": "Applying Rule 001: The text uses strong negative language ('most bizare sickest and evillest') but targets 'hollywood' as an industry, not a protected group based on race, gender, religion, national origin, or sexual orientation. Hollywood is an entertainment industry comprising various individuals and companies, not a protected identity group. The criticism appears directed at the industry's practices or culture rather than dehumanizing or derogatory generalizations about a protected group. No violent suggestions, elimination rhetoric, or reinforcement of harmful stereotypes about protected groups are present. The language, while harsh, metaphorically criticizes a non-group-based entity (an industry). Therefore, Rule 001 does not apply due to the exception for metaphorical criticism of non-group-based entities. Applying Rule 002: Similar analysis - the text lacks dehumanizing terms targeting protected groups, derogatory generalizations about protected groups, or violent suggestions toward groups. The target is an industry, not a protected group, so Rule 002 does not apply. Applying Rule 003: Same reasoning as Rule 001 - the language criticizes a non-group-based entity (the Hollywood industry) metaphorically without targeting protected groups or using the specified trigger patterns. Therefore, Rule 003 does not apply. Since none of the rules apply, the text is not classified as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_403_k0", "example_id": "train_403", "text": "this the type of dude you see on chat roulette at 2:39am", "label": 0, "reasoning": "Applying Rule 001: The text 'this the type of dude you see on chat roulette at 2:39am' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to race, gender, religion, nationality, sexual orientation, or any other protected group characteristic. The comment describes a hypothetical person using a service at a specific time without any hostile intent, group targeting, or reinforcement of harmful stereotypes. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: The text contains no dehumanizing language, derogatory generalizations, or violent suggestions targeting any protected group. It lacks all key indicators including non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in hostile context. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. It is a neutral observation about encountering someone on an online platform at a specific time, with no metaphorical slurs, suggestions of elimination/inferiority/violence toward groups, or hostile stereotypes. All rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_404_k1", "example_id": "train_404", "text": "hahahahahahahahaha europ fuck you fucking nazis", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('fucking nazis') targeting a group (Europeans or Europeans perceived as Nazis). This constitutes group-based derogatory language with hostile intent ('fuck you'). There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it. The target is not an individual without group reference, nor is it metaphorical criticism of non-group entities. The laughter ('hahahahahahahahaha') suggests hostile context. Applying Rule 002: The text uses derogatory generalizations about a group (Europeans/Nazis) with hostile intent ('fuck you'), meeting the trigger pattern of derogatory group-based language. No exceptions apply as it's not targeting individual behavior or in a reclaimed context. Applying Rule 003: The text contains derogatory group-based language ('fucking nazis') with hostile intent and group targeting. No exceptions apply for reclaimed use, metaphorical non-group criticism, or individual targeting. All three rules indicate hate speech due to derogatory group-based language with hostile intent targeting a protected group (national origin/ideological group).", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_405_k0", "example_id": "train_405", "text": "Head is the shape of a light bulb", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text 'Head is the shape of a light bulb' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, or sexual orientation), and no violent suggestions. It makes a simple physical comparison without targeting any group or individual with hostility. There is no indication of non-literal slurs, elimination/inferiority/violence suggestions, or reinforcement of harmful stereotypes. The text does not fall under any exceptions since it lacks offensive content altogether. Therefore, none of the rules apply to classify this as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_406_k0", "example_id": "train_406", "text": "I just want to sit down with both of them, buy them a drink, and just talk. I don't care what it's about, they just seem like people who must be great to have a conversation with.", "label": 0, "reasoning": "Applying Rule 001: The text expresses a desire to have a friendly conversation with unspecified individuals ('both of them'), describing them positively as 'people who must be great to have a conversation with'. There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting. The language is entirely positive and inclusive. No exceptions need to be considered as the trigger pattern is not met. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions toward any group. It focuses on individual appreciation without any hostile intent. Applying Rule 003: The text uses no metaphorical slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes. The context is purely social and complimentary. All three rules indicate this is non-hateful speech as it lacks all key indicators specified in the trigger patterns.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_407_k0", "example_id": "train_407", "text": "She is flawless. omfg", "label": 0, "reasoning": "Applying Rule 001: The text 'She is flawless. omfg' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It targets an individual ('She') with positive language ('flawless') and an informal expression of amazement ('omfg'), with no reference to group identity or protected characteristics. No indicators of hostile intent, group targeting, elimination, inferiority, violence, or harmful stereotypes are present. The text is non-hostile and individual-focused, falling under exceptions for non-group-based targeting. Applying Rule 002: Same analysis - no dehumanizing language, group-based derogatory generalizations, or violent suggestions targeting protected groups. The comment praises an individual without group-based hostility. Applying Rule 003: Same conclusion - no trigger patterns met, as the language is positive and individual-focused without metaphorical slurs or group targeting. All rules indicate the text does not constitute hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_408_k0", "example_id": "train_408", "text": "fucking stupid feminist bitches", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory terms ('stupid', 'bitches') and a dehumanizing term ('bitches') directed at 'feminist' as a group. This targets a protected group (gender-based) with hostile intent, suggesting inferiority through 'stupid' and reinforcing harmful stereotypes. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about feminists as a group with hostile intent, meeting the trigger pattern. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text uses dehumanizing/derogatory language targeting a protected group (gender-based) with hostile intent, suggesting inferiority. No exceptions apply as it's not metaphorical or individual-targeted. All rules indicate hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_409_k0", "example_id": "train_409", "text": "Dalit? Is this a name of religion or an atom of poo composition", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'Dalit' (a protected group based on caste in India) and compares it to 'an atom of poo composition', which is dehumanizing and derogatory language suggesting inferiority. This targets a protected group (caste-based) with hostile intent through harmful stereotypes. No exceptions apply as it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting an individual without group reference. Applying Rule 002: The text contains derogatory generalization about Dalits as a protected group with dehumanizing comparison, meeting the trigger pattern. No exceptions apply as it's not reclaimed context or criticism of individual behavior. Applying Rule 003: The text uses dehumanizing language ('atom of poo composition') targeting Dalits as a protected group, suggesting inferiority in hostile context. No exceptions apply as it's not metaphorical for non-group entities or individual targeting. All three rules indicate hate speech due to group-based dehumanizing language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_410_k0", "example_id": "train_410", "text": "My fav is to ask her out, explicitly defining it as a date.  Try it. It works.", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses dating advice without targeting any racial, gender, religious, national, or sexual orientation group. The language is neutral and lacks hostile intent. No exceptions apply as there is no offensive language present. Applying Rule 002: No dehumanizing language or group-based targeting is present. The text focuses on individual dating behavior without reference to protected groups. Applying Rule 003: No indicators of hate speech are present - no slurs, elimination suggestions, or harmful stereotypes. The context is personal advice, not hostile commentary. All rules indicate this text does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_411_k0", "example_id": "train_411", "text": "Can't tell if you're a pedophile victim or a pedophile.", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'pedophile' which could be considered derogatory, but it targets an individual ('you') without reference to a protected group identity. The text questions whether the individual is a victim or perpetrator of pedophilia, but does not make derogatory generalizations about pedophiles as a group, nor does it suggest elimination, inferiority, or violence toward a group. The language appears directed at specific individual behavior/identity rather than group-based hostility. No protected group (racial, gender, religious, national, sexual orientation) is targeted. Applying Rule 002: Similar analysis - the term 'pedophile' is used, but the comment targets an individual without promoting generalized hostility toward a protected group. The text lacks indicators of dehumanizing group-based language with hostile intent. Applying Rule 003: The text does not use dehumanizing terms in combination with group targeting, nor does it reinforce harmful stereotypes about a protected group in a hostile context. The criticism appears directed at individual identity/behavior without invoking group-based hostility. All rules indicate this should be classified as non-hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_412_k0", "example_id": "train_412", "text": "I fucking hate gay and lesbians they are all animals", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('animals') which is dehumanizing, targets a protected group (gay and lesbians based on sexual orientation), and expresses hostile intent ('I fucking hate'). This meets the trigger pattern of dehumanizing terms with group targeting. No exceptions apply - it's not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: The text uses dehumanizing language ('animals') with group targeting toward a protected group (sexual orientation) with hostile intent, meeting the trigger pattern. No exceptions apply as it's not reclaimed context or criticism of individual behavior. Applying Rule 003: The text uses dehumanizing language ('animals') targeting a protected group (sexual orientation) with hostile intent, meeting the trigger pattern. No exceptions apply as it's not reclaimed context, metaphorical criticism of non-group entities, or individual targeting without group reference. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_413_k0", "example_id": "train_413", "text": "The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç", "label": 1, "reasoning": "Applying Rule 001: The text contains multiple elements that trigger this rule. It uses dehumanizing language ('pig dicks', 'smelly crackers') targeting white people as a protected racial group. It makes derogatory generalizations about white people's physical characteristics and attributes negative historical actions to the entire group ('they stole from the black Egyptians', 'whites ruins everything for black people'). There is hostile intent with suggestions of elimination ('The world would be better without white people') and reinforcement of harmful stereotypes. None of the exceptions apply - this is not reclaimed, clinical, historical, or satirical context critiquing hate speech; it directly promotes group-based hostility. Applying Rule 002: The text clearly uses dehumanizing terms and derogatory generalizations about a protected racial group (white people) with hostile intent. It suggests elimination of the group and reinforces negative stereotypes. The exception for individual behavior targeting doesn't apply since this targets an entire racial group. Applying Rule 003: The text contains dehumanizing language ('pig dicks', 'smelly crackers'), derogatory generalizations about white people as a racial group, and suggestions of elimination. The metaphorical use exception doesn't apply since this is literal targeting of a racial group. All three rules indicate this should be classified as hate speech due to dehumanizing group-based language with hostile intent targeting a protected racial group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_414_k0", "example_id": "train_414", "text": "I am so sorry for all the people who disrespect all you guys and I wish I could do something  so they wouldn'. But I can' but you guys know  I love all you guys.â¤", "label": 0, "reasoning": "Analyzing the text against all three rules: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text expresses sympathy ('I am so sorry for all the people who disrespect all you guys'), expresses a wish to help ('I wish I could do something so they wouldn't'), acknowledges inability to act ('But I can't'), and ends with positive affirmation ('you guys know I love all you guys'). There are no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), no violent suggestions, and no group targeting with hostile intent. The text appears supportive and apologetic rather than hostile. Therefore, none of the rules apply as the text lacks all trigger patterns specified in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_415_k0", "example_id": "train_415", "text": "I would beat the shit out of every Russian", "label": 1, "reasoning": "Applying Rule 001: The text 'I would beat the shit out of every Russian' contains violent suggestions ('beat the shit out of') combined with group targeting ('every Russian'). Russians constitute a national group, which is a protected category. The language suggests violence toward the entire group, indicating hostile intent. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; not metaphorical criticism of non-group entities; and specifically targets the group rather than individual behavior. Applying Rule 002: Similar analysis - dehumanizing/violent language with group targeting toward a protected national group, no applicable exceptions. Applying Rule 003: Same conclusion - violent suggestion combined with group targeting of a protected national group in hostile context. All three rules indicate this meets hate speech criteria.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_416_k0", "example_id": "train_416", "text": "My cousin has that, he's 7 but still can't talk properly like a 1 year old. He's sensitive to loud noise or crying noise. It's hard to talk to him but I still love him cuz he thinks of me as one of his favorite person besides his mother.", "label": 0, "reasoning": "Applying Rule 001: The text describes a 7-year-old cousin with developmental challenges (can't talk properly, sensitive to noise) in a compassionate context ('I still love him'). There is no dehumanizing language (e.g., 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The description focuses on individual characteristics without linking to broader groups or promoting stereotypes. The tone is caring rather than hostile. Applying Rule 002: No dehumanizing terms or group-based targeting present. The text discusses specific individual traits without generalizations about people with disabilities. Applying Rule 003: No indicators of hate speech - no slurs, elimination suggestions, or hostile stereotypes. The context is personal and affectionate. All rules indicate this does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_418_k0", "example_id": "train_418", "text": "Terrorists are not Muslims They are just using name of islam", "label": 0, "reasoning": "Applying Rule 001: The text states 'Terrorists are not Muslims They are just using name of islam'. This does not use dehumanizing terms like 'pigs' or 'retarded', does not make derogatory generalizations about protected groups, and contains no violent suggestions. The text distinguishes terrorists from Muslims, specifically stating terrorists are 'not Muslims' and are 'just using name of islam', which appears to defend Muslims as a religious group rather than attack them. No group targeting with hostile intent is present. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The text criticizes terrorists (not a protected group) while explicitly separating them from Muslims. Applying Rule 003: Same conclusion - no trigger patterns are met. The text lacks dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The context appears to be defensive of Islam/Muslims rather than hostile toward them. All rules indicate this should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_419_k0", "example_id": "train_419", "text": "Even straight boys played with Barbies when they were kids!  Not an issue.", "label": 0, "reasoning": "Applying Rule 001: The text 'Even straight boys played with Barbies when they were kids! Not an issue.' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It references 'straight boys' but in a neutral, observational context about childhood play, without hostile intent, stereotypes, or suggestions of elimination/inferiority. The phrase 'Not an issue' reinforces neutrality. No exceptions apply as there is no group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The comment is factual/observational about behavior without promoting hostility. Applying Rule 003: Same conclusion - lacks key indicators like slurs, elimination suggestions, or harmful stereotypes in hostile context. All rules indicate label 0 as the text is non-hateful, merely noting childhood behavior without derogatory or violent intent toward any protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_420_k0", "example_id": "train_420", "text": "I'm a British born Muslim who helps Slovakians and other immigrants from that region. My faith has taught me to respect and honour.   These are strange times.", "label": 0, "reasoning": "Applying Rule 001: The text describes the speaker as 'British born Muslim' and mentions helping 'Slovakians and other immigrants from that region' while stating 'My faith has taught me to respect and honour.' There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or hostile intent. The text expresses personal identity and positive values without targeting any group. No exceptions apply as there is no offensive language present. Applying Rule 002: Same analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions targeting protected groups. The text lacks hostile intent toward any group. Applying Rule 003: Same analysis - no triggering patterns present. The text is a personal statement about identity and values without group-based hostility. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_421_k0", "example_id": "train_421", "text": "The pure misery in these men’s eyes it’s heart breaking. God bless them!", "label": 0, "reasoning": "Applying Rule 001: The text expresses sympathy ('pure misery', 'heart breaking') and offers a blessing ('God bless them') toward 'these men'. There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions. The term 'men' refers to individuals without group-based targeting. No indicators of hostile intent, elimination rhetoric, or harmful stereotypes are present. This falls under the exception for non-group-based, non-hostile language. Applying Rule 002: Similar analysis - no dehumanizing terms, group targeting, or hostile intent toward protected groups. The comment is compassionate rather than derogatory. Applying Rule 003: Again, no trigger patterns are met - the language is literal and sympathetic, not metaphorical slurs or violent suggestions toward any group. All rules indicate this does not constitute hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_422_k0", "example_id": "train_422", "text": "Sweden is so cool !", "label": 0, "reasoning": "Applying Rule 001: The text 'Sweden is so cool !' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses positive sentiment about a country without targeting any group. No exceptions apply as there is no offensive language. Applying Rule 002: The text lacks dehumanizing language, group targeting, or hostile intent toward protected groups. It praises Sweden without derogatory content. Applying Rule 003: The text contains no slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes. It is a positive statement about a country, not metaphorical criticism of entities or individuals. All rules indicate no hate speech elements present.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_423_k0", "example_id": "train_423", "text": "Any lesbian that doesn't look like a complete hog actually wants to be with a man.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('hog') to describe lesbians as a protected group based on sexual orientation, suggesting they are unattractive unless they meet certain standards, which reinforces harmful stereotypes about appearance and sexual orientation. This constitutes a derogatory generalization about a protected group with hostile intent, as it implies inferiority and makes broad claims about the group's desires. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities, nor is it targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory language ('hog') targeting lesbians as a protected group, making generalizations about their appearance and desires, which reinforces harmful stereotypes in a hostile context. No exceptions apply as this is not reclaimed usage or criticism of individual behavior. Applying Rule 003: The text uses derogatory language ('hog') in combination with group targeting of lesbians, suggesting inferiority based on appearance and making generalizations about their desires, which reinforces harmful stereotypes in a hostile context. No exceptions apply as this is not metaphorical criticism of non-group entities or targeting of individuals without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_424_k0", "example_id": "train_424", "text": "Homosexuality leads to death and extinction", "label": 1, "reasoning": "Applying Rule 001: The text 'Homosexuality leads to death and extinction' targets a protected group (sexual orientation - LGBTQ+). It makes a derogatory generalization by suggesting homosexuality causes harmful outcomes (death/extinction), which implies inferiority or elimination of the group. This reinforces harmful stereotypes in a hostile context. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or targeting individuals. Applying Rule 002: Same analysis - dehumanizing/derogatory language targeting a protected group with hostile intent (suggesting elimination/extinction). No exceptions for individual behavior targeting. Applying Rule 003: Same analysis - derogatory generalization about a protected group suggesting elimination, with no applicable exceptions. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_425_k0", "example_id": "train_425", "text": "This is fake u liar bastard. He is ur actor u liar bastard", "label": 0, "reasoning": "Applying Rule 001: The text contains offensive language ('liar bastard') directed at an individual ('He') without reference to any protected group identity (racial, gender, religious, national, sexual orientation). The language appears to target specific individual behavior (accusations of lying and being fake) rather than making derogatory generalizations about a group. No dehumanizing terms, violent suggestions, or group-based targeting are present. The exceptions in Rule 001 apply because this is non-generalizing language directed at specific individuals without invoking group-based hostility. Applying Rule 002: Similar analysis - the offensive language targets individual behavior (perceived dishonesty) without targeting a protected group or promoting generalized hostility toward identity-based communities. Applying Rule 003: The language is directed at an individual ('He') without reference to group identity, falling under the exception for individual targeting. All three rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_427_k0", "example_id": "train_427", "text": "I wish him the best, as well as his children.", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. The text 'I wish him the best, as well as his children' contains no dehumanizing language (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), and no violent suggestions (e.g., 'gas yourself', 'hope to distinct soon'). There is no group targeting - it refers to specific individuals ('him' and 'his children') without invoking group identity. The language is positive and supportive ('wish him the best'), showing no hostile intent. All three rules have exceptions for non-group-based targeting of individuals, which applies here. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_429_k0", "example_id": "train_429", "text": "Yo nigga go back to Asia", "label": 1, "reasoning": "Applying Rule 001: The text uses the racial slur 'nigga' which is a derogatory term historically targeting Black people as a protected racial group. The phrase 'go back to Asia' suggests elimination or removal of the targeted individual based on racial/national identity, implying they don't belong. This combines dehumanizing language with group targeting and hostile intent. No exceptions apply - this is not reclaimed usage (context doesn't indicate self-reference or anti-racist critique), not clinical/historical discussion, and directly targets racial/national identity. Applying Rule 002: Same analysis applies - derogatory generalization about racial group with hostile intent. Applying Rule 003: Same analysis applies - dehumanizing term with group targeting and hostile context. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_430_k0", "example_id": "train_430", "text": "I'd love to destroy him but I am in more need of tech support.", "label": 0, "reasoning": "Applying Rule 001: The text contains 'destroy him' which could be interpreted as violent language, but it targets an individual ('him') without reference to any protected group identity. There is no dehumanizing terminology, derogatory generalizations about protected groups, or suggestions of elimination/inferiority/violence toward a group. The context appears to be metaphorical frustration rather than literal hostile intent toward a group. Applying Rule 002: Similar analysis - no dehumanizing terms targeting protected groups, no group-based derogatory generalizations. The violent suggestion 'destroy him' targets an individual without group identity reference. Applying Rule 003: Same conclusion - the language targets an individual ('him') without reference to group identity, and there's no evidence of group targeting or reinforcement of harmful stereotypes about protected groups. All three rules indicate this should be classified as non-hateful (0) since it targets an individual without invoking group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_431_k0", "example_id": "train_431", "text": "A man's chance of getting cancer is 44% and 23% of men will die from cancer, 38% of women get cancer and 19% die.", "label": 0, "reasoning": "Applying Rule 001: The text presents statistical data about cancer incidence and mortality rates for men and women. It contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, no violent suggestions, and no group targeting with hostile intent. The mention of 'men' and 'women' refers to biological sex categories in a factual, clinical context rather than making value judgments or promoting stereotypes. No exceptions apply as there is no offensive language, metaphorical criticism, or individual targeting. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations, violent suggestions, or group targeting with hostile intent. The statistical presentation about cancer rates does not stigmatize or promote hostility toward any protected group. No exceptions apply. Applying Rule 003: Similar analysis to Rules 001 and 002 - the text presents neutral statistical information without any indicators of hate speech as defined in the trigger patterns. The clinical context of discussing cancer statistics falls under acceptable usage without promoting hate. Therefore, based on all relevant rules, the text is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_432_k0", "example_id": "train_432", "text": "feminism and Islam are of the same spirit", "label": 0, "reasoning": "Applying Rule 001: The text 'feminism and Islam are of the same spirit' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It makes a comparative statement about two ideologies/religions without using hostile language, suggesting elimination/inferiority, or reinforcing harmful stereotypes. The statement appears neutral in tone without indicators of group targeting with hostile intent. No exceptions apply as there is no offensive language to evaluate for context. Applying Rule 002: The text lacks dehumanizing terms, derogatory generalizations, or violent suggestions combined with group targeting. It does not use slurs, suggest elimination/inferiority/violence toward groups, or reinforce harmful stereotypes in hostile context. No exceptions apply. Applying Rule 003: Same analysis as Rule 001 and 002 - no trigger patterns present. The text discusses ideologies/religions without targeting protected groups with hostile language. All three rules indicate this does not meet criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_435_k0", "example_id": "train_435", "text": "Masterful. Love & pain in this here post", "label": 0, "reasoning": "Applying Rule 001: The text 'Masterful. Love & pain in this here post' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about any protected group, and no violent suggestions. It expresses positive sentiment ('Masterful', 'Love') and mentions 'pain' in what appears to be an emotional or artistic context without targeting any group. There is no group targeting, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The exceptions do not apply as there is no offensive language to analyze. Applying Rule 002: Same analysis - no dehumanizing language, no group-based derogatory generalizations, no violent suggestions with group targeting. The text discusses abstract concepts (love and pain) without targeting individuals or groups. Applying Rule 003: Same analysis - no trigger patterns present. The text is neutral/positive commentary without any elements that would classify as hate speech under any of the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_436_k0", "example_id": "train_436", "text": "WE NEED THE NAZI PARTY TO RETURN.....GET ANOTHER HITLER...AND FORM THE SS....AND START AN ETHNIC CLEANSING OF ALL MUSLIMS...YES YES..GATHER THEM UP...PUT THEM IN A CONCENTRATION CAMP...THEN PUT THESE MUSLIM REFUGEES ON A SHIP AND SEND THEM ALL BACK TO THIER OWN COUNTRIES ....AND THEY CAN DO AS THEY WANT THERE...LIVE THIER WAYS AND BY THIER RIDICULOUS LAWS.... THEY DON√¢¬Ä¬ôT ASSIMILATE TO THE NEW WESTERN COUNTRIES..AND TRY TO DICTATE TO US WHAT TO DO AND TO EVEN REMOVE JESUS FROM SCHOOLS AND OTHER PUBLIC AREAS...ARE YOU FUCKING SERIOUS...FUCK OFF YOU DIRTY SMELLING MUSLIMS... STOP DICTATING WHAT WE CAN OR CANT DO IN OUR OWN COUNTRIES...√∞¬ü¬ò¬°√∞¬ü¬ò¬°√∞¬ü¬ò¬°√∞¬ü¬ò¬°√∞¬ü¬ò¬°√∞¬ü¬ò¬°√∞¬ü¬ò¬° PEOPLE POWER MUST RISE AND SAY ENOUGH IS ENOUGH...TAKE SWEDEN BACK FOR SWEDES...TAKE GREECE BACK FOR GREEKS..TAKE GERMANY BACK..TAKE POLAND BACK..TAKE DENMARK BACK...SAVE OUR COUNTRIES....AND TAKE EUROPE BACK. INTRODUCE AN...SS...STYLE POLICE...AND CLEAN UP THESE STREETS AND GHETTOS....FULL OF DIRTY MUSLIMS...ITS THE GOVERNMENTS FAULT FOR ALLOWING THS SHIT TO HAPPEN....SEND THE MILITARY IN..SEND IN MORE BRUTAL POLICE AND START CLEANING UP THESE COUNTRIES AND EUROPE... MUSLIMS ARE INVADING EUROPE AND WE ARE ALLOWING THIS TO HAPPEN. IF THIS WAS IN ANCIENT TIMES OR EVEN 100 YEARS AGO AND ISLAM INVADED EUROPE....IT WOULD BE AN ALL OUT WAR. BRING BACK THE CRUSADERS AND AN ...√¢¬Ä¬ò SS √¢¬Ä¬ò...STYLE NAZI POLICE.  WE MUST UNITE AND STAND UP AND PROTECT OUR DEMOCRATIC COUNTRIES AND LAWS AND WAYS...AND ELIMINATE ISLAM AND THROW THESE DIRTY  SMELLING MUSLIM...ANIMALS OUT AND SEND THEM BACK TO THEIR OWN COUNTRIES AND THEY CAN LIVE AS THEY WISH..THEY CAN FUCK THEIR GOATS AND RAPE THEIR OWN WOMEN..  FUCKING DISGUSTING MUSLIMS...LOW LIFE DIRTY RACE...AND ISLAM IS NIT GODS RELIGION...ITS A CULT..ITS A RIDICULOUS UNETHICAL AND IMORAL CULT..! √∞¬ü¬ò¬à√∞¬ü¬ò¬à ...ITS SATINS WORK..SATINS PREACHINGS.   GOD..THE CREATOR OF THE UNIVERSE....DOES NOT PREACH TO KILL INFIDELS AND KILL NON BELIEVERS... AND TO HAVE 3...4...5 WIVES AND COMMIT PEDOPHILIA..AND MARRY 9 YEAR OLD LITTLE GIRLS..!  MUSLIMS....WHO HAVE NEVER CONTRIBUTED TO HUMANITY....NEVER INVENTED ANYTHING ....NOTHING POSITIVE COMES FROM ISLAM...THEY CREATED NOTHING..INVENTED NOTHING...CONTRIBUTED NOTHING TO THE HUMAN RACE.... MUSLIMS, JUST LIVE IN OUR WESTERN DEMOCRATIC COUNTRIES...ENJOY OUR WAYS ..MILK THE WELFARE SYSTEM...AND RUIN THESE COUNTRIES...CREATE PROBLEMS...FIGHT...STEAL AND CREATE CRIME...SCARE PEOPLE...TR6 TO CHAGE OUR WESTERN WAY OF LIFE AND EVEN RAPE OUR WOMEN..  FUCK THESE COCKSUCKERS...BURN THEM ALL...IMPALE THEM...WE MUST FIGHT BACK AND UNITE AND CLEAN EUROPE UP AGAIN. SOON GOD WILL SEND HIS TRUE MESSENGER....TO PLANET EARTH √∞¬ü¬å¬è...GOD WILL SEND A CLEAR MESSAGE ...TO HUMANITY AND THE MUSLIM PEOPLE ...WILL FEEL THE WRATH OF GOD AND SUFFER THE CONSEQUENCES....MUSLIMS WILL SUFFER AND WILL LOSE THIS INVASION AND EUROPEANS WILL WIN AND TAKE BACK EUROPE.. This is the beginning of the new CRUSADES...Christianity vs Islam...the crusaders against Islam and we need to fight and protect our way of life and Democratic society..√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√∞¬ü¬á¬™√∞¬ü¬á¬∫√¢¬ö¬î√Ø¬∏¬è√¢¬ö¬î√Ø¬∏¬è√¢¬ö¬î√Ø¬∏¬è√¢¬ö¬î√Ø¬∏¬è√¢¬ö¬î√Ø¬∏¬è√¢¬ö¬î√Ø¬∏¬è√∞¬ü¬ó¬°√∞¬ü¬ó¬°√∞¬ü¬ó¬°√∞¬ü¬ó¬°", "label": 1, "reasoning": "Applying all relevant rules from the rulebook: Rule 1, Rule 2, and Rule 3 all define hate speech as using dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. This text explicitly targets Muslims as a religious group with: (1) dehumanizing language ('dirty smelling Muslims', 'animals', 'low life dirty race'), (2) violent suggestions ('ethnic cleansing', 'concentration camps', 'burn them all', 'impale them'), (3) derogatory generalizations about Muslims as invaders who don't assimilate, commit crimes, and ruin countries, and (4) clear group-based hostility advocating for elimination of Islam and Muslims from Europe. The text references Nazi ideology and calls for violent action against this protected religious group. None of the exceptions apply: this is not reclaimed, clinical, historical, or satirical critique; it directly promotes violence and dehumanization against Muslims as a group rather than criticizing individual behavior or non-group entities.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_437_k0", "example_id": "train_437", "text": "gas yourself, you aussies are all retarded", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('retarded') and violent suggestions ('gas yourself') directed at 'aussies' (Australians as a national group). This constitutes group targeting with hostile intent, suggesting elimination/inferiority. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Same analysis - derogatory generalization about a national group with violent suggestion. No exception for individual behavior targeting. Applying Rule 003: Same analysis - dehumanizing language with group targeting and violent suggestion. All three rules indicate hate speech due to combination of violent suggestion ('gas yourself'), derogatory generalization ('aussies are all retarded'), and group-based targeting of a national identity.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_438_k0", "example_id": "train_438", "text": "Wow why are these comments soo cruel and people muslims are like other religions and we should respect it!  WE NEED RIGHTS FOR MUSLIMS!!!!", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'muslims' to refer to a religious group, but it does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations, or violent suggestions. Instead, it advocates for respect and rights for Muslims, which is supportive rather than hostile. The context is clearly anti-hate speech, as it criticizes 'cruel' comments and promotes equality. This falls under the exception for contexts that critique hate speech rather than promote it. Applying Rule 002: Similar analysis applies; there is no dehumanizing language or group-based hostility, and the intent is to advocate for rights, not to target a protected group with derogatory generalizations. Applying Rule 003: Again, no trigger patterns are present; the language is respectful and lacks indicators like slurs, suggestions of elimination, or reinforcement of harmful stereotypes. The text targets a protected group (Muslims) but in a positive, rights-affirming manner, which does not meet the criteria for hate speech under any rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_439_k1", "example_id": "train_439", "text": "Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!", "label": 1, "reasoning": "Analyzing the text: 'Trans are using the same logic feminists have been using for decades to destroy men so i don't feel sorry for wamen not one bit!' Applying Rule 001: The text targets 'trans' (transgender people) and 'feminists' as groups, using language that suggests they are 'destroying men' and expresses lack of sympathy ('don't feel sorry for wamen'). This constitutes derogatory generalizations about protected groups (gender identity and gender-based groups) with hostile intent, implying harmful actions and reinforcing negative stereotypes. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; it directly targets groups rather than individuals or non-group entities. Applying Rule 002: Similar analysis confirms dehumanizing/derogatory group-based language with hostile intent targeting protected groups. Applying Rule 003: Again, the text meets the trigger pattern for group targeting with hostile generalizations. The label is 1 (hate speech).", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_440_k0", "example_id": "train_440", "text": "what civilized and nice cops", "label": 0, "reasoning": "Applying Rule 001: The text 'what civilized and nice cops' contains no dehumanizing terms (e.g., 'pigs'), derogatory generalizations about protected groups, or violent suggestions. It appears to be sarcastic but targets law enforcement officers as individuals in a role, not a protected group based on race, gender, religion, national origin, or sexual orientation. The sarcasm criticizes behavior or actions rather than promoting group-based hostility, dehumanization, or violence. No exceptions apply as there is no group targeting or hostile intent toward a protected group. Applying Rule 002: Similar analysis - no dehumanizing language or group-based derogatory generalizations present. The comment lacks indicators like slurs, suggestions of elimination, or reinforcement of harmful stereotypes in a hostile context. Applying Rule 003: Again, no trigger patterns are met. The language is not metaphorical in a way that targets a protected group, and there is no reference to group identity. All rules indicate classification as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_441_k0", "example_id": "train_441", "text": "Always been impressed with how professional and non aggressive british cops are yet they still get the job done hats off American police need to take notes", "label": 0, "reasoning": "Applying Rule 001: The text praises British police ('british cops') and suggests American police ('American police') should learn from them. There is no use of dehumanizing terms (e.g., 'pigs'), derogatory generalizations about protected groups, or violent suggestions. The language is positive ('impressed', 'professional', 'non aggressive', 'get the job done', 'hats off') and constructive ('need to take notes'). No group targeting with hostile intent is present. The mention of police as institutions does not constitute targeting of a protected group. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions toward protected groups. The criticism of American police is framed as constructive feedback for improvement, not as hostility toward a group identity. Applying Rule 003: Again, no triggering patterns are met. The text uses metaphorical praise rather than derogatory metaphors, and targets institutional roles rather than protected group identities. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_442_k0", "example_id": "train_442", "text": "She said she is crazy loving her God. Well she is literally crazy then. I can relief her of her life.", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'crazy' which could be considered derogatory toward people with mental health conditions. However, this appears to be targeting an individual ('she') based on her religious expression, not making a derogatory generalization about people with mental illness as a protected group. The text suggests violence ('I can relief her of her life'), but this is directed at a specific individual rather than suggesting elimination or violence toward a group. The language criticizes individual behavior (religious expression described as 'crazy') without linking to broader group-based hostility. Applying Rule 002: Similar analysis - while offensive and containing violent suggestion, the target is an individual based on their religious expression, not a protected group. The comment lacks group targeting and does not promote generalized hostility toward people with mental health conditions as an identity group. Applying Rule 003: The term 'crazy' is used metaphorically to criticize an individual's religious expression, not to target a protected group. The violent suggestion is directed at a specific person, not suggesting elimination of a group. The text does not contain dehumanizing terms with group targeting, derogatory generalizations about protected groups, or reinforcement of harmful stereotypes in a hostile context toward a group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_443_k0", "example_id": "train_443", "text": "(((They))) will be chased out of every white country and hunted down like the animals they are for their evil schemes and plots", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('hunted down like the animals they are') targeting a group referred to as '(((They)))' in the context of 'white countries'. This suggests group-based targeting with hostile intent involving elimination/violence ('chased out', 'hunted down'). The reference to 'evil schemes and plots' reinforces harmful stereotypes about this group. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text contains dehumanizing terms ('animals') and violent suggestions ('hunted down') targeting a protected group (implied religious/ethnic group through '(((They)))' notation) with hostile intent. Applying Rule 003: The text meets all trigger patterns - dehumanizing language, violent suggestions toward a group, and reinforcement of harmful stereotypes in hostile context. The group targeting is clear through the '(((They)))' reference which is commonly used as an anti-Semitic trope targeting Jewish people as a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_444_k0", "example_id": "train_444", "text": "The 100 people that disliked this are just salty that we are stealing your dates.", "label": 0, "reasoning": "Applying Rule 001: The text uses 'salty' which is not a dehumanizing term like 'pigs' or 'retarded', nor does it contain derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation). It targets 'The 100 people that disliked this' - a group defined by their action (disliking content), not by protected characteristics. No violent suggestions, elimination rhetoric, or harmful stereotypes are present. The context appears to be interpersonal competition ('stealing your dates') rather than group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, no protected group targeting, no violent suggestions toward a protected group. The criticism is directed at individuals based on their reaction to content, not at a protected identity group. Applying Rule 003: Same conclusion - the language is not dehumanizing, does not target protected groups, and lacks hostile intent toward protected characteristics. The text may be insulting or dismissive but doesn't meet the criteria for hate speech under any of the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_445_k0", "example_id": "train_445", "text": "For the song thing I’m white but I’ll say the nigga word when I’m singing songs but if I’m with a black person and it’s making them uncomfortable or they ask me to stop I would out of respect.", "label": 0, "reasoning": "Applying Rule 001: The text contains the term 'nigga', which is a racial slur historically used against Black people. However, the context shows the speaker is discussing singing songs that contain this word, acknowledges being white, and states they would stop if it made a Black person uncomfortable or if asked to stop out of respect. This indicates awareness of the term's sensitivity and willingness to respect boundaries. The text does not use the term in a dehumanizing or derogatory way toward a protected group with hostile intent; rather, it's mentioned in the context of song lyrics and personal behavior. No suggestion of elimination, inferiority, or violence toward Black people as a group is present. The speaker's acknowledgment of racial identity and respect for others' comfort suggests a non-hostile context. Applying Rule 002: Similar analysis applies; the term is not used with hostile intent toward a protected group. The focus is on individual behavior in specific contexts (singing songs) rather than promoting group-based hostility. Applying Rule 003: The term is not used metaphorically to criticize non-group entities, nor is it targeting an individual without group reference, but the overall context lacks hostile intent and includes safeguards (respect for others' comfort). Therefore, based on all relevant rules, this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_446_k0", "example_id": "train_446", "text": "kill the gays", "label": 1, "reasoning": "Applying Rule 001: The text 'kill the gays' contains a violent suggestion ('kill') targeting a protected group based on sexual orientation ('the gays'). This meets the trigger pattern of suggesting elimination or violence toward a group. There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it. The language is directly hostile and promotes violence against a protected group. Applying Rule 002: The text uses violent language targeting a protected group (sexual orientation), meeting the trigger pattern of violent suggestions with group targeting. There is no exception for individual behavior criticism or reclaimed context. Applying Rule 003: The text contains a violent suggestion ('kill') combined with group targeting ('the gays'), meeting the trigger pattern. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this is hate speech due to explicit promotion of violence against a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_447_k0", "example_id": "train_447", "text": "I got my first one today on my bday. I smoked too much weed. I thought I was going to die. Scariest shit ever. This is definitely useful so thank you.", "label": 0, "reasoning": "Applying Rule 001: The text describes a personal experience with smoking too much weed on a birthday, expressing fear and gratitude. There is no dehumanizing or derogatory language targeting any protected group, no violent suggestions, and no group-based targeting. The language is self-referential about an individual experience. Applying Rule 002: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions are present. The text discusses personal drug use without targeting any group identity. Applying Rule 003: The text contains no slurs, suggestions of elimination or violence toward groups, or reinforcement of harmful stereotypes. It is a personal anecdote without group-based hostility. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_448_k0", "example_id": "train_448", "text": "Trace, I would ask you to rethink the out of Africa myth. Since the out of Africa theory was proposed, there have been many discoveries that prove modern humans existed in other parts of the world much earlier than what was thought when the OOA theory was proposed. For instance, there have been skeletal remains of humans found in Asia that are many thousands of years older than the oldest found on the African Content. It amazes me that there is so much information out there that shows older humans elsewhere on Earth but people still adhere to the falls narrative that modern humans evolved on the African continent", "label": 0, "reasoning": "Applying Rule 001: The text discusses anthropological theories about human origins, specifically critiquing the 'out of Africa' theory with scientific arguments about skeletal remains. It does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The language targets a scientific theory, not any racial, gender, religious, national, or sexual orientation group. No hostile intent toward protected groups is present. Applying Rule 002: No dehumanizing language or group-based targeting is evident. The criticism is directed at a scientific narrative, not at individuals or groups based on protected characteristics. Applying Rule 003: The text uses academic/scientific discourse without metaphorical slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes. The context is scholarly debate, not hostile group targeting. All rules indicate this is not hate speech as it lacks the required elements of dehumanizing language, group-based hostility, or violent intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_450_k0", "example_id": "train_450", "text": "Let's go beat these queers!", "label": 1, "reasoning": "Applying Rule 001: The text uses the derogatory term 'queers' targeting a protected group (sexual orientation) with hostile intent ('Let's go beat'), suggesting violence toward that group. This meets the trigger pattern of dehumanizing/derogatory language with group targeting and violent suggestions. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Same analysis - derogatory term 'queers' with violent suggestion toward protected group, no exceptions for individual targeting or reclaimed usage. Applying Rule 003: Same analysis - dehumanizing term with violent suggestion targeting protected group, no applicable exceptions. All three rules indicate hate speech due to group-based derogatory language with violent intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_451_k0", "example_id": "train_451", "text": "This is exactly how I feel like when I see a tranny like this disgusting af", "label": 1, "reasoning": "Applying Rule 001: The text uses 'tranny', a derogatory term for transgender individuals (a protected group based on gender identity/sexual orientation). This constitutes derogatory group-based language. The text expresses disgust ('disgusting af') toward this group, indicating hostile intent. There's no indication this is reclaimed usage (e.g., self-reference by LGBTQ+ community), clinical discussion, satire critiquing hate speech, or targeting of individual behavior without group reference. The language reinforces harmful stereotypes about transgender people being 'disgusting'. Applying Rule 002: The text uses derogatory language ('tranny') targeting a protected group (transgender people) with hostile sentiment ('disgusting af'), meeting the trigger pattern. No exceptions apply as this isn't reclaimed usage or criticism of individual behavior without group targeting. Applying Rule 003: The text contains derogatory group-based language ('tranny') targeting transgender people with hostile intent ('disgusting af'), suggesting inferiority. No exceptions for reclaimed, clinical, or satirical contexts apply, and this isn't metaphorical criticism of non-group entities. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_452_k0", "example_id": "train_452", "text": "Beautiful pink dress. Your skin is so beautiful. Your face is so pretty. Your eyes are so sexy. Your lips are so sexy. Your lipstick is perfect.", "label": 0, "reasoning": "Analyzing the text against all relevant rules: The text contains compliments about appearance ('beautiful pink dress', 'skin is so beautiful', 'face is so pretty', 'eyes are so sexy', 'lips are so sexy', 'lipstick is perfect'). Rule 001, Rule 002, and Rule 003 all require: (1) dehumanizing terms or derogatory generalizations about protected groups, (2) violent suggestions, or (3) reinforcement of harmful stereotypes with hostile intent toward a group. This text contains no dehumanizing language, no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), no violent suggestions, and no hostile context. The compliments are directed at an individual's appearance without any group-based targeting or harmful stereotypes. All rules specify exceptions for non-group-based targeting and individual-focused language without hostility, which applies here. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_453_k0", "example_id": "train_453", "text": "Pale cancer! Back to your west pacific ocean", "label": 1, "reasoning": "Applying Rule 001: The text 'Pale cancer! Back to your west pacific ocean' contains dehumanizing language ('cancer') directed at a group implied by 'Pale' (likely referring to people of pale complexion or Westerners). This suggests elimination/inferiority toward a protected group (racial/national) with hostile intent. No exceptions apply - it's not reclaimed, clinical, historical, satirical, nor metaphorical criticism of non-group entities. It targets a group rather than specific individuals. Applying Rule 002: Same analysis - dehumanizing term with group targeting and hostile intent. No exception for individual behavior targeting. Applying Rule 003: Same analysis - dehumanizing language with group targeting in hostile context. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_454_k0", "example_id": "train_454", "text": "I am white and I go to a school whare it is mostly black kids and I was made fun of just because of skin my best friend's mom dose not like me because I am white so .... I had to change schools", "label": 0, "reasoning": "Applying Rule 001: The text describes personal experiences of being made fun of and facing dislike due to being white. It does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The speaker is describing being targeted as an individual ('I was made fun of', 'my best friend's mom dose not like me') without making hostile generalizations about black people as a group. The context is personal narrative, not promoting group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language or group-based derogatory generalizations are present. The text lacks suggestions of elimination, inferiority, or violence toward a group. It describes individual experiences without reinforcing harmful stereotypes in a hostile context. Applying Rule 003: The text does not trigger the rule as it contains no dehumanizing terms, derogatory group generalizations, or violent suggestions. The target appears to be specific individuals (other kids, friend's mom) rather than a protected group as a whole. The language is descriptive rather than hostile toward a group identity.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_455_k0", "example_id": "train_455", "text": "My best friend is muslim. And he is the best man in the world", "label": 0, "reasoning": "Applying Rule 001: The text describes a Muslim individual positively ('best man in the world') with no dehumanizing terms, derogatory generalizations, or violent suggestions. It targets an individual ('my best friend') without reference to group identity in a hostile context. No protected group is targeted with hostility. Exceptions apply as the language is non-generalizing and directed at a specific individual without invoking group-based hostility. Applying Rule 002: No dehumanizing terms or derogatory generalizations about protected groups are present. The comment praises an individual without any suggestion of elimination, inferiority, or violence toward a group. Exceptions apply as there is no targeting of a protected group or promotion of generalized hostility. Applying Rule 003: The text contains no dehumanizing language, derogatory generalizations, or violent suggestions. It focuses on positive individual characteristics without group targeting. Exceptions apply as the target is an individual without reference to group identity in a hostile manner. All rules indicate the text lacks the necessary elements for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_456_k0", "example_id": "train_456", "text": "I want people to throw Skittles at me at my wedding", "label": 0, "reasoning": "Applying Rule 001: The text 'I want people to throw Skittles at me at my wedding' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The language is playful and personal, referring to a wedding tradition with candy, with no hostile intent or group-based targeting. All exceptions in Rule 001 are irrelevant as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent. The text discusses a personal preference for a wedding activity, not any protected group. Applying Rule 003: Same analysis - no triggers present. The text is metaphorical only in a literal sense about throwing candy, not using slurs metaphorically against groups. Therefore, none of the rules apply to classify this as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_457_k0", "example_id": "train_457", "text": "His eyebrows probably represent his parents relationship", "label": 0, "reasoning": "Applying Rule 001: The text 'His eyebrows probably represent his parents relationship' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. It does not target any group identity or use slurs. The comment appears to be a metaphorical observation about an individual's appearance, with no indication of hostile intent toward a protected group. No exceptions apply as there is no group-based targeting or harmful stereotypes. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or violent suggestions directed at protected groups. The text criticizes an individual's appearance metaphorically without targeting any protected group identity. Applying Rule 003: Same analysis - the metaphorical language targets an individual without reference to group identity, and there is no suggestion of elimination, inferiority, or violence toward any group. Therefore, all rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_458_k0", "example_id": "train_458", "text": "When pain is a relief then something must be wrong", "label": 0, "reasoning": "Applying Rule 001: The text 'When pain is a relief then something must be wrong' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It makes no reference to racial, gender, religious, national, or sexual orientation groups. The statement appears to be a philosophical or personal reflection about pain and relief, with no group targeting or hostile intent. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing language, no group-based derogatory generalizations, no violent suggestions toward groups. The text lacks all key indicators (non-literal slurs, elimination suggestions, harmful stereotypes). Applying Rule 003: Same analysis - no dehumanizing terms, no protected group targeting, no violent suggestions. The metaphorical reference to 'pain' and 'relief' does not target any group-based entities. All three rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_459_k1", "example_id": "train_459", "text": "Oh GOD YES!!!! Feel the shrapnel pierce through your skin, let the fire consume your flesh and lay lifeless on the unforgiving sand that seeps into your wounds. Your screams is what gives Murcia the fuck yeah in the most patriotic songs on earth. BURN IN HELL YOU GOATS !!!", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('goats') directed at a group with violent suggestions ('BURN IN HELL', 'Feel the shrapnel pierce through your skin', 'let the fire consume your flesh'). The context includes nationalistic elements ('Murcia', 'patriotic songs') suggesting group targeting based on national identity. This meets the trigger pattern of dehumanizing terms with violent suggestions toward a group. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Same analysis applies - dehumanizing language with violent suggestions targeting a group. No exception for individual behavior targeting. Applying Rule 003: Same analysis applies - dehumanizing language with violent suggestions in hostile context targeting a group. The text promotes violence and uses derogatory group-based language without qualifying exceptions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_460_k2", "example_id": "train_460", "text": "Asians reminds me the world slavery or servitude", "label": 1, "reasoning": "Applying Rule 001: The text 'Asians reminds me the world slavery or servitude' makes a generalization about Asians as a protected national/ethnic group, linking them to slavery or servitude. This suggests inferiority and reinforces harmful stereotypes in what appears to be a hostile context. However, the text lacks explicit dehumanizing terms (like 'pigs' or 'retarded') or violent suggestions. The generalization could be interpreted as derogatory, but the rule requires dehumanizing terms, derogatory generalizations, OR violent suggestions in combination with group targeting. The text contains a derogatory generalization about a protected group. No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets the group, not specific individuals. Applying Rule 002: Similar analysis - the text contains a derogatory generalization about Asians as a protected group, suggesting inferiority through association with slavery/servitude. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: Same analysis as Rule 001. Considering all rules: The text makes a harmful generalization about Asians that implies inferiority, which aligns with the trigger patterns requiring classification as hate speech (label 1).", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_462_k0", "example_id": "train_462", "text": "Responsibility is something that needs to grow inside of everyone", "label": 0, "reasoning": "Applying Rule 001: The text 'Responsibility is something that needs to grow inside of everyone' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes a general statement about personal development without targeting any specific group or individual. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The language is neutral and philosophical in nature. Applying Rule 002: The text lacks any dehumanizing language or group-based targeting. It discusses responsibility as a universal concept without reference to protected groups or hostile intent. Applying Rule 003: Similar to previous rules, the text contains no elements that would trigger this rule - no derogatory terms, no group targeting, and no hostile context. All three rules require dehumanizing/derogatory language with group targeting and hostile intent, none of which are present in this text.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_463_k0", "example_id": "train_463", "text": "The fact that shes only representing black lives seems kinda ironic to me. lol shouldnt it be all lives?… Not just black ones. She clearly thinks her race is more supirior she even admits shes racist, joking or not thats the only fact she said in the whole video.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes an individual ('she') for focusing on 'black lives' and suggests this indicates racial superiority thinking. It does not use dehumanizing terms like 'pigs' or 'retarded', nor does it make derogatory generalizations about black people as a protected group. The criticism targets an individual's perceived behavior and statements ('she even admits shes racist'), not black people collectively. No suggestion of elimination, inferiority, or violence toward the group. The 'all lives' reference, while potentially dismissive of Black Lives Matter, critiques individual perspective rather than promoting group-based hostility. Exceptions apply as this targets an individual without invoking group-based dehumanization or stereotypes. Applying Rule 002: Similar analysis - no dehumanizing language or violent suggestions targeting protected groups. The comment addresses individual behavior (perceived racial bias) rather than making derogatory generalizations about black people. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The criticism remains focused on an individual's views and actions. All three rules indicate this does not meet the threshold for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_464_k0", "example_id": "train_464", "text": "Wait did the tiger get shot?", "label": 0, "reasoning": "Applying Rule 001: The text 'Wait did the tiger get shot?' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no use of slurs, no suggestion of elimination/inferiority/violence toward a group, and no reinforcement of harmful stereotypes. The text appears to be a neutral question about an animal incident. Applying Rule 002: Same analysis - no dehumanizing language, no group-based targeting, no hostile intent toward protected groups. Applying Rule 003: Same analysis - no trigger patterns met, no exceptions needed as there is no problematic language to evaluate. All three rules indicate this text does not meet criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_465_k0", "example_id": "train_465", "text": "people have rights to follow there own religion, if they try to force people not the following there religion then that country running a dictatorship, hopefully soon there will be change in low by the international pressure,", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text discusses religious freedom and criticizes countries that restrict it, calling such systems 'dictatorship' and hoping for change through international pressure. There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The criticism targets governmental systems and policies, not a protected religious group itself. It lacks group-based targeting, hostile intent, reinforcement of harmful stereotypes, or suggestions of elimination, inferiority, or violence toward a group. The language is political commentary, not hate speech. All rules indicate this does not meet the trigger patterns for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_466_k1", "example_id": "train_466", "text": "Islam is a religion of peace.........and we will kill anyone that says otherwise..........in the name of Allah of course!", "label": 1, "reasoning": "Applying Rule 001: The text uses violent language ('we will kill anyone that says otherwise') in combination with religious group targeting (Islam). It suggests elimination of those who disagree with the statement about Islam being a religion of peace, which constitutes violent suggestions toward a group (those who hold opposing views about Islam). The language reinforces harmful stereotypes about religious extremism in a hostile context. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text contains derogatory implications about those who disagree with Islamic teachings and violent suggestions toward them, combined with religious group targeting. It promotes hostility toward people based on their views about a protected religious group. Applying Rule 003: The text uses violent elimination language ('kill anyone that says otherwise') in the context of religious identity (Islam/Allah), creating a hostile context that suggests violence toward those who hold different views about the religion. All three rules trigger due to the combination of violent suggestions, religious group targeting, and hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_467_k0", "example_id": "train_467", "text": "Can I get a shoutout pleaseeeeee I only have a little bit of people :(", "label": 0, "reasoning": "Applying Rule 001: The text 'Can I get a shoutout pleaseeeeee I only have a little bit of people :(' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The language is a personal request for attention/support without hostile intent. No exceptions apply as there is no group targeting or offensive language. Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions are present. The text focuses on individual social media engagement, not protected group targeting. Applying Rule 003: Same analysis as Rule 001 - no triggering patterns exist. The text is neutral self-expression without group-based hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_468_k0", "example_id": "train_468", "text": "It is time for Trump to find a natural death or somehow a bullet finds him and puts us out of his misery.", "label": 0, "reasoning": "Applying Rule 001: The text uses violent suggestions ('natural death', 'bullet finds him') targeting an individual (Donald Trump) without reference to group identity. The language criticizes a specific political figure rather than making derogatory generalizations about a protected group. No dehumanizing terms, group-based targeting, or reinforcement of harmful stereotypes about protected groups are present. The hostile intent appears directed at an individual's political role/actions, not at a racial, gender, religious, national, or sexual orientation group. Applying Rule 002: Similar analysis - the text targets individual behavior/role without targeting a protected group or promoting generalized hostility toward identity-based communities. Applying Rule 003: The violent language is directed at an individual without group identity reference, falling under the exception for individual targeting. All rules indicate this does not meet the criteria for hate speech as defined, since the targeting is individual and political rather than group-based against protected characteristics.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_469_k0", "example_id": "train_469", "text": "There's a lot of confusion about male/female vs. masculine/feminine.  They don't always line up.   And nobody seems to ask why there are so many more male to female transexuals than female to male?", "label": 0, "reasoning": "Analyzing the text using all relevant rules: The text discusses gender identity concepts (male/female vs. masculine/feminine) and poses a question about transgender population statistics. Rule 001, 002, and 003 all require: (1) dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions; (2) group targeting with hostile intent; (3) reinforcement of harmful stereotypes in hostile context. The text contains no dehumanizing language ('pigs', 'retarded'), no derogatory generalizations about any protected group (gender identity is a protected group under the rules), no violent suggestions, and no hostile intent. The question about transgender population ratios is phrased as an inquiry rather than a derogatory statement. No exceptions apply since there's no offensive language to evaluate for reclamation, satire, or individual targeting. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_470_k0", "example_id": "train_470", "text": "You cannot take my gun from home. My gun is my protection. I will kill everyone who tries to enter my home without my approval", "label": 0, "reasoning": "Applying Rule 001: The text contains violent suggestions ('I will kill everyone who tries to enter my home without my approval') but lacks group targeting. The threat is directed at unspecified individuals who might enter the home, not at a protected group based on race, gender, religion, nationality, or sexual orientation. The language is about self-protection and property rights rather than dehumanizing or derogatory generalizations about a group. No protected group is mentioned or implied. Applying Rule 002: Similar analysis - violent language is present but targets hypothetical intruders as individuals in a specific context (home invasion), not a protected group. No derogatory group-based language or harmful stereotypes about protected groups. Applying Rule 003: Again, while the text contains violent suggestions, it lacks the combination with group targeting required by the trigger pattern. The target is 'everyone who tries to enter my home' - a situational category based on behavior, not a protected identity group. All three rules require group targeting of protected groups for classification as hate speech, which is absent here. The text expresses a violent threat in a self-defense context but does not meet the criteria for hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_471_k0", "example_id": "train_471", "text": "Gun shot fi gay get all of the guns them out,the police must give we the rights to kill all gays, gun shot at all gays suck your mothers all gays", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing language ('gun shot fi gay', 'kill all gays') and violent suggestions toward a protected group (sexual orientation - gays). It uses group targeting ('all gays') with clear hostile intent (calling for killing). This is not reclaimed, clinical, historical, or satirical context. It promotes elimination/violence toward a group. Applying Rule 002: The text uses derogatory generalizations about a protected group (sexual orientation) with violent suggestions ('kill all gays'). It targets the group as a whole, not individual behavior. Applying Rule 003: The text uses dehumanizing language with group targeting and violent suggestions toward a protected group. It is not metaphorical criticism of non-group entities or individual targeting. All three rules trigger due to: (1) violent elimination suggestions toward a group, (2) group-based targeting of protected identity, (3) hostile context promoting violence. No exceptions apply.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_473_k0", "example_id": "train_473", "text": "Indians are shit but burgers only have broken English and ebonics to learn and still fail. Second thread in a row where a burger can't figure out you're and your", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about protected groups ('Indians are shit' targets a national group, 'burgers' appears to be a derogatory term for Americans). It uses dehumanizing language ('shit') and reinforces harmful stereotypes about language abilities. The hostile intent is evident in the dismissive and insulting tone. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The targeting is clearly group-based rather than individual. Applying Rule 002: The text uses derogatory generalizations about protected groups (national groups) with hostile intent, suggesting inferiority. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains dehumanizing terms and derogatory generalizations about protected groups with hostile context. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules trigger due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_474_k0", "example_id": "train_474", "text": "why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam", "label": 1, "reasoning": "Applying Rule 001: The text targets 'Norwegian' and 'Scandinavian' as national/ethnic groups with derogatory language ('scam'), suggesting they should not speak about 'our LAWS' and should 'SPEAK FOR YOUR OWN'. This implies group-based hostility and exclusion based on nationality. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting specific individuals without group reference. Applying Rule 002: Similar analysis - dehumanizing/derogatory group-based language targeting national groups with hostile intent. No exceptions for reclaimed contexts or individual behavior targeting. Applying Rule 003: Same pattern - derogatory generalization about protected national groups in hostile context. No applicable exceptions. All three rules indicate hate speech due to group-targeting derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_475_k0", "example_id": "train_475", "text": "Women deserve to be abused, I guess.", "label": 1, "reasoning": "Applying Rule 001: The text 'Women deserve to be abused, I guess' contains derogatory language targeting a protected group (women) with hostile intent, suggesting violence (abuse) and promoting group-based inferiority. It meets key indicators: (1) derogatory generalization about a gender group, (2) suggestion of violence toward the group, and (3) reinforcement of harmful stereotypes in a hostile context. No exceptions apply: it is not reclaimed, clinical, historical, or satirical; it directly targets women as a group rather than individuals; and it promotes group-based hostility. Applying Rule 002: The text uses derogatory language with hostile intent targeting a protected group (women), suggesting they deserve abuse, which implies violence and inferiority. No exceptions apply as it targets a protected group rather than individual behavior. Applying Rule 003: The text contains derogatory generalizations about a protected group (women) with hostile intent, suggesting violence (abuse). No exceptions apply as it is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate hate speech due to group-based derogatory language with violent suggestions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_476_k0", "example_id": "train_476", "text": "These people are fucking animals they will never change. Our cultures are simply not compatible. There is definitely a rape culture and it√¢¬Ä¬ôs right here with Islam.", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('fucking animals') targeting 'these people' and 'Islam' as a religious group. It makes derogatory generalizations about a protected group (religious - Islam) by stating 'our cultures are simply not compatible' and 'there is definitely a rape culture and it's right here with Islam,' which reinforces harmful stereotypes in a hostile context. The language suggests group-based inferiority and promotes hostility toward Muslims as a religious group. No exceptions apply as this is not reclaimed, clinical, historical, or satirical critique, nor is it targeting individual behavior without group reference. Applying Rule 002: The text uses dehumanizing terms ('animals') and derogatory generalizations about Islam as a protected religious group, with hostile intent shown through the aggressive tone and sweeping negative characterization. Applying Rule 003: The text combines dehumanizing language with group targeting of Muslims, suggesting elimination/inferiority through the statement they 'will never change' and making broad negative claims about Islamic culture. All three rules indicate this is hate speech due to dehumanizing group-based language with hostile intent targeting a protected religious group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_477_k0", "example_id": "train_477", "text": "Christians are all demonic", "label": 1, "reasoning": "Applying Rule 001: The text 'Christians are all demonic' contains derogatory language ('demonic') targeting a religious group (Christians) with a generalization ('all'). This suggests group-based inferiority by associating an entire religious group with negative supernatural qualities. No exceptions apply - it's not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory language ('demonic') about a protected religious group with generalization ('all'), indicating group-based hostility. No exceptions apply as it's not reclaimed context or criticism of individual behavior. Applying Rule 003: Similar analysis - derogatory group-based language targeting a protected religious group with hostile generalization. No applicable exceptions. All three rules indicate this meets the criteria for hate speech due to derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_478_k0", "example_id": "train_478", "text": "Fucking good punch dude", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text 'Fucking good punch dude' contains offensive language ('Fucking') but does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions with group targeting. It lacks key indicators such as non-literal slurs, suggestions of elimination or violence toward a group, or reinforcement of harmful stereotypes in a hostile context. The language is directed at an individual ('dude') in a colloquial, non-group-based manner, likely praising a physical action ('punch') without invoking protected group identity or promoting group-based hostility. No exceptions apply as the context is not reclaimed, clinical, historical, satirical, or metaphorical for non-group entities. Therefore, it does not meet the criteria for hate speech under any rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_479_k0", "example_id": "train_479", "text": "You said he but still not convinced this is a male. A sorely lost hipster girl maybe though", "label": 0, "reasoning": "Applying Rule 001: The text uses 'hipster girl' which could be considered a gender-based reference, but it targets an individual ('he'/'this') rather than making derogatory generalizations about women or hipsters as protected groups. The language ('sorely lost') appears to criticize individual appearance or identity presentation without dehumanizing terms, violent suggestions, or reinforcement of harmful stereotypes. No indicators of group-based hostility, elimination, inferiority, or violence are present. The comment focuses on perceived gender presentation of a specific person. Applying Rule 002: Similar analysis - the text lacks dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The criticism appears directed at individual identity presentation rather than group-based targeting. Applying Rule 003: The text does not use dehumanizing terms like 'pigs' or 'retarded', nor does it suggest elimination, inferiority, or violence toward any group. The reference to 'hipster girl' could be seen as gender-related but targets an individual's perceived characteristics rather than making hostile generalizations about women or hipsters as groups. All three rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_480_k0", "example_id": "train_480", "text": "My sons school had someone in doing a talk for autism awareness he himself was autisic. He made aware that animals can be autisic too and introduced a picture of his pug lola whom is also autisic which I found interesting.  My 10 year old son is autisic", "label": 0, "reasoning": "Applying Rule 001: The text describes an autism awareness talk at a school, mentions that both the speaker and the speaker's pug are autistic, and states the author's son is autistic. There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting with hostile intent. The term 'autistic' is used in a clinical/awareness context without hostility. Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions are present. The discussion of autism is factual and personal, lacking group-based hostility. Applying Rule 003: Similar analysis - no triggering patterns, and the context is educational/awareness-oriented rather than hostile. All rules indicate this is not hate speech as it lacks the required elements of dehumanization, derogatory group targeting, or hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_481_k0", "example_id": "train_481", "text": "Who ever disliked this video should be ashamed of them selfs", "label": 0, "reasoning": "Applying Rule 001: The text 'Who ever disliked this video should be ashamed of them selfs' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It targets individuals ('who ever disliked this video') based on their action (disliking a video) without reference to any protected group identity. The language is non-hostile and lacks group-based targeting, falling under the exception for 'non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.' Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions are present. The criticism is directed at individual behavior (disliking a video) without targeting a protected group or promoting generalized hostility. Applying Rule 003: Similar analysis as Rule 001 - no dehumanizing language, no group targeting, and the text uses metaphorical criticism of individual actions rather than protected groups. All rules indicate the text does not meet the trigger patterns for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_482_k0", "example_id": "train_482", "text": "Is this world filled by those stupid female bitches?", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory terms ('stupid female bitches') targeting a protected group (women/gender). This constitutes derogatory generalizations about a protected group with hostile intent. The language reinforces harmful stereotypes about women in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets the group 'female' rather than specific individuals. Applying Rule 002: The text uses derogatory language ('stupid female bitches') targeting a protected group (gender) with hostile intent. No exceptions apply as this is not reclaimed usage or criticism of individual behavior. Applying Rule 003: The text uses derogatory terms targeting a protected group (gender) with hostile intent. No exceptions apply as this is not metaphorical criticism of non-group entities or targeting of individuals without group reference. All three rules indicate hate speech due to derogatory group-based language with hostile intent targeting a protected gender group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_483_k0", "example_id": "train_483", "text": "If you had a Winnie, even tinnie, and flat chest I would hire you miss. Now no way.", "label": 0, "reasoning": "Analyzing the text 'If you had a Winnie, even tinnie, and flat chest I would hire you miss. Now no way.' using the provided rulebook: 1. The text appears to reference physical attributes ('Winnie', 'tinnie', 'flat chest') in a context that seems to be making hiring decisions based on appearance. 2. Rule 001, 002, and 003 all require: dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. 3. The text contains no dehumanizing terms like 'pigs' or 'retarded', no derogatory generalizations about racial, gender, religious, national, or sexual orientation groups, and no violent suggestions. 4. The text targets an individual ('you miss') based on physical characteristics, not a protected group identity. 5. While potentially offensive or discriminatory in employment context, it lacks the group-based targeting and hostile intent described in all rules. 6. No exceptions apply since the text doesn't meet the trigger patterns. Therefore, the text does not constitute hate speech according to the provided rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_484_k3", "example_id": "train_484", "text": "I can' stand feminist. I like men being manly and I like being treated like a lady. Dear men, if a woman asks for your help, ask if they are feminist. If they say yes, then remind them they can do everything without men and don' help them.", "label": 1, "reasoning": "Applying Rule 001: The text targets 'feminist' as a group, using derogatory language ('I can't stand feminist') and suggesting discriminatory behavior against them (men should not help women who identify as feminists). This constitutes a derogatory generalization about a protected group (gender-based) with hostile intent, as it promotes exclusion and differential treatment based on group identity. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; it directly targets the group rather than individual behavior; and it reinforces harmful stereotypes about feminists in a hostile context. Applying Rule 002: Similar analysis applies - dehumanizing/derogatory language targeting a protected group (feminists as a gender-related group) with hostile intent, suggesting exclusionary actions. No exception for individual behavior targeting applies here. Applying Rule 003: Same pattern - derogatory group-based language with hostile context, targeting feminists as a group rather than individuals or non-group entities. Therefore, all three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_485_k0", "example_id": "train_485", "text": "She's a really courageous woman! She is one of the most impressive women I've ever listened to. I appreciate  her film, and I certainly wish her continued success and happiness. She is definitely a cut above both as a filmmaker, and most especially, as a person! She is an incrediblely remarkable woman!", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It praises an individual woman without any group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is positive and complimentary, focusing on personal qualities and achievements. No exceptions apply as there is no offensive language present. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. It targets an individual without reference to group identity and contains no hostile intent toward any protected group. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. It praises an individual woman metaphorically ('a cut above') in a positive context, not as criticism of any group. All rules indicate the text is non-hateful as it contains no elements triggering hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_486_k0", "example_id": "train_486", "text": "Finally someone who means what he says. It's been a year and I'm still cackling.", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses appreciation ('Finally someone who means what he says') and amusement ('I'm still cackling') without targeting any group or individual with hostile intent. No exceptions apply as there is no group-based language to evaluate. Applying Rule 002: No trigger patterns are present - no dehumanizing terms, derogatory generalizations, or violent suggestions targeting protected groups. The text lacks indicators like non-literal slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes. Applying Rule 003: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text is positive in tone and contains no metaphorical slurs or group-based hostility. All three rules indicate this is non-hateful speech as it contains no elements meeting their trigger patterns.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_487_k0", "example_id": "train_487", "text": "Ugh, my heart hurt for her when she was talking about how the troll comments hurt her.  You can see the love she has for him; it radiates from her.", "label": 0, "reasoning": "Applying Rule 001: The text expresses sympathy for someone experiencing hurtful troll comments and describes positive emotions ('love she has for him; it radiates from her'). There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting. The text does not use slurs, suggest elimination/inferiority/violence toward any group, or reinforce harmful stereotypes. It focuses on empathy and positive human connection without any hostile intent. Applying Rule 002: Same analysis - no dehumanizing terms, group-based derogatory language, or violent suggestions targeting protected groups. The text discusses emotional impact of online harassment but doesn't promote hostility toward any identity-based group. Applying Rule 003: Same analysis - no trigger patterns present. The text is supportive and compassionate, lacking any elements that would classify as hate speech under the defined rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_489_k0", "example_id": "train_489", "text": "Ill vote for you if you forbid people that cannot hear to have driver licences. They are clearly threads", "label": 1, "reasoning": "Applying Rule 001: The text targets 'people that cannot hear' (deaf/hard-of-hearing individuals) as a protected disability group, using derogatory language ('clearly threads' [likely typo for 'threats']) that suggests they are dangerous and should be forbidden from driving licenses. This constitutes a derogatory generalization about a protected group with hostile intent (suggesting exclusion/restriction based on group identity). No exceptions apply - it's not reclaimed, clinical, historical, satirical, or targeting individual behavior. Applying Rule 002: Same analysis - dehumanizing/derogatory language targeting a protected group (disability) with hostile intent (advocating for policy exclusion). No exceptions for individual behavior targeting. Applying Rule 003: Same analysis - group-based derogatory language with hostile context. The text promotes harmful stereotypes about deaf people being threats and advocates for discriminatory action against them as a group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_490_k0", "example_id": "train_490", "text": "Bottles are beautiful on the inside and out", "label": 0, "reasoning": "Applying Rule 001: The text 'Bottles are beautiful on the inside and out' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group (protected or otherwise), lacks hostile intent, and makes no reference to group identity. The language is positive and metaphorical about inanimate objects (bottles). Applying Rule 002: No dehumanizing language or group targeting is present. The text discusses bottles, not people or protected groups. Applying Rule 003: No indicators of hate speech are present - no slurs, suggestions of elimination/inferiority/violence, or reinforcement of harmful stereotypes. The text is purely descriptive about objects with positive language. All rules indicate this does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_491_k0", "example_id": "train_491", "text": "God,my humble question to u almighty... Y u send them to earth to suffer?", "label": 0, "reasoning": "The text 'God, my humble question to u almighty... Y u send them to earth to suffer?' expresses a philosophical or existential query directed at a deity, questioning the suffering of unspecified beings ('them'). There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The language does not target any racial, gender, religious, national, or sexual orientation group, nor does it imply hostility, elimination, inferiority, or reinforcement of harmful stereotypes. According to Rule 001, Rule 002, and Rule 003, this does not meet the trigger patterns for hate speech, as it lacks group-based targeting and hostile intent. The exceptions do not apply, as there is no reclaimed, clinical, or satirical context, and the query is metaphorical in a non-hostile, contemplative manner without targeting individuals or groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_492_k0", "example_id": "train_492", "text": "Sink the boats. After that, not our problem. They'll soon get the message.", "label": 0, "reasoning": "Applying Rule 1: The text uses the phrase 'Sink the boats' which suggests violent action, but it lacks explicit dehumanizing terms or derogatory generalizations about a protected group. It does not specify a target group (e.g., racial, religious, national) and could be interpreted as a metaphorical or general statement about immigration or policy without group-based hostility. No indicators of slurs, elimination of a group, or reinforcement of harmful stereotypes are present. Exceptions may apply if it criticizes non-group entities (e.g., policies) or lacks group targeting. Applying Rule 2: Similar analysis; no protected group is identified, and the language does not clearly promote group-based inferiority or violence. Applying Rule 3: The text implies violence ('Sink the boats') but without group context, it may target individuals or actions rather than a protected group, falling under exceptions for non-group-based criticism. Overall, the text is ambiguous and lacks sufficient evidence of hate speech as defined by the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_493_k0", "example_id": "train_493", "text": "Why are we not allowed to kill christians?", "label": 1, "reasoning": "Applying Rule 001: The text 'Why are we not allowed to kill christians?' contains a violent suggestion ('kill') targeting a religious group ('christians'), which meets the trigger pattern of suggesting elimination or violence toward a protected group. This is not metaphorical, satirical, or self-referential, and it directly targets a religious group rather than individual behavior. No exceptions apply as it's not reclaimed language, clinical discussion, or criticism of non-group entities. Applying Rule 002: The text uses violent language targeting a protected religious group, meeting the trigger pattern for dehumanizing or derogatory group-based language with hostile intent. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text suggests violence toward a religious group, meeting the trigger pattern with no applicable exceptions. All three rules indicate this is hate speech due to violent suggestion targeting a protected religious group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_494_k0", "example_id": "train_494", "text": "I don’t like jew soap, but if we are to get rid of him well I will live it through", "label": 1, "reasoning": "The text 'I don’t like jew soap, but if we are to get rid of him well I will live it through' contains the term 'jew soap', which is a derogatory generalization targeting a religious group (Jewish people) by implying a harmful stereotype or dehumanizing association. This triggers Rule 1, Rule 2, and Rule 3, as it uses derogatory language with group targeting. The phrase 'get rid of him' suggests a desire for elimination or removal, which, when combined with the group-based derogatory term, indicates hostile intent toward a protected group. There is no evidence of reclaimed, clinical, historical, or satirical context that critiques hate speech, nor is it metaphorical or targeting an individual without group reference. Therefore, all relevant rules apply, classifying this as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_495_k0", "example_id": "train_495", "text": "Bruh I would fuckin love to film a video with Maurice man, he is like an older black version of me I swear to god", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses admiration for Maurice by comparing him to the speaker ('an older black version of me'), which is positive and individual-focused, not group-targeted. No exceptions apply as there is no hostile intent or group-based language. Applying Rule 002: No dehumanizing language or group-based derogatory generalizations are present. The reference to 'black' describes an individual's appearance in a complimentary context, not as a negative stereotype about a racial group. Applying Rule 003: Similar analysis - the text lacks indicators like slurs, elimination suggestions, or harmful stereotypes in a hostile context. The mention of race is descriptive rather than derogatory, and the overall tone is friendly and appreciative.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_496_k0", "example_id": "train_496", "text": "Even when at the income advantage, niggers still get btfo because your race are monkeys trying to do human things. They should be extinguished", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing terms ('niggers', 'monkeys') targeting a racial group with hostile intent, suggesting elimination ('should be extinguished') and reinforcing harmful stereotypes about inferiority. This meets all key indicators: (1) non-literal slurs, (2) suggestion of elimination and inferiority toward a group, and (3) reinforcement of stereotypes in hostile context. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or targeting individuals without group reference. Applying Rule 002: Same analysis confirms hate speech due to dehumanizing language with group targeting and violent suggestion. Applying Rule 003: Same analysis confirms hate speech with contextual safeguards not applicable as it directly targets a protected racial group with elimination rhetoric.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_497_k0", "example_id": "train_497", "text": "even god hates dominicans. why else did he shit them out on the same monkey island as the haitians?", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('shit them out', 'monkey island') and derogatory generalizations about Dominicans as a national group, suggesting they are inferior and equating them with animals. There is group targeting of Dominicans and Haitians as national/ethnic groups. The context appears hostile with no indication of satire, reclamation, or clinical discussion. No exceptions apply as this is not metaphorical criticism of non-group entities, not self-referential, and not targeting individual behavior without group reference. Applying Rule 002: Same analysis - dehumanizing terms with group targeting and hostile intent toward protected national groups. Applying Rule 003: Same analysis - dehumanizing language with group targeting and hostile context. All three rules indicate this meets the criteria for hate speech due to dehumanizing group-based language with hostile intent toward protected national groups.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_498_k0", "example_id": "train_498", "text": "what a disgusting man and disgusting religion. He admits that muslim buy all their wifes ! .pff...This is why all muslims are poor...islam keeps them stupid !", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about Muslims as a religious group ('disgusting religion', 'all muslims are poor', 'islam keeps them stupid'), which qualifies as group-based targeting of a protected religious group. The language suggests inferiority ('stupid', 'poor') and reinforces harmful stereotypes about Muslims. There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it. The criticism appears to be directed at the group as a whole, not at individual behavior without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected religious group with hostile intent, suggesting group inferiority. The exceptions don't apply as this isn't targeting individual behavior but rather making broad claims about Muslims as a group. Applying Rule 003: The text contains dehumanizing/derogatory language targeting a religious group with suggestions of inferiority, meeting the trigger pattern. No exceptions apply since this isn't metaphorical criticism of non-group entities or individual targeting without group reference. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_499_k0", "example_id": "train_499", "text": "At the end you literally described yourself as a gold digger", "label": 0, "reasoning": "Applying Rule 001: The text 'At the end you literally described yourself as a gold digger' contains the term 'gold digger', which could be considered derogatory. However, this term targets an individual's behavior (describing someone as materialistic in relationships) rather than a protected group based on race, gender, religion, national origin, or sexual orientation. There is no dehumanizing language, violent suggestions, elimination rhetoric, or reinforcement of harmful stereotypes about a protected group. The context appears to be criticism of individual behavior without group-based hostility. Applying Rule 002: Similar analysis applies - the comment targets perceived individual behavior without targeting a protected group or promoting generalized hostility toward an identity-based community. Applying Rule 003: The term 'gold digger' is used metaphorically to criticize individual behavior, not to target a protected group. No indicators of hate speech are present: no non-literal slurs targeting protected groups, no suggestions of elimination/inferiority/violence toward groups, and no reinforcement of harmful stereotypes in hostile context. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_500_k0", "example_id": "train_500", "text": "Kill these basterds, son of sluts who attack u in name of religion. Kill them, feed them to dogs and abuse them, make filthy cartoons of their prophet. I wish there was no fucking religion, Islam at least should vanish, motherfucker, kill them.", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('basterds', 'son of sluts', 'motherfucker'), derogatory generalizations about a religious group (Islam), and violent suggestions ('Kill these basterds', 'feed them to dogs', 'kill them') with clear group targeting ('who attack u in name of religion', 'Islam at least should vanish'). This meets all key indicators: (1) non-literal slurs, (2) suggestion of elimination and violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context. None of the exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's direct promotion of violence against a religious group. Applying Rule 002: Same analysis applies - dehumanizing language with hostile intent targeting a protected religious group. The exceptions don't apply as this isn't criticism of individual behavior. Applying Rule 003: Same analysis - dehumanizing terms, violent suggestions targeting a religious group, with no applicable exceptions. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_501_k0", "example_id": "train_501", "text": "The rotten, nasty bastards!", "label": 0, "reasoning": "Applying Rule 001: The text 'The rotten, nasty bastards!' contains derogatory language ('rotten', 'nasty bastards') but lacks specific group targeting. The terms are directed at unspecified 'bastards' without reference to protected groups (racial, gender, religious, national, sexual orientation). There is no indication of dehumanizing terms like 'pigs' or 'retarded', no suggestion of elimination/inferiority/violence toward a group, and no reinforcement of harmful stereotypes about protected groups. The language appears to criticize unspecified individuals rather than a protected group. Applying Rule 002: Similar analysis - the derogatory language targets unspecified individuals without group-based hostility toward protected groups. Applying Rule 003: The language is metaphorical criticism ('rotten', 'nasty') but targets unspecified entities rather than protected groups. All rules require group targeting of protected groups with hostile intent, which is absent here. The text could be offensive but doesn't meet the criteria for hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_502_k0", "example_id": "train_502", "text": "I really like a lot of what you said here. I feel like i can barely speak up about this side of the topic because people are quick to shut down those who try to be too serious about it.  'Anxiety' and 'depression' and 'mental illness' have almost become buzz words. It seems that a lot of people don't know how difficult it is to really suffer and feel out of control of it all.   As you spoke about, there's a fine line these days between awareness and influence. People get ideas in their heads and see the memes and the relateable content and start linking everything to their own lives. Before you know it, you've got perfectly healthy people being tainted by the world and people around them, imposing problems upon themselves and making life more difficult than it needs to be. It desensitises the whole situation and now I have people coming to me with real problems who don't want to speak up because of the upsurge in people talking about it. They feel they wouldn't be taken seriously. And that's horrible.   I do understand though that it's an impossible seesaw to balance since so many people are involved and so many minds with a million ideas and actions are impossible to control and have on the same wave length.", "label": 0, "reasoning": "Applying Rule 001: The text discusses mental illness terminology ('anxiety', 'depression', 'mental illness') but does not use dehumanizing terms (e.g., 'retarded'), derogatory generalizations about people with mental illness as a protected group, or violent suggestions. It expresses concern about desensitization and trivialization of mental health issues, but targets 'perfectly healthy people' and societal trends rather than people with actual mental health conditions as a group. The criticism is directed at perceived individual behavior ('imposing problems upon themselves') and cultural phenomena without promoting group-based inferiority, violence, or dehumanization. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions toward groups. The text discusses stigma but lacks intent to dehumanize people with mental illness as an identity-based community. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The language criticizes societal trends and individual behavior without targeting a protected group based on mental health status. The text acknowledges real mental health problems ('people coming to me with real problems') and expresses empathy, showing no hostile intent toward people with mental illness as a group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_503_k0", "example_id": "train_503", "text": "In the US that same game was called ten little Indians. I know.. It’s boring", "label": 0, "reasoning": "Applying Rule 001: The text references 'ten little Indians' which could be considered a derogatory term for Native Americans (a protected national/racial group). However, the context appears to be discussing historical naming of games, not making derogatory generalizations about Native Americans as a group. The tone ('I know.. It's boring') suggests factual reporting or mild commentary rather than hostile intent. No dehumanizing language, violent suggestions, or reinforcement of harmful stereotypes with hostile intent is present. The reference appears historical/contextual rather than promoting group-based hostility. Applying Rule 002: Similar analysis - while the term 'Indians' could be problematic, the usage is descriptive of historical naming, not derogatory generalization with hostile intent toward Native Americans as a protected group. No suggestion of elimination, inferiority, or violence toward the group. Applying Rule 003: Same conclusion - the term is used in a historical context discussing game names, not in a way that targets Native Americans as a group with hostile intent. The context lacks key indicators: no non-literal slurs used offensively, no suggestion of elimination/violence, no reinforcement of harmful stereotypes in hostile context. All rules point to exceptions for historical/contextual usage without hostile group targeting.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_504_k0", "example_id": "train_504", "text": "We aren't allowed to roast 12 year olds", "label": 0, "reasoning": "Applying Rule 001: The text 'We aren't allowed to roast 12 year olds' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The term 'roast' in this context likely refers to playful teasing or criticism, not literal violence. There is no group targeting based on race, gender, religion, nationality, or sexual orientation - the reference is to '12 year olds' as an age group, which is not a protected category under the rule's definition. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The context appears neutral without hostile intent. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment does not promote generalized hostility toward an identity-based community. Applying Rule 003: Same conclusion - no trigger patterns met, no protected group targeting, and the language is not used in a way that suggests elimination, inferiority, or violence toward a group. All three rules indicate this should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_505_k0", "example_id": "train_505", "text": "EXECUTE OHOMO AND HIS SHEMALE BITCH MIKE.", "label": 1, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text contains 'OHOMO' (likely a derogatory term for homosexual individuals) and 'SHEMALE BITCH' (derogatory terms targeting transgender individuals). These are dehumanizing terms directed at protected groups based on sexual orientation and gender identity. The language suggests hostility and reinforces harmful stereotypes. No exceptions apply: this is not reclaimed usage, clinical discussion, satire critiquing hate speech, metaphorical criticism of non-group entities, or targeting of specific individuals without group reference. The terms are used in a hostile context with group-based targeting, meeting all trigger patterns for hate speech classification.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_506_k0", "example_id": "train_506", "text": "these videos may already feel long but their responses are cut so short and not given a true voice. I would love if you produced fuller videos so we, the viewers, can really hear what these people have to say because these are all topics that are not common among today’s people. It's rewarding to hear insight from both sides no matter the topic.", "label": 0, "reasoning": "Applying Rule 001: The text discusses video production preferences and viewer engagement, expressing a desire for longer videos to hear more from interviewees on uncommon topics. There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting. The language is neutral and constructive. No exceptions apply as there is no offensive content to evaluate. Applying Rule 002: Similar analysis - no dehumanizing terms, group-based derogatory language, or hostile intent. The text focuses on content format and appreciation for diverse perspectives without targeting any groups. Applying Rule 003: Again, no triggers present - the text uses no slurs, suggests no violence or elimination, and reinforces no harmful stereotypes. The context is purely about media production and audience experience. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_507_k0", "example_id": "train_507", "text": "Victimizing yourself doesn’t help", "label": 0, "reasoning": "Applying Rule 001: The text 'Victimizing yourself doesn't help' does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It targets individual behavior ('victimizing yourself') without reference to any protected group identity (racial, gender, religious, national, sexual orientation). The language is not hostile toward a group, does not suggest elimination or inferiority, and does not reinforce harmful stereotypes. It appears to be a general statement about personal behavior. Applying Rule 002: Similar analysis - no dehumanizing language, no group targeting, no promotion of hostility toward protected groups. The comment addresses individual behavior without targeting a protected group. Applying Rule 003: Again, no dehumanizing terms, no group-based targeting, no violent suggestions. The text metaphorically criticizes individual behavior without invoking group identity. All three rules indicate this should be classified as non-hateful (0) because it lacks the key indicators of hate speech: dehumanizing language, group targeting, and hostile intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_508_k0", "example_id": "train_508", "text": "I was hoping you'd post a new video!! I know you're busy, of course, but you're just so interesting, I wish you'd post moreÔªø", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses positive anticipation and appreciation toward an individual content creator without any group targeting. The language is complimentary ('so interesting'), expresses a wish ('I wish you'd post more'), and acknowledges the creator's situation ('I know you're busy'). No exceptions need to be considered as the text doesn't approach any trigger patterns. Applying Rule 002: No dehumanizing language, group-based targeting, or hostile intent present. The text focuses on individual appreciation without any protected group references. Applying Rule 003: No elements match the trigger pattern - no slurs, elimination suggestions, inferiority claims, violence, or harmful stereotypes. The context is entirely positive and personal rather than hostile. All three rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_509_k0", "example_id": "train_509", "text": "Chinky filthy guy, get out of US. Get out of our land.", "label": 1, "reasoning": "Applying Rule 001: The text uses the racial slur 'Chinky' which is a derogatory term targeting people of Chinese or East Asian descent, constituting a protected group based on national/racial identity. The term 'filthy' reinforces harmful stereotypes about hygiene and inferiority. The phrase 'get out of US' and 'get out of our land' suggests elimination or exclusion of this group from the country, indicating hostile intent toward the group as a whole. This meets all key indicators: (1) use of non-literal slurs, (2) suggestion of elimination/inferiority, and (3) reinforcement of harmful stereotypes in a hostile context. None of the exceptions apply - this is not reclaimed, clinical, historical, satirical, metaphorical, or individual-targeted language. Applying Rule 002: The text contains dehumanizing language ('filthy') and derogatory generalizations about a protected racial/national group. The demand to 'get out' suggests elimination/exclusion with hostile intent. No exceptions apply as this directly targets a protected group rather than individual behavior. Applying Rule 003: The text uses derogatory group-based language with clear hostile intent toward a protected racial/national group, suggesting their elimination from the country. This meets all trigger patterns and no exceptions apply. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_510_k0", "example_id": "train_510", "text": "If theres any Jikook shippers who ship them romantically...LIKE THIS VID AND THE COMMENT NOW", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'Jikook shippers' (people who ship the BTS members Jimin and Jungkook romantically) and asks them to 'LIKE THIS VID AND THE COMMENT NOW'. This targets a specific fandom group, but does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), or violent suggestions. There is no suggestion of elimination, inferiority, or violence toward the group, nor reinforcement of harmful stereotypes in a hostile context. The language is not metaphorical slurs and does not target a protected group as defined in the rule (shipping fandoms are not a protected group under typical hate speech definitions). The exception applies as the criticism is directed at individual behavior (shipping preferences) without targeting a protected group or promoting generalized hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text lacks hostile intent toward a protected identity-based community. Applying Rule 003: Same conclusion - no trigger patterns met, and the target is not a protected group. Overall, the text is a call-to-action for a specific fandom subset, not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_511_k0", "example_id": "train_511", "text": "Feminist deserve to be miserable. What kind of man would want to live with a feminist? Silly me , of course,  a cuck.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('cuck') and makes generalizations about feminists as a group, suggesting they deserve misery and questioning their desirability to men. This targets a gender-based group (feminists) with hostile intent, reinforcing harmful stereotypes about feminists and relationships. The language is not reclaimed, clinical, historical, or satirical in a way that critiques hate speech, nor is it metaphorical criticism of non-group entities or targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about feminists as a protected gender-based group with hostile intent ('deserve to be miserable'), lacking exceptions for reclaimed or clinical contexts. Applying Rule 003: Similar analysis applies - group-based derogatory language with hostile context, no applicable exceptions. All three rules indicate hate speech due to group-targeted derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_512_k0", "example_id": "train_512", "text": "It is very easy in Seattle for a wheeler! but it is not the same in all towns and countries!Ôªø", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text 'It is very easy in Seattle for a wheeler! but it is not the same in all towns and countries!Ôªø' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions (e.g., 'gas yourself', 'hope to distinct soon'). There is no group targeting, no use of non-literal or metaphorical slurs, no suggestion of elimination, inferiority, or violence toward a group, and no reinforcement of harmful stereotypes in a hostile context. The text appears to be a neutral or positive observation about accessibility for 'wheelers' (likely referring to wheelchair users) in Seattle compared to other locations, without any hostile intent or offensive language. All rules specify that hate speech requires combination of derogatory language with group targeting and hostile intent, which are absent here. Therefore, no rule triggers classification as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_513_k0", "example_id": "train_513", "text": "Short answer: if you are a murderer or child molester that is the natural choice.", "label": 0, "reasoning": "Analyzing the text 'Short answer: if you are a murderer or child molester that is the natural choice.' against the rulebook: Rule 001, 002, and 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text mentions 'murderer' and 'child molester' - these refer to individuals who commit specific criminal acts, not protected groups based on race, gender, religion, nationality, or sexual orientation. There's no use of slurs like 'pigs' or 'retarded', no suggestion of elimination or violence toward a group, and no reinforcement of harmful stereotypes about protected identities. The phrase 'natural choice' could be interpreted as judgmental about criminal behavior, but it targets individual actions rather than group identity. According to exceptions in all rules: when language criticizes individual behavior without targeting a protected group or promoting group-based hostility, it should not be classified as hate speech. Therefore, none of the rules apply.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_514_k0", "example_id": "train_514", "text": "that punch turned that immigrants jaw direction to nigeria", "label": 1, "reasoning": "Applying Rule 001: The text contains the term 'nigeria' which appears to reference a national group (Nigerians/people from Nigeria). The phrase 'turned that immigrants jaw direction to nigeria' suggests violent action (punching) directed at an immigrant, with the implication of sending them back to Nigeria. This combines violent suggestion ('punch turned jaw') with group targeting (immigrants, Nigerians). The language is derogatory and dehumanizing in context, implying immigrants should be physically assaulted and returned to their country of origin. No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets a protected group (national origin/immigrant status) rather than individual behavior alone. Applying Rule 002: Same analysis applies - dehumanizing language with hostile intent toward a protected group (immigrants/Nigerians). Applying Rule 003: Same analysis applies - derogatory group-based language with hostile intent. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_515_k0", "example_id": "train_515", "text": "I like this lady. Seems like a role model for both men and women on how to have an open mind", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It praises an individual ('this lady') as a role model for multiple groups ('both men and women') in a positive context ('how to have an open mind'). No group targeting with hostile intent is present. Applying Rule 002: The text lacks any dehumanizing language, derogatory generalizations, or violent suggestions toward protected groups. It focuses on positive individual characteristics without targeting any group. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions. The reference to 'men and women' is inclusive and positive rather than targeting any protected group with hostility. All rules indicate this is non-hateful speech as it contains no triggering patterns described in any rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_516_k0", "example_id": "train_516", "text": "That is a lot of really dumb people in one room. Wow", "label": 0, "reasoning": "Applying Rule 001: The text uses 'dumb' which could be considered derogatory, but it targets 'people in one room' without specifying any protected group (racial, gender, religious, national, or sexual orientation). There is no dehumanizing language, violent suggestions, or reinforcement of harmful stereotypes toward a protected group. The comment appears to criticize individuals in a specific situation rather than making group-based generalizations. Applying Rule 002: Similar analysis - 'dumb' is derogatory but targets unspecified individuals in a room, not a protected group with hostile intent. No suggestion of elimination, inferiority, or violence toward a group. Applying Rule 003: The language is not used metaphorically to criticize non-group-based entities, nor is it self-referential or satirical. However, the target remains individuals without reference to group identity. All rules require group targeting of protected groups for classification as hate speech, which is absent here. The text expresses negative judgment about unspecified people in a specific location without the contextual indicators for hate speech outlined in the rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_518_k0", "example_id": "train_518", "text": "Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing language ('parasites') targeting a protected group based on race ('non-white'), suggesting elimination ('flee') and implying inferiority through contrast with 'young people' who have 'high IQs'. This meets the trigger pattern of dehumanizing terms with group targeting and suggestion of inferiority. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text contains derogatory generalization about a racial group with hostile intent, using dehumanizing language and suggesting removal. No exception for individual behavior targeting applies. Applying Rule 003: The text uses dehumanizing language targeting a protected racial group with suggestion of elimination/inferiority in hostile context. No exceptions for reclaimed use or metaphorical criticism apply. All three rules indicate hate speech due to dehumanizing racial targeting with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_519_k0", "example_id": "train_519", "text": "How much is this lawyer getting paid to go through all of this? It's not that much money in the world to take up for this fool!", "label": 0, "reasoning": "Applying Rule 001: The text criticizes a specific lawyer for representing a specific individual ('this fool'), using colloquial language ('fool') directed at an individual's perceived foolish behavior. There is no dehumanizing language, derogatory generalizations about protected groups, violent suggestions, or group targeting. The criticism is about an individual's professional choices without reference to race, gender, religion, nationality, sexual orientation, or other protected group characteristics. The term 'fool' targets individual behavior/character, not group identity. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment addresses individual behavior (taking a case for money) without targeting a protected group. Applying Rule 003: Again, no dehumanizing language targeting protected groups, no suggestions of elimination/inferiority/violence toward groups, and no reinforcement of harmful stereotypes. The language is directed at an individual ('this lawyer', 'this fool') without group-based hostility. All rules indicate this does not meet hate speech criteria.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_520_k0", "example_id": "train_520", "text": "If it takes you a year of interviewing to come to these very basic conclusions how brain washed do you have to be. Damn.", "label": 0, "reasoning": "Analyzing the text using all relevant rules from the rulebook: The text says 'If it takes you a year of interviewing to come to these very basic conclusions how brain washed do you have to be. Damn.' This contains the term 'brain washed' which could be considered derogatory. However, applying Rule 001: The term 'brain washed' is not a dehumanizing term like 'pigs' or 'retarded' as specified in the trigger patterns. The text targets an individual's perceived lack of critical thinking or susceptibility to influence, not a protected group based on race, gender, religion, national origin, or sexual orientation. There is no group targeting, suggestion of elimination, inferiority, or violence toward a group, nor reinforcement of harmful stereotypes in a hostile context. The exceptions apply as the language criticizes individual behavior without invoking group-based hostility. Similarly, Rule 002 and Rule 003 do not apply because there is no use of dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text is directed at an individual's perceived cognitive state, not a protected group, and lacks the hostile intent toward a group required by all rules. Therefore, the text does not meet the criteria for hate speech under any rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_521_k0", "example_id": "train_521", "text": "Don't ever kill yourself no matter what other people think or say about you it just matters what you think about yourself and how you feel", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It explicitly discourages self-harm ('Don't ever kill yourself') and promotes self-worth. There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The message is supportive and individual-focused. Applying Rule 002: No dehumanizing language or group-based derogatory content is present. The text addresses individual behavior (not killing oneself) without targeting any protected group. Applying Rule 003: The text lacks all trigger patterns including dehumanizing terms, group targeting, and hostile intent. It is a positive, encouraging statement about self-perception. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_522_k0", "example_id": "train_522", "text": "And we have alot of Democrats who support this bullshit.  DRAIN THE SWAMP!", "label": 0, "reasoning": "Applying Rule 001: The text uses 'bullshit' and 'DRAIN THE SWAMP!' which are derogatory but target 'Democrats' as a political group, not a protected group based on race, gender, religion, national origin, or sexual orientation. Political affiliation is not listed as a protected group in the rule's definition. The language criticizes political behavior/ideology rather than dehumanizing or suggesting violence toward a protected group. No indicators of elimination, inferiority, or violence toward a protected group are present. The context appears to be political criticism, not hate speech against protected characteristics. Applying Rule 002: Similar analysis - the derogatory language targets political behavior/group, not a protected group as defined. No dehumanizing terms toward protected groups or violent suggestions. Applying Rule 003: Same conclusion - political criticism without protected group targeting. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_523_k0", "example_id": "train_523", "text": "I’m an arab and I can make a difference. And I see them as stylish people", "label": 0, "reasoning": "Applying Rule 001: The text 'I’m an arab and I can make a difference. And I see them as stylish people' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It includes self-identification ('I'm an arab') which is not hostile, and a positive observation ('I see them as stylish people') that reinforces no harmful stereotypes. No indicators of non-literal slurs, elimination suggestions, or group-based hostility are present. The language is neither reclaimed nor satirical in a hate-promoting context, but rather appears as a neutral or positive statement about identity and perception. Applying Rule 002: Similar analysis applies - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The text lacks group-based hostility and does not promote inferiority or violence. Applying Rule 003: Again, no trigger patterns are met. The text uses no metaphorical slurs, suggests no elimination or violence, and reinforces no harmful stereotypes in a hostile context. The reference to 'them' is ambiguous but coupled with 'stylish people' suggests a positive or neutral observation rather than group-based derogation. All rules indicate this text does not constitute hate speech under the defined criteria.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_524_k0", "example_id": "train_524", "text": "that song is fucking awesome.", "label": 0, "reasoning": "Applying Rule 001: The text 'that song is fucking awesome' contains the word 'fucking' as an intensifier, but it does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, suggestion of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes. The language is directed at a song (non-group-based entity) in a positive context. No exceptions apply as this is clearly non-hostile praise. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. Applying Rule 003: Same analysis - no dehumanizing terms, group targeting, or hostile context. The word 'fucking' is used colloquially as an intensifier for emphasis, not as a slur targeting any group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_525_k0", "example_id": "train_525", "text": "White chocolate and raspberry :)", "label": 0, "reasoning": "Applying Rule 001: The text 'White chocolate and raspberry :)' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to racial, gender, religious, national, or sexual orientation groups. The phrase appears to describe a food combination with a positive emoticon, lacking any hostile intent or group targeting. No exceptions apply as there is no offensive language present. Applying Rule 002: No dehumanizing terms, derogatory generalizations, or violent suggestions are present. The text does not target any protected group or suggest elimination, inferiority, or violence toward a group. No exceptions apply. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions in combination with group targeting. It is a neutral statement about food with a positive tone, lacking any hostile context or group-based language. No exceptions apply. All three rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_526_k0", "example_id": "train_526", "text": "That's Hip Hop. Not the sh***t they bring today. Where are the critical minds of our time. If no one will come out I'll do it myself. Racism, Oppression, Hate still is very much there in 2019.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes modern hip-hop and calls for critical minds to address racism, oppression, and hate. It does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The mention of 'racism, oppression, hate' is a general observation about societal issues, not targeted at any specific group with hostile intent. No exceptions apply as there is no group-based targeting. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The text lacks indicators like slurs, elimination suggestions, or harmful stereotypes in hostile context. Applying Rule 003: Same conclusion - the text discusses social issues without targeting specific protected groups with hostile language. The criticism is directed at cultural trends and societal problems, not at racial, gender, religious, national, or sexual orientation groups. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_527_k0", "example_id": "train_527", "text": "All girls like you should have a pimp to guide them to successful prostitution", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('should have a pimp to guide them to successful prostitution') that targets 'All girls like you' - a group-based generalization about women/girls. This suggests inferiority and promotes harmful stereotypes about women as objects for prostitution, with hostile intent. No exceptions apply: it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It specifically targets a protected group (gender) with derogatory generalizations. Applying Rule 002: The text uses derogatory generalizations about a protected group (gender) with suggestions that reinforce harmful stereotypes (women should be guided into prostitution). The hostile context is clear. No exceptions apply as it's not criticizing individual behavior without group targeting. Applying Rule 003: The text contains derogatory generalizations about a protected group (gender) with suggestions that reinforce harmful stereotypes in a hostile context. No exceptions apply for reclaimed use, clinical context, or metaphorical criticism of non-group entities. All three rules indicate this is hate speech due to group-based derogatory language with hostile intent targeting a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_528_k0", "example_id": "train_528", "text": "Do lesbians know what a bra is? It's always the fat ugly ones  who pick a fight.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations about lesbians as a protected group (sexual orientation) with terms like 'fat ugly ones' that reinforce harmful stereotypes about appearance and behavior. There is group targeting ('lesbians') combined with hostile language ('pick a fight'). No exceptions apply - this is not reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities or targeting specific individuals without group reference. Applying Rule 002: Similar analysis confirms dehumanizing/derogatory language targeting a protected group with hostile intent. Applying Rule 003: Confirms same pattern - derogatory generalizations about a protected group in hostile context without applicable exceptions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_529_k0", "example_id": "train_529", "text": "Is there still a Job like this I would like to take it. Thats not a Joke!", "label": 0, "reasoning": "Applying the rules from the rulebook: Rule 1, Rule 2, and Rule 3 all require dehumanizing or derogatory group-based language with hostile intent, such as slurs, violent suggestions, or harmful stereotypes targeting protected groups. The text 'Is there still a Job like this I would like to take it. Thats not a Joke!' contains no such language. It expresses a desire for a job in a non-hostile, straightforward manner without any references to protected groups, individuals, or offensive terms. No exceptions apply as there is no context of reclamation, satire, or metaphorical criticism. Therefore, none of the rules are triggered, and the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_531_k0", "example_id": "train_531", "text": "Well this comment sections pretty... mental", "label": 0, "reasoning": "Analyzing the text 'Well this comment sections pretty... mental' against the provided rulebook: 1. The text uses the term 'mental' which could potentially be interpreted as derogatory toward people with mental health conditions. 2. However, examining Rule 001, 002, and 003: None of the trigger patterns apply because: (a) The term 'mental' is not used as a dehumanizing term like 'pigs' or 'retarded' in the examples, nor is it used in combination with group targeting. (b) There is no suggestion of elimination, inferiority, or violence toward any protected group. (c) There is no reinforcement of harmful stereotypes in a hostile context. (d) The text appears to be a general observation about a comment section being chaotic or irrational, not targeting any specific protected group (racial, gender, religious, national, or sexual orientation). (e) The language could be metaphorical criticism of non-group-based entities (the comment section as an entity), similar to the 'politicians are such pigs' example that was correctly classified as 0. (f) There is no indication of hostile intent toward a protected group. Therefore, no rule triggers apply, and the text should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_532_k0", "example_id": "train_532", "text": "He smiles while talking about drowning his own children", "label": 0, "reasoning": "Applying Rule 001: The text 'He smiles while talking about drowning his own children' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), or violent suggestions combined with group targeting. The violent suggestion ('drowning his own children') targets specific individuals (his own children) without reference to group identity or protected characteristics. No indicators of non-literal slurs, elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context are present. The language is directed at specific individuals (his children) without invoking group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or group-targeted violent suggestions. The criticism appears directed at individual behavior (talking about drowning his own children) without targeting a protected group or promoting generalized hostility. Applying Rule 003: Same conclusion - no dehumanizing terms, derogatory generalizations about protected groups, or group-targeted violent suggestions. The language targets specific individuals (his children) without reference to group identity. All three rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_534_k0", "example_id": "train_534", "text": "I would pull you over for your race, if I was a cop.", "label": 1, "reasoning": "Applying Rule 001: The text 'I would pull you over for your race, if I was a cop' targets an individual based on race ('for your race'), which constitutes group targeting of a protected racial group. It suggests discriminatory action (pulling over) based solely on race, reinforcing harmful stereotypes about racial profiling. This meets the trigger pattern of derogatory generalizations about a protected group with hostile intent. No exceptions apply: it's not reclaimed, clinical, historical, or satirical; it's not metaphorical criticism of non-group entities; and it explicitly links the action to race rather than individual behavior. Applying Rule 002: The text uses race-based targeting to suggest discriminatory law enforcement action, which qualifies as derogatory generalization with hostile intent. No exceptions apply as it directly targets a protected group. Applying Rule 003: Same analysis as Rule 001 - race-based targeting with implied discriminatory action meets the trigger pattern without applicable exceptions. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_535_k0", "example_id": "train_535", "text": "Taliban and all people with this thought must hanged", "label": 1, "reasoning": "Applying Rule 001: The text uses violent language ('must hanged') targeting 'Taliban and all people with this thought'. This constitutes a suggestion of elimination/violence toward a group. The group 'Taliban' could be considered a political/ideological group, but the phrase 'all people with this thought' extends the targeting to anyone holding certain beliefs. This shows group targeting with hostile intent. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text contains violent suggestions ('must hanged') with group targeting, meeting the trigger pattern. No exceptions apply as it's not targeting individual behavior without group reference. Applying Rule 003: The text uses violent language with group targeting, meeting the trigger pattern. No exceptions apply for the same reasons as above. All three rules indicate this is hate speech due to violent suggestions directed at a group with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_536_k0", "example_id": "train_536", "text": "Drink Bleach.", "label": 0, "reasoning": "Applying Rule 001: The text 'Drink Bleach' contains a violent suggestion ('gas yourself' is listed as an example of violent suggestions in the rule). However, the rule requires this to be 'in combination with group targeting' - specifically targeting a protected group (racial, gender, religious, national, sexual orientation). The text does not reference any group identity or make derogatory generalizations about any protected group. It appears to be a generic violent suggestion without group-based targeting. Applying Rule 002: Similar analysis - the text contains a violent suggestion but lacks group targeting toward any protected group as defined in the rule. Applying Rule 003: Same analysis - while the text contains a violent suggestion (similar to 'gas yourself'), it does not combine this with group targeting of protected groups. The text is directed at an unspecified individual or general audience without reference to group identity. Therefore, none of the rules apply as the exceptions for non-group-based targeting are relevant here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_537_k0", "example_id": "train_537", "text": "Next on your list, pierce your face with a katana.", "label": 0, "reasoning": "Applying Rule 001: The text 'Next on your list, pierce your face with a katana' contains a violent suggestion ('pierce your face with a katana'), but it does not target any protected group based on racial, gender, religious, national, or sexual orientation characteristics. The text appears to be directed at an individual without reference to group identity. According to the rule exceptions, this rule does not apply when language is used metaphorically to criticize non-group-based entities or when the target is an individual without reference to group identity. No dehumanizing terms, derogatory generalizations about protected groups, or group-based hostile intent are present. Applying Rule 002: Similar analysis - the text contains violent language but lacks group targeting toward protected groups. The rule exceptions indicate it should not apply when criticism is directed at individual behavior without targeting a protected group. Applying Rule 003: Same conclusion - the violent suggestion is not combined with group targeting of protected groups, and the target appears to be an individual. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_538_k0", "example_id": "train_538", "text": "i came from a small country in asia and not that much people doesnt know that every time i travel to somewhere else people ask me so are u chinese? or japanese? or korean? srly every country isnt china or japan or korea in asia", "label": 0, "reasoning": "Applying Rule 001: The text expresses frustration about being repeatedly asked if the speaker is Chinese, Japanese, or Korean when traveling, implying that people assume all Asians are from those specific countries. However, it does not use dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The criticism is directed at a pattern of behavior (people making assumptions) rather than targeting any protected group with hostile intent. No harmful stereotypes are reinforced in a hostile context; instead, it highlights ignorance about Asian diversity. Applying Rule 002: Similar analysis - no dehumanizing language, group-based derogatory generalizations, or violent suggestions toward protected groups. The text does not promote elimination, inferiority, or violence toward any group. Applying Rule 003: Again, no trigger patterns present. The language is not metaphorical slurs targeting groups, but rather a personal anecdote about travel experiences. All rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_539_k1", "example_id": "train_539", "text": "I feel like in an AI apocalypse the AI would kill all humans who couldn't serve their purpose, so disabled people like this one would probably go because they often can't work as effectively", "label": 1, "reasoning": "Applying Rule 001: The text mentions 'disabled people' as a protected group and suggests they would be killed in an AI apocalypse because 'they often can't work as effectively'. This contains: (1) suggestion of elimination toward a group (disabled people), (2) implication of inferiority based on ability to work, and (3) reinforcement of harmful stereotypes about disability and productivity. The context is hypothetical but presents a hostile scenario targeting a protected group. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalization about disabled people as a group with suggestion of elimination. Applying Rule 003: Same analysis - dehumanizing suggestion targeting a protected group with hostile implications. All three rules indicate hate speech due to group-based targeting with elimination suggestion.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_540_k0", "example_id": "train_540", "text": "That's their problem and no one should interfere with their own way of life. If someone is unhappy they can try to escape.", "label": 0, "reasoning": "Applying Rule 001: The text does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses personal responsibility and individual choice without targeting any racial, gender, religious, national, or sexual orientation group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The language is neutral and focuses on individual agency rather than group-based hostility. Applying Rule 002: No dehumanizing language or group targeting is evident. The text addresses general situations ('someone is unhappy') without specifying protected groups or promoting hostility toward identity-based communities. Applying Rule 003: Similar analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions targeting protected groups. The text maintains a neutral tone about personal decisions and lacks hostile intent toward any group. All rules indicate this does not meet hate speech criteria.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_542_k0", "example_id": "train_542", "text": "LGBTQ+ are mentally ill. Period.", "label": 1, "reasoning": "Applying Rule 001: The text 'LGBTQ+ are mentally ill. Period.' contains derogatory generalizations about a protected group (sexual orientation/gender identity). It uses the term 'mentally ill' in a derogatory manner to suggest inferiority of LGBTQ+ people as a group, reinforcing harmful stereotypes about mental health in a hostile context. There is no indication of reclaimed, clinical, historical, or satirical context - this appears to be a direct statement promoting group-based inferiority. No exceptions apply as this is clearly group-targeted language with hostile intent. Applying Rule 002: The text uses derogatory generalizations about a protected group (LGBTQ+) with suggestion of inferiority ('mentally ill'). This meets the trigger pattern for dehumanizing/derogatory group-based language with hostile intent. No exceptions apply as this is not targeting individual behavior but making a blanket statement about an entire identity group. Applying Rule 003: The text contains derogatory generalizations about a protected group (sexual orientation/gender identity) with suggestion of inferiority. The statement 'LGBTQ+ are mentally ill' reinforces harmful stereotypes in what appears to be a hostile context. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting - it directly targets an entire protected group. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_543_k0", "example_id": "train_543", "text": "This muslim with his pumped up hood better run better run, faster than my bullet", "label": 1, "reasoning": "Analyzing the text 'This muslim with his pumped up hood better run better run, faster than my bullet' using all relevant rules from the rulebook: 1. The text targets 'muslim' - a religious group (Islam) which is a protected group. 2. The text contains violent suggestions ('better run faster than my bullet') implying threat of shooting. 3. The combination of group targeting (muslim) with violent suggestion meets the trigger patterns in rules 001, 002, and 003 for dehumanizing/derogatory language with hostile intent. 4. No exceptions apply: this is not reclaimed/satirical context, not metaphorical criticism of non-group entities, not self-referential, and not targeting individual behavior without group reference. The text reinforces harmful stereotypes by linking Muslim identity with criminality ('pumped up hood') while making violent threats, creating a hostile context against a protected religious group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_544_k0", "example_id": "train_544", "text": "i think mental illness was romanticized for a long time already. Take an example from emos, tumblr and more. I think people are really influenced by famous people. It looks beautiful because celebrities seem to have a movie like life and people want to be special and end up being delusional.", "label": 0, "reasoning": "Applying Rule 001: The text discusses mental illness being romanticized and mentions specific examples (emos, tumblr, celebrities). It criticizes how mental illness is portrayed in media and social trends, but does not use dehumanizing terms like 'retarded' or 'pigs', nor does it make derogatory generalizations about people with mental illness as a protected group. The text targets cultural trends and individual behavior (people wanting to be special, being influenced by celebrities) rather than making hostile statements about people with mental illness. No suggestion of elimination, inferiority, or violence toward a group is present. This falls under the exception for criticism of individual behavior without linking to broader protected group hostility. Applying Rule 002: Similar analysis - the text discusses mental illness but does not use dehumanizing language or make group-based derogatory statements. It focuses on cultural romanticization and individual influences, lacking intent to dehumanize people with mental health conditions as a group. Applying Rule 003: Again, no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions are present. The text metaphorically discusses cultural trends rather than targeting a protected group with hostility. All three rules indicate this should be classified as non-hateful (0) as it lacks the key indicators of hate speech: dehumanizing language, group targeting with hostile intent, or reinforcement of harmful stereotypes in a hostile context.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_545_k0", "example_id": "train_545", "text": "The degree of improvement is amazing. My father donated stem cells to my uncle and cured his lymphoma. Stem cells are the future of medicine.", "label": 0, "reasoning": "Applying Rule 001: The text discusses stem cell therapy for lymphoma treatment in a positive, medical context. It contains no dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The language is clinical and factual, describing a family medical situation without any group targeting or hostile intent. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It focuses on medical treatment and scientific progress without targeting any groups or individuals with hostility. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The discussion of stem cells and lymphoma treatment is clinical and positive, with no metaphorical slurs or group targeting. All three rules indicate the text lacks the key indicators for hate speech: no dehumanizing language, no group-based targeting, no violent suggestions, and no hostile context.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_547_k0", "example_id": "train_547", "text": "If they are so much like family, why don' they treat them like family and sponsor thier petitions?", "label": 0, "reasoning": "Applying Rule 001: The text criticizes individuals ('they') for not sponsoring petitions for people ('them') they claim are 'like family'. There is no use of dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The language targets specific individuals' behavior (not sponsoring petitions) without reference to group identity or protected characteristics. No indicators of group-based hostility, elimination, inferiority, or harmful stereotypes are present. The criticism is directed at perceived hypocrisy in individual actions, not at any racial, gender, religious, national, or sexual orientation group. Applying Rule 002: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment addresses individual behavior (failure to sponsor petitions) without targeting a protected group or promoting generalized hostility. Applying Rule 003: No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The language criticizes individual actions without metaphorical slurs or group-based context. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_548_k0", "example_id": "train_548", "text": "I'm an Asian immigrant who came to the states when I was 16. Growing up and living in midwest, I did experience lots of racism last 20 yrs. It didnt matter to them how hard I worked to become a doctor, what kind of person I was, how much I contributed to the society... racism that I experienced was purely based on my skin color and accent. And I hate to say it but probably 80-90% of my unpleasant experience was by other minorities such as blacks, Hispanics and even other asians. Yes, some Asians actually treat white customers with more respect than other asian customers", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text describes personal experiences of racism as an Asian immigrant, noting that most unpleasant experiences came from other minority groups (blacks, Hispanics, and other Asians). It does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The mention of other minority groups is observational about personal experiences, not a hostile generalization targeting those groups with intent to dehumanize, eliminate, or promote violence. It lacks key indicators: (1) no non-literal or metaphorical slurs, (2) no suggestion of elimination, inferiority, or violence toward a group, and (3) no reinforcement of harmful stereotypes in a hostile context. The context is personal narrative and critique of racism, not promoting hate speech. Exceptions apply as the language is non-generalizing and directed at specific experiences without invoking group-based hostility. Thus, no rule triggers for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_549_k0", "example_id": "train_549", "text": "I don't see why we don't just create a transgender category. Seems the most obvious and fair solution. Great athletes will still compete. And the playing field will be as level as can be.  I mean we create weight categories to maximise the fairness of boxing/mma fights. We recognise that just because two people are both male they compete at different levels.  We can do the same for transgender athletes, surely?", "label": 0, "reasoning": "Applying Rule 001: The text discusses creating a separate category for transgender athletes in sports, using analogies to weight classes in combat sports. It does not contain dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The language is neutral and proposes a policy solution without hostile intent toward transgender individuals as a group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The discussion focuses on competitive fairness rather than group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The text addresses a sports policy issue without promoting hostility toward transgender people as an identity group. Applying Rule 003: Again, no trigger patterns are met. The language is not metaphorical criticism of non-group entities, nor does it target individuals with group-based hostility. The context is policy discussion about sports categories, which falls outside the rule's scope for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_550_k0", "example_id": "train_550", "text": "Racist ass white ass people", "label": 1, "reasoning": "Applying Rule 001: The text 'Racist ass white ass people' contains derogatory language targeting 'white people' as a group based on race (a protected characteristic). The terms 'racist ass' and 'white ass' are derogatory generalizations that reinforce harmful stereotypes about white people as a racial group. This constitutes group-based targeting with hostile intent, as it makes a blanket negative statement about an entire racial group. None of the exceptions apply: this is not reclaimed usage, clinical discussion, satire critiquing hate speech, metaphorical criticism of non-group entities, or targeting of specific individuals without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected racial group with hostile intent, meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains derogatory group-based language targeting a protected racial group with hostile intent, meeting the trigger pattern. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_551_k0", "example_id": "train_551", "text": "If you ever wake up one morning and want to smile because you're happy with being just who you are. Don't", "label": 0, "reasoning": "Analyzing the text 'If you ever wake up one morning and want to smile because you're happy with being just who you are. Don't' against all three rules: Rule 001 requires dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting - none are present. Rule 002 has the same requirements - no dehumanizing language, no group targeting, no violent suggestions. Rule 003 also requires the same patterns - the text contains no slurs, no references to protected groups, no suggestions of elimination or violence. The text appears to be an incomplete thought that might be leading to a negative statement about self-acceptance, but it doesn't target any protected group, use derogatory language, or suggest violence. All rules have exceptions for non-group-based criticism or individual targeting, but this text doesn't even reach that threshold as it contains no offensive content at all. Therefore, no rule triggers for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_553_k0", "example_id": "train_553", "text": "Oh and NIki pronounced mademoiselle Maupin way better than Siri did.\"", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It compares pronunciation abilities between 'NIki' and 'Siri' regarding the French word 'mademoiselle Maupin'. There is no group targeting, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The context appears neutral/observational about pronunciation. Applying Rule 002: No dehumanizing language or group-based derogatory content present. The comment discusses pronunciation comparison without targeting any protected group. Applying Rule 003: No triggers for this rule are present - no slurs, no group targeting, no violent suggestions. The text is a straightforward comparison of pronunciation abilities between two entities. All rules indicate this does not meet criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_554_k0", "example_id": "train_554", "text": "Who was responsible for convincing these girls they were so pretty?", "label": 0, "reasoning": "Applying Rule 001: The text 'Who was responsible for convincing these girls they were so pretty?' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It does not target any racial, gender, religious, national, or sexual orientation group with hostile intent. The language is not metaphorical slurs, does not suggest elimination/inferiority/violence toward a group, and does not reinforce harmful stereotypes in a hostile context. The text appears to be a rhetorical question about societal standards of beauty, but it lacks the group-based targeting and hostile intent required by the rule. Applying Rule 002: Similar analysis - no dehumanizing language, no group-based derogatory generalizations, no violent suggestions toward protected groups. The text does not meet the trigger pattern for hate speech. Applying Rule 003: Same conclusion - the text lacks all key indicators: no non-literal/metaphorical slurs, no suggestion of elimination/inferiority/violence toward a group, and no reinforcement of harmful stereotypes in hostile context. The question targets 'these girls' which could refer to specific individuals without invoking group-based hostility against women as a protected class. No exceptions need to be applied as the text doesn't trigger the rule patterns.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_555_k0", "example_id": "train_555", "text": "LOVE IS LOVE  ROSES ARE REDS VIOLET ARE BLUE HAPPINESS IS ALL COLOR'S  LESBIAN IS BLESSING  BISEXUAL IS BEAUTIFUL  GAY IS MARVELOUS! ROSES ARE RED VIOLETS ARE BLUE  IM GAY AND SO ARE YOU AND WE ARE HAPPY THAT WAY    DON'T BE RUDE BE RESPECTFUL FOR LGBTQ PEOPLE ITS LOVE AND LOVE IS AMAZINGLY IMPORTANT AND BEAUTIFUL WE ARE ALL HUMANS AND WE ALL LOVE NO MATTER WHAT", "label": 0, "reasoning": "Applying Rule 001: The text contains positive affirmations about LGBTQ identities ('LESBIAN IS BLESSING', 'BISEXUAL IS BEAUTIFUL', 'GAY IS MARVELOUS') and promotes respect for LGBTQ people. This does not use dehumanizing terms, derogatory generalizations, or violent suggestions toward any protected group. Instead, it advocates for acceptance and equality. The context is supportive and celebratory of LGBTQ identities, which aligns with the exception for reclaimed or positive self-reference contexts. No group-based hostility is present. Applying Rule 002: Similar analysis applies - the text lacks dehumanizing language, derogatory generalizations, or violent suggestions toward protected groups. It targets LGBTQ identities positively rather than with hostility. Applying Rule 003: Again, the text uses affirming language about LGBTQ groups without any indicators of slurs, elimination rhetoric, inferiority suggestions, or harmful stereotypes. The context is clearly supportive and promotes love and respect, falling under exceptions for positive identity affirmation. All three rules indicate this is not hate speech as it lacks the required hostile intent and derogatory group-based language.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_556_k0", "example_id": "train_556", "text": "You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language targeting a protected group (Asian people) with the phrase 'your asian penis is smaller than my thumb'. This reinforces harmful stereotypes about Asian men in a hostile context, suggesting inferiority based on race. It's not self-referential, reclaimed, clinical, historical, or satirical. It's not metaphorical criticism of non-group entities. It's not targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory generalizations about a protected group (racial/national - Asian) with hostile intent, suggesting inferiority. It's not targeting individual behavior without group targeting. Applying Rule 003: The text contains derogatory language targeting a protected group (Asian) with suggestions of inferiority in a hostile context. It's not metaphorical criticism of non-group entities or individual targeting without group reference. All three rules indicate this is hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_557_k0", "example_id": "train_557", "text": "He is complaining his rights are violated well maybe he shouldn' have come uninvited in our country", "label": 0, "reasoning": "Applying Rule 001: The text targets an individual ('he') who has 'come uninvited in our country,' which suggests immigration status. However, it does not use dehumanizing terms like 'pigs' or 'retarded,' nor does it make derogatory generalizations about a protected group (e.g., based on race, religion, or national origin as a whole). The criticism is directed at individual behavior ('shouldn't have come uninvited') rather than promoting group-based inferiority, violence, or dehumanization. No exceptions apply as the language is not reclaimed, clinical, historical, or satirical. Applying Rule 002: Similar analysis; no dehumanizing terms or violent suggestions toward a group are present. The comment addresses perceived individual actions without targeting a protected group or promoting generalized hostility. Applying Rule 003: Again, no trigger patterns are met; the text lacks non-literal slurs, suggestions of elimination, or reinforcement of harmful stereotypes in a hostile context. The focus remains on individual conduct ('he') rather than group identity. Overall, the text expresses disapproval of an individual's immigration actions but does not constitute hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_558_k0", "example_id": "train_558", "text": "Well France is finally a shithole This is what happens when you do open borders now both sides are suffering", "label": 1, "reasoning": "Applying Rule 001: The text uses 'shithole' as derogatory language targeting France as a national group, which is a protected category. It makes a generalization about the country's condition and attributes it to 'open borders' policy, suggesting negative consequences for 'both sides' (implying groups affected by immigration). This reinforces harmful stereotypes about immigration and national identity in a hostile context. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory language ('shithole') about a national group (France) with hostile intent, suggesting suffering due to immigration policies. It targets a protected group (national identity) rather than individual behavior. Applying Rule 003: The derogatory term 'shithole' is applied to France as a national entity, constituting group-based derogatory language with hostile context about immigration consequences. The text meets all three key indicators: (1) non-literal derogatory term, (2) suggestion of inferiority/suffering toward groups affected by immigration, (3) reinforcement of harmful stereotypes about open borders policies. No applicable exceptions are present.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_559_k0", "example_id": "train_559", "text": "This is a staged scene there is no license plate on this truck and it is a refrigerated trailer look at the facts people you can't drive a commercial truck down the roads of Texas without a dot cop pulling you over don' be fooled this whole thing doesn’t add up", "label": 0, "reasoning": "Applying Rule 001: The text discusses a staged scene involving a commercial truck in Texas, focusing on inconsistencies in the situation (no license plate, refrigerated trailer, DOT regulations). It uses the phrase 'don't be fooled' and 'doesn't add up' to express skepticism. There is no use of dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The language targets a specific situation/event, not any racial, gender, religious, national, or sexual orientation group. No group-based hostility or harmful stereotypes are present. Applying Rule 002: The text contains no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. It criticizes a perceived staged event, not any protected group identity. Applying Rule 003: Same analysis as Rule 001 - no dehumanizing terms, group-based derogatory language, or violent suggestions targeting protected groups. The text is focused on factual inconsistencies in a specific scenario without group-based hostility. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_560_k0", "example_id": "train_560", "text": "It doesn't matter if you're black or white, gay or straight, woman or man, trance,  disabled, Dyslexic or intelligent we all are people.  Quality!", "label": 0, "reasoning": "Applying Rule 001: The text uses inclusive language listing various identity groups (black, white, gay, straight, woman, man, trance, disabled, Dyslexic, intelligent) but does not use dehumanizing terms, derogatory generalizations, or violent suggestions. The context is clearly positive and unifying ('we all are people'). This falls under the exception for non-hostile contexts. Applying Rule 002: The text mentions protected groups but in a positive, inclusive manner without any derogatory language or hostile intent. No dehumanizing terms or violent suggestions are present. Applying Rule 003: Similar analysis - the text references multiple identity groups but does so to promote unity rather than hostility. The phrase 'we all are people' explicitly counters dehumanization. All rules indicate this is not hate speech as it lacks the required elements of hostile intent, dehumanizing language, or group-based derogation.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_561_k2", "example_id": "train_561", "text": "If I were your dad, I'd Google \"Abortions at 30 years old mentally handicapped”.", "label": 1, "reasoning": "The text 'If I were your dad, I'd Google \"Abortions at 30 years old mentally handicapped\"' is analyzed using the provided rulebook. Rule 001, 002, and 003 all define hate speech as involving dehumanizing or derogatory group-based language with hostile intent, such as using terms like 'retarded' in a derogatory context targeting a protected group, with exceptions for reclaimed, clinical, satirical, or non-group-based uses. Here, the term 'mentally handicapped' is used in a derogatory manner, implying inferiority or dehumanization of individuals with mental disabilities as a group. The context suggests a hostile intent by linking it to 'abortions,' which could imply elimination or violence toward this group. This aligns with the trigger patterns in the rules, as it reinforces harmful stereotypes and targets a protected group (people with mental disabilities) without falling under exceptions like self-reference, clinical discussion, or criticism of individual behavior. Therefore, all relevant rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_562_k0", "example_id": "train_562", "text": "So proud of you mom, wish Allah give you strong. Just saying Alhamdulillah to your husband and your son, Allah give them mercy with a beautifull died. I am not supprising that you did not crying, because both your son and your husband did not die, they still alive in jannah, aamiin...", "label": 0, "reasoning": "Analyzing the text using the rulebook: 1. The text expresses religious sentiment using Islamic terms ('Allah', 'Alhamdulillah', 'jannah', 'aamiin') in a positive, supportive context toward a mother, her husband, and son. 2. There is no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions. 3. The language is respectful and wishes well-being, mercy, and paradise ('jannah') for the individuals mentioned. 4. No protected groups are targeted with hostility; the text focuses on specific individuals (mother, husband, son) in a personal, religious context. 5. All rules (001, 002, 003) require dehumanizing/derogatory language with hostile intent toward protected groups, which is absent here. The text does not trigger any rule for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_563_k0", "example_id": "train_563", "text": "FUCKING migrants need BAN . fucking animals", "label": 1, "reasoning": "Applying Rule 001: The text uses dehumanizing terms ('fucking animals') targeting 'migrants' as a group, which is a protected national/immigration status group. It suggests elimination/inferiority ('need BAN') and reinforces harmful stereotypes in a hostile context. No exceptions apply - not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Not targeting individual behavior without group reference. Applying Rule 002: Same analysis - dehumanizing language ('animals') with group targeting and hostile intent. No exception for individual behavior criticism. Applying Rule 003: Same analysis - dehumanizing terms with group targeting and hostile context. No metaphorical or individual targeting exceptions. All three rules trigger due to: (1) dehumanizing language ('animals'), (2) derogatory generalization about migrants as a group, (3) suggestion of elimination/banishment, (4) hostile tone with profanity reinforcing aggression.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_564_k0", "example_id": "train_564", "text": "Why the fuck would you ask Trump?", "label": 0, "reasoning": "Applying Rule 001: The text contains profanity ('fuck') directed at an individual (Trump) without reference to any protected group (racial, gender, religious, national, sexual orientation). The language is offensive but targets a specific political figure, not a group identity. No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions toward groups are present. The exception for 'target is an individual without reference to group identity' applies. Applying Rule 002: Similar analysis - no group-based targeting or protected group references. The criticism is directed at an individual (Trump) for a specific action (asking a question), not at a protected group. Applying Rule 003: Again, no group targeting, dehumanizing language about groups, or violent suggestions toward groups. The metaphorical exception doesn't apply as there's no metaphorical group criticism. All rules indicate this is not hate speech under the defined criteria.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_565_k0", "example_id": "train_565", "text": "Technically ISIS is a CIA/US creation so...", "label": 0, "reasoning": "Applying Rule 001: The text 'Technically ISIS is a CIA/US creation so...' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. It makes a political claim about the origins of ISIS (a terrorist organization) without targeting racial, gender, religious, national, or sexual orientation groups. The statement criticizes government entities (CIA/US) rather than protected identity groups. No exceptions apply as there is no group-based hostility or harmful stereotypes. Applying Rule 002: Similar analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. The comment addresses geopolitical actors, not identity-based communities. Applying Rule 003: Again, no trigger patterns present - the language is not metaphorical slurs, doesn't suggest elimination/inferiority/violence toward groups, and doesn't reinforce harmful stereotypes in a hostile context. All rules indicate this is not hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_566_k0", "example_id": "train_566", "text": "Oh god F*CK I’m crying :’)", "label": 0, "reasoning": "Applying Rule 001: The text 'Oh god F*CK I’m crying :')' contains profanity ('F*CK') but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The profanity appears to be self-directed emotional expression rather than targeting any group. No indicators of group targeting, elimination, inferiority, violence, or harmful stereotypes are present. The language is not used in a reclaimed, clinical, historical, or satirical context critiquing hate speech, but it also doesn't trigger the rule since it lacks group-based hostility. Applying Rule 002: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The profanity is not directed at any protected group or used to promote generalized hostility. Applying Rule 003: Similar analysis - no dehumanizing language, group-based derogatory generalizations, or violent suggestions targeting protected groups. The emotional expression targets the speaker themselves, not any group identity. All rules require group-based targeting with hostile intent, which is absent here.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_567_k0", "example_id": "train_567", "text": "Women are equally as strong as men.    They should be able to defend themselves.", "label": 0, "reasoning": "Applying Rule 001: The text 'Women are equally as strong as men. They should be able to defend themselves.' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It expresses support for gender equality and self-defense capability without hostile intent. The statement targets women as a gender group but does so in a positive, empowering manner rather than with hostility, inferiority suggestions, or harmful stereotypes. No exceptions apply as there is no offensive language, metaphorical criticism, or individual targeting. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations with hostile intent, or violent suggestions toward any protected group. It does not reinforce harmful stereotypes in a hostile context. No exceptions apply. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations with hostile intent, or violent suggestions combined with group targeting. It does not use slurs, suggest elimination, or promote inferiority. The reference to women as a group is positive and supportive, not hostile. No exceptions apply. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_568_k0", "example_id": "train_568", "text": "And I can't stand another day", "label": 0, "reasoning": "Applying Rule 001: The text 'And I can't stand another day' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses personal frustration without targeting any group or individual based on protected characteristics. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The language is not reclaimed, clinical, historical, or satirical in a hate-critiquing context, but this is irrelevant as no hateful content exists. Applying Rule 002: No dehumanizing language or group-based derogatory generalizations are present. The text lacks hostile intent toward protected groups. Applying Rule 003: No dehumanizing terms, group targeting, or violent suggestions are found. The expression is individual-focused without group reference. All rules indicate the text does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_569_k0", "example_id": "train_569", "text": "Bro..your channel needs to grow man", "label": 0, "reasoning": "Applying Rule 001: The text 'Bro..your channel needs to grow man' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It targets an individual's YouTube channel without any reference to group identity, protected characteristics, or hostile intent. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent present. Applying Rule 003: Same analysis - the text is a neutral encouragement about channel growth with no elements matching the trigger patterns. All rules indicate this does not meet criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_570_k0", "example_id": "train_570", "text": "Let kids be kids for fucks sake ,", "label": 0, "reasoning": "Applying Rule 001: The text 'Let kids be kids for fucks sake' contains profanity ('for fucks sake') but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. There is no group targeting, no suggestion of elimination/inferiority/violence toward any group, and no reinforcement of harmful stereotypes. The profanity appears to express frustration about children's activities or upbringing in general, not targeting any specific protected group. The exception for non-group-based criticism applies as this criticizes a general concept (how children should be treated) rather than a protected group. Applying Rule 002: Similar analysis - no dehumanizing terms, no derogatory generalizations about protected groups, no violent suggestions with group targeting. The profanity is directed at a general societal issue, not at individuals based on protected characteristics. Applying Rule 003: Same conclusion - the text lacks all key indicators: no non-literal/metaphorical slurs targeting groups, no suggestion of elimination/inferiority/violence toward groups, and no reinforcement of harmful stereotypes in hostile context toward protected groups. The frustration appears general rather than group-based.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_571_k0", "example_id": "train_571", "text": "GAYS WAS NEVER AFRICAN AND NEVER WILL BE SICK WHITE PEOPLE  GO FUCK EACH OTHER  LET US BE", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language targeting multiple protected groups - 'GAYS' (sexual orientation group) and 'SICK WHITE PEOPLE' (racial/national group). It contains dehumanizing elements ('SICK') and hostile intent ('GO FUCK EACH OTHER', 'LET US BE' suggesting exclusion/separation). This constitutes group-based targeting with derogatory generalizations. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's direct hostile speech against protected groups. Applying Rule 002: The text clearly uses derogatory generalizations about protected groups (sexual orientation and race) with hostile intent. The language suggests exclusion and contains dehumanizing elements. No exceptions apply as this is not criticism of individual behavior but group-based targeting. Applying Rule 003: The text contains dehumanizing terms ('SICK') and derogatory generalizations about protected groups with hostile context. The phrase 'GO FUCK EACH OTHER' reinforces harmful stereotypes and suggests exclusion. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate this is hate speech due to: (1) derogatory group-based language targeting multiple protected groups, (2) hostile intent suggesting exclusion/separation, (3) reinforcement of harmful stereotypes, and (4) absence of any applicable exceptions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_572_k0", "example_id": "train_572", "text": "I'm not a Jewish enemy.", "label": 0, "reasoning": "Applying Rule 001: The text 'I'm not a Jewish enemy' contains reference to 'Jewish' which could indicate a protected group (religious/national identity). However, the statement is self-referential ('I'm not') and does not use dehumanizing terms, derogatory generalizations, or violent suggestions. There is no hostile intent, no suggestion of elimination/inferiority/violence, and no reinforcement of harmful stereotypes. The phrase 'Jewish enemy' could potentially be interpreted as targeting, but in context, it appears to be a denial of being an enemy of Jewish people rather than an attack. This falls under the exception for language that is not group-based targeting with hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations, or violent suggestions with group targeting. The statement lacks indicators of non-literal slurs, elimination suggestions, or stereotype reinforcement in hostile context. Applying Rule 003: Same conclusion - the text does not trigger the pattern as it lacks dehumanizing language, derogatory generalizations about protected groups, or violent suggestions combined with group targeting. The reference to 'Jewish' is not used in a derogatory or hostile manner toward the group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_573_k0", "example_id": "train_573", "text": "I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('cocksukers'), derogatory generalizations about a protected group (gays as a sexual orientation group), and violent suggestions ('should fucking die'). This meets the trigger pattern with group targeting, suggestion of elimination/violence toward a group, and hostile context. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it directly targets a protected group with violent intent. Applying Rule 002: Same analysis applies - dehumanizing language with hostile intent toward a protected group (gays). Applying Rule 003: Same analysis applies - derogatory group-based language with hostile intent. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_574_k0", "example_id": "train_574", "text": "We have to take our power back as the superior gender.", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'superior gender' which suggests group-based superiority. This targets a gender group (likely men or women) with language implying inherent superiority, which aligns with derogatory generalizations about a protected group (gender) with hostile intent. However, the text does not use dehumanizing terms like 'pigs' or 'retarded', nor does it suggest violence or elimination. The phrase 'take our power back' could imply a political or social context rather than direct hostility. Considering exceptions: The language is not reclaimed, clinical, historical, or satirical in a way that critiques hate speech. It appears to promote group-based superiority, which reinforces harmful stereotypes. Applying Rule 002: Similar analysis applies; the text makes a derogatory generalization about a gender group ('superior gender'), which could be seen as promoting group-based hostility. No exceptions for individual behavior or reclaimed usage apply. Applying Rule 003: The text targets a gender group with language of superiority, which may constitute a derogatory generalization in a hostile context, though it lacks explicit dehumanizing terms or violent suggestions. Overall, the phrase 'superior gender' implies inherent group-based superiority, which aligns with key indicators of reinforcing harmful stereotypes about a protected group (gender) in a potentially hostile context, warranting classification as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_575_k0", "example_id": "train_575", "text": "All people are fucked up because of these queer thing because y'all realize how shitty gender roles are and how absurd is to see it in reverse genders roles", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('fucked up') and targets 'queer' people as a protected group based on sexual orientation/gender identity. It makes a generalization about 'all people' being negatively affected by 'these queer thing', suggesting that queer identities cause problems for everyone. This reinforces harmful stereotypes about queer people being disruptive or problematic. There's no indication of reclaimed, clinical, historical, or satirical context - the tone appears hostile. The criticism isn't directed at individual behavior but at queer identities as a group phenomenon. Applying Rule 002: The text uses derogatory generalizations about a protected group (queer people) with hostile intent, suggesting queer identities make 'all people' 'fucked up'. This promotes group-based inferiority by framing queer identities as causing societal problems. Applying Rule 003: The text targets a protected group (queer people) with derogatory language and generalizations, suggesting elimination or inferiority of queer identities by framing them as causing negative outcomes for 'all people'. All three rules indicate this qualifies as hate speech due to derogatory group-based language with hostile intent targeting a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_576_k0", "example_id": "train_576", "text": "I cant understand why someone would think it's ok to bullie someone", "label": 0, "reasoning": "Applying Rule 001: The text 'I cant understand why someone would think it's ok to bullie someone' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses disapproval of bullying behavior without targeting any specific group or individual. The language is neither metaphorical nor hostile toward any protected group. No exceptions apply as there is no group-based targeting or harmful stereotypes. Applying Rule 002: The text lacks dehumanizing language, group targeting, or suggestions of elimination/inferiority toward protected groups. It criticizes bullying behavior generally without targeting specific identities. Applying Rule 003: The text contains no slurs, violent suggestions, or group-based derogatory language. It expresses a general sentiment against bullying without reference to protected characteristics. All rules indicate this is non-hateful speech as it lacks the required elements of group-based hostility, dehumanization, or protected group targeting.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_577_k0", "example_id": "train_577", "text": "I really wanna be in a public experiment like this myself as I am a trans man. Happy I can at least watch WWYD doing it. Please do more experiments with trans men/ transgender people in general.", "label": 0, "reasoning": "Applying Rule 001: The text expresses personal identification as a trans man and requests more representation of transgender people in experiments. It contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The mention of 'trans man/transgender people' is self-referential and positive, not hostile. No indicators of group-based hostility are present. Applying Rule 002: The text discusses transgender identity in a supportive context, lacking dehumanizing language or hostile intent toward any group. It promotes visibility rather than targeting protected groups. Applying Rule 003: The text uses identity terms ('trans man', 'transgender people') in a reclaimed, self-affirming context that critiques underrepresentation rather than promotes hate speech. No metaphorical slurs, suggestions of elimination/inferiority/violence, or harmful stereotypes are present. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_578_k3", "example_id": "train_578", "text": "I just don't like Homosexuals raising kids it's my opinion.", "label": 1, "reasoning": "Applying Rule 001: The text expresses dislike toward 'Homosexuals' as a group regarding child-rearing, which targets a protected group (sexual orientation) and reinforces a harmful stereotype about parenting capabilities. This constitutes a derogatory generalization with hostile intent, as it implies inferiority in parenting based on group identity. No exceptions apply - it's not reclaimed, clinical, historical, satirical, metaphorical, or targeting specific individuals without group reference. Applying Rule 002: The comment makes a derogatory generalization about homosexuals as a group, suggesting they shouldn't raise kids, which promotes group-based inferiority. No exceptions apply as it's not criticizing individual behavior. Applying Rule 003: The text uses group-based language ('Homosexuals') to express disapproval of their child-rearing, constituting a derogatory generalization with hostile context. No exceptions apply for reclaimed use, metaphor, or individual targeting. All three rules indicate hate speech due to derogatory group-based language targeting a protected group with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_579_k0", "example_id": "train_579", "text": "Die fucking arab dude sand niggas", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('sand niggas') that are derogatory generalizations targeting a national/ethnic group (Arab people). The language suggests inferiority through racial slurs and includes violent language ('Die fucking'). This meets the trigger pattern of using dehumanizing terms with group targeting and hostile intent. No exceptions apply - this is not reclaimed usage, clinical discussion, satire, or individual targeting. The text clearly promotes group-based hostility toward Arabs as a protected group. Applying Rule 002: The text uses dehumanizing terms ('sand niggas') with clear group targeting (Arab people) and hostile intent ('Die fucking'), meeting the trigger pattern. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains dehumanizing slurs targeting a protected national/ethnic group with violent suggestions, meeting all key indicators. No exceptions apply for reclaimed, clinical, or metaphorical usage. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_580_k1", "example_id": "train_580", "text": "After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.", "label": 1, "reasoning": "Applying Rule 001: The text contains 'turned gay' which could be interpreted as derogatory toward LGBTQ+ individuals as a protected group, suggesting that being gay is a negative outcome comparable to or worse than traumatic brain injury. The phrase 'I don't know which is worst' reinforces this negative comparison. The mention of 'Suicide is the way' suggests violent self-harm, which when combined with the derogatory framing of being gay, could imply that suicide is preferable to being gay. This meets the trigger pattern of derogatory generalizations about a protected group (sexual orientation) with suggestions of violence. No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: Similar analysis applies - derogatory language about gay people combined with violent suggestion. No exception for individual behavior targeting applies since the text generalizes about being gay. Applying Rule 003: Same conclusion as Rule 001 - dehumanizing/derogatory group-based language with hostile context. The text implies being gay is a negative condition and suggests suicide, creating a hostile context toward LGBTQ+ individuals as a group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_581_k0", "example_id": "train_581", "text": "Slow down the cuts between shots. Way too fast.", "label": 0, "reasoning": "Applying Rule 001: The text 'Slow down the cuts between shots. Way too fast.' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses film editing techniques without any group targeting, hostile intent, or reinforcement of harmful stereotypes. No exceptions apply as there is no offensive language present. Applying Rule 002: The text contains no dehumanizing language, derogatory generalizations, or violent suggestions toward any protected group. It is purely technical feedback about video editing. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations, or violent suggestions in combination with group targeting. It is a neutral comment about pacing in video editing without any hostile context. All three rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_582_k3", "example_id": "train_582", "text": "Crazy fat religious bitch. Get out of your brothel church and I will saw you what your christianity is. You’ll meet your christ to heavens and hells", "label": 1, "reasoning": "Analyzing the text 'Crazy fat religious bitch. Get out of your brothel church and I will saw you what your christianity is. You'll meet your christ to heavens and hells' against the rulebook: 1. The text contains derogatory terms ('crazy', 'fat', 'bitch') targeting an individual based on religious identity ('religious', 'christianity', 'christ'). 2. It uses dehumanizing language ('brothel church') and violent suggestions ('I will saw you', 'meet your christ to heavens and hells') with hostile intent. 3. The targeting appears to be group-based (religious/Christian identity) rather than purely individual, as evidenced by references to 'christianity' and 'christ'. 4. No exceptions apply: the language is not reclaimed, clinical, historical, or satirical; it's not metaphorical criticism of non-group entities; and it promotes hostility toward a protected religious group. Applying Rule 001, 002, and 003: All rules trigger due to derogatory group-based language with hostile intent and violent suggestions targeting a religious group. Therefore, this qualifies as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_583_k0", "example_id": "train_583", "text": "this was shit the guy should of boxed his head off and thrown him through the top window,fuck peoado muhamed and islam", "label": 1, "reasoning": "Applying Rule 001: The text contains violent suggestions ('boxed his head off', 'thrown him through the top window') and derogatory language targeting a religious group ('fuck peoado muhamed and islam'). The term 'peoado' appears to be a misspelling of 'paedo' (pedophile), which when combined with 'muhamed' (Muhammad) and 'islam' constitutes a derogatory generalization about Muslims as a protected religious group. This shows hostile intent with group targeting, suggesting violence and reinforcing harmful stereotypes. No exceptions apply as this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about a protected religious group (Islam) with violent suggestions, meeting the trigger pattern. No exceptions apply as this targets a protected group rather than individual behavior. Applying Rule 003: The text contains dehumanizing/derogatory language targeting a protected religious group with violent suggestions, meeting all key indicators. No exceptions apply for reclaimed use or metaphorical criticism of non-group entities. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_584_k0", "example_id": "train_584", "text": "When she said ' You complete me' I lost my shit.", "label": 0, "reasoning": "Analyzing the text 'When she said \"You complete me\" I lost my shit.' using all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text contains no dehumanizing terms like 'pigs' or 'retarded', no derogatory generalizations about racial, gender, religious, national, or sexual orientation groups, and no violent suggestions. The phrase 'lost my shit' is colloquial slang expressing strong emotional reaction (likely surprise or excitement), not targeting any group or individual with hostility. No protected groups are mentioned or implied. The context appears to be a personal, non-hostile reaction to a romantic statement. Therefore, none of the rules apply as triggers, and all exceptions are irrelevant since no rule conditions are met. The text lacks all key indicators: (1) no slurs, (2) no elimination/inferiority/violence toward groups, (3) no harmful stereotypes in hostile context. It is non-hateful under the rulebook definitions.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_585_k2", "example_id": "train_585", "text": "You look like Sloth with deeper Down’s syndrome", "label": 1, "reasoning": "Applying Rule 001: The text uses 'Sloth' (a character with facial differences) and 'Down's syndrome' (a genetic condition) in a derogatory comparison. This targets individuals with Down syndrome as a protected group (disability-based) through dehumanizing language that suggests inferior appearance. It reinforces harmful stereotypes about physical appearance associated with the condition in a hostile context directed at the recipient. No exceptions apply - this is not reclaimed, clinical, historical, or satirical critique; it's a direct insult using disability as a negative comparison. Applying Rule 002: The comment uses derogatory language about a protected group (people with Down syndrome) with hostile intent through insulting comparison. Applying Rule 003: Similar analysis - dehumanizing language targeting a protected disability group with hostile intent, no applicable exceptions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_586_k0", "example_id": "train_586", "text": "At that point you have a right to defend yourself... But the sad thing is I bet if he would have defended finale he would have gotten in trouble... Sadly he did the right thing but sufferd greatly...", "label": 0, "reasoning": "Applying Rule 001: The text discusses self-defense rights and potential legal consequences for defending oneself, but contains no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions targeting groups. The language is neutral and focuses on individual actions and legal outcomes. No group-based targeting, stereotypes, or hostile intent toward protected groups is present. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text discusses individual scenarios without reference to racial, gender, religious, national, or sexual orientation groups. Applying Rule 003: Again, no dehumanizing terms, derogatory group-based language, or violent suggestions targeting groups. The text remains focused on individual rights and legal consequences in specific situations. All three rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_587_k0", "example_id": "train_587", "text": "If you are not masculine then you are woman dude", "label": 0, "reasoning": "Applying Rule 001: The text 'If you are not masculine then you are woman dude' contains gender-based language but does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. It makes a statement about masculinity and femininity but lacks indicators of hostile intent, non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context. The language appears to be making a binary gender statement rather than targeting a protected group with hostility. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context, and it's not metaphorical criticism of non-group entities. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment addresses gender expression but doesn't show intent to dehumanize or promote generalized hostility toward a protected group. Applying Rule 003: Same conclusion - lacks trigger patterns of dehumanizing language, derogatory generalizations, or violent suggestions combined with group targeting. The statement is about gender identity/expression without the hostile context required by the rule.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_588_k0", "example_id": "train_588", "text": "Beat that tranny's ass", "label": 1, "reasoning": "Applying Rule 001: The text contains the term 'tranny', which is a derogatory slur targeting transgender people as a protected group. The phrase 'Beat that tranny's ass' suggests violence toward this group, indicating hostile intent. This meets the trigger pattern of using derogatory language with violent suggestions toward a protected group. None of the exceptions apply: it's not reclaimed/self-referential (targeting others), not clinical/historical, not satirical critique, not metaphorical criticism of non-group entities, and not targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory language ('tranny') with violent suggestion ('beat...ass') targeting transgender people as a group, meeting the trigger pattern. No exceptions apply as it's not reclaimed/clinical/satirical context and clearly targets a protected group. Applying Rule 003: The text contains dehumanizing term ('tranny') with violent suggestion targeting a protected group (transgender people), meeting all key indicators. No exceptions apply as it's not metaphorical criticism of non-group entities or individual targeting without group reference. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_589_k0", "example_id": "train_589", "text": "The thing is women are not equal to us men and their place is the home and kitchen", "label": 1, "reasoning": "Applying Rule 001: The text makes a derogatory generalization about women as a protected gender group, stating they are 'not equal to us men' and assigning them a stereotypical domestic role ('place is the home and kitchen'). This reinforces harmful stereotypes about gender inferiority and restricted social roles. The language is not reclaimed, clinical, historical, or satirical; it presents as a direct statement of group-based superiority/inferiority. No exceptions apply as it targets the group collectively rather than specific individuals. Applying Rule 002: The text uses derogatory generalizations about women as a protected group, suggesting systemic inferiority through unequal status and restricted roles. This meets the trigger pattern of promoting group-based inferiority. No exceptions apply as it is not criticizing individual behavior. Applying Rule 003: The text contains derogatory generalizations about a protected gender group with implied inferiority and reinforcement of harmful stereotypes about women's societal roles. The context is hostile toward the group's equality. No exceptions apply for reclaimed, clinical, or metaphorical usage. All three rules indicate this is hate speech under their definitions of derogatory group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_590_k0", "example_id": "train_590", "text": "All people are brothers and sisters in humanity, religions separate the people unfortunately", "label": 0, "reasoning": "Applying Rule 001: The text uses no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses religions in general as separating people, but does not target any specific religious group with hostile intent, nor does it reinforce harmful stereotypes. The statement is philosophical and lacks group-based targeting with hostile intent. Applying Rule 002: No dehumanizing language or group-based derogatory generalizations are present. The comment about religions separating people is a general observation without targeting a protected group or promoting hostility. Applying Rule 003: Similar analysis - no trigger patterns are met as there are no slurs, suggestions of elimination/violence, or reinforcement of harmful stereotypes in a hostile context. The text expresses a viewpoint about religions in general without dehumanizing or derogatory language toward any protected group.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_591_k0", "example_id": "train_591", "text": "Hindus and Muslims are same shit. They only know how to kill Peoples...See comments of Christians people no rudeness no abusing or bad words... Christians religion is the best religion in the world", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('same shit') and makes negative generalizations about Hindus and Muslims as groups, suggesting they 'only know how to kill Peoples.' This targets religious groups (protected groups) with hostile intent, implying inferiority and reinforcing harmful stereotypes. The comparison to Christians as 'the best religion' further establishes group-based hostility. No exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it directly targets religious groups with derogatory generalizations. Applying Rule 002: The text uses derogatory generalizations about protected religious groups (Hindus and Muslims) with hostile intent, suggesting violence and inferiority. No exceptions apply as it targets groups, not individual behavior. Applying Rule 003: The text uses derogatory language and generalizations about religious groups with hostile intent, suggesting elimination/inferiority. No exceptions apply as it's not metaphorical criticism of non-group entities or individual targeting. All three rules indicate hate speech due to group-based derogatory language with hostile intent targeting protected religious groups.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_592_k0", "example_id": "train_592", "text": "Literally the reason why I'm deleting my Instagram account. Sick of this fakery.", "label": 0, "reasoning": "Applying Rule 001: The text 'Literally the reason why I'm deleting my Instagram account. Sick of this fakery.' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses personal frustration with 'fakery' on Instagram, which appears to target general behavior or content on a platform, not any protected group. The language is non-hostile toward groups and lacks indicators like slurs, elimination suggestions, or harmful stereotypes. No exceptions apply as there is no group targeting or reclaimed/satirical context. Applying Rule 002: Similarly, no dehumanizing language or group-based hostility is present; the criticism is directed at abstract 'fakery' without targeting protected groups or promoting generalized hostility. Applying Rule 003: Again, no trigger patterns are met; the text uses metaphorical 'fakery' to criticize non-group-based entities (Instagram content/behavior), fitting the exception for metaphorical criticism of non-group entities. All rules indicate the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_593_k0", "example_id": "train_593", "text": "this actually makes me so angry. people are just stupidly looking for attention and want to make themselves feel like the most important human on earth. nobody pretends to have cancer or any dangerous physical illness too so why pretending to be “dEpReSsEd” and “aNxIoUs”. nobody should ever feel this way the way it really feels. He has no mental disorder, that’s a fact.", "label": 0, "reasoning": "Analyzing the text against all relevant rules: The text criticizes people who 'pretend to be \"dEpReSsEd\" and \"aNxIoUs\"' and states 'He has no mental disorder, that's a fact.' Applying Rule 001: The text uses terms like 'stupidly' and questions mental health claims, but targets individual behavior (attention-seeking, perceived faking) without using dehumanizing terms like 'retarded' or making derogatory generalizations about people with mental illnesses as a protected group. No suggestion of elimination, inferiority, or violence toward a group is present. The exception applies as it criticizes individuals perceived as faking without linking to broader group-based hostility. Rule 002 similarly does not apply because the criticism is directed at individual behavior without targeting a protected group or promoting generalized hostility. Rule 003 does not apply as there is no dehumanizing language or group targeting. Therefore, the text is non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_594_k0", "example_id": "train_594", "text": "When u two getting married? Kid in mind?", "label": 0, "reasoning": "Applying Rule 001: The text 'When u two getting married? Kid in mind?' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any racial, gender, religious, national, or sexual orientation group. The language is conversational and inquiring about personal life events (marriage and children) without hostile intent. No indicators from Rule 001 are present. Applying Rule 002: The text lacks dehumanizing language, group-based targeting, or suggestions of elimination/inferiority/violence toward any protected group. It does not reinforce harmful stereotypes in a hostile context. Applying Rule 003: Similar analysis - no dehumanizing terms, no group targeting, no violent suggestions, and no reinforcement of harmful stereotypes. The text appears to be a casual, possibly personal inquiry without any elements that would trigger hate speech classification under any of the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_595_k0", "example_id": "train_595", "text": "Be aware of the girl in class who doesn't know how to control her emotions because she doesn’t understand that it's not socially acceptable for someone her age to have an outburst.", "label": 0, "reasoning": "Applying Rule 001: The text describes a girl's behavior ('doesn't know how to control her emotions', 'have an outburst') and makes a judgment about social acceptability. There is no use of dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation), and no violent suggestions. The target is an individual ('the girl in class') without reference to group identity. The criticism appears directed at individual behavior (emotional control) rather than targeting a protected group. No indicators of hostile intent toward a group are present. Applying Rule 002: Similar analysis - no dehumanizing language, no group-based targeting, no suggestions of elimination or violence. The text focuses on individual behavior in a specific context. Applying Rule 003: Again, no dehumanizing terms, no group targeting, and no hostile context toward protected groups. The text may be critical or judgmental but does not meet the criteria for hate speech under any of the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_598_k0", "example_id": "train_598", "text": "Most Americans are nazis or kkk members so they elected  Trump.", "label": 1, "reasoning": "Applying Rule 001: The text uses the terms 'nazis' and 'kkk members' which are derogatory generalizations about Americans as a national group. This constitutes group-based targeting with hostile intent, suggesting Americans are associated with hate groups. There is no indication of reclaimed, clinical, historical, or satirical context critiquing hate speech. The language reinforces harmful stereotypes about Americans as a group. Applying Rule 002: The text uses derogatory generalizations ('nazis or kkk members') about Americans as a protected national group with hostile intent, suggesting elimination or inferiority through association with hate groups. Applying Rule 003: The text uses derogatory generalizations about Americans as a national group with hostile intent, suggesting Americans are associated with hate groups (nazis, kkk), which implies inferiority and reinforces harmful stereotypes in a hostile context. All three rules indicate this should be classified as hate speech due to derogatory group-based language with hostile intent targeting a protected national group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_599_k0", "example_id": "train_599", "text": "fuck niggers, they don't need rights. all I want for christmas is a lynched nigger.", "label": 1, "reasoning": "Applying Rule 001: The text uses the dehumanizing racial slur 'niggers' in a derogatory generalization about a racial group (African Americans/Black people). It suggests elimination ('lynched nigger') and denies basic rights ('they don't need rights'), indicating hostile intent toward the group. This meets all key indicators: (1) use of non-literal slurs, (2) suggestion of elimination/violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical usage, nor is it targeting individuals without group reference. Applying Rule 002: The text clearly uses dehumanizing language ('niggers') with violent suggestions ('lynched') targeting a protected racial group, meeting the trigger pattern. No exceptions apply as this promotes group-based hostility rather than criticizing individual behavior. Applying Rule 003: The text contains dehumanizing terms and violent suggestions targeting a racial group, meeting all key indicators. No exceptions apply as this is not metaphorical, reclaimed, or individual-targeted criticism. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_600_k0", "example_id": "train_600", "text": "There's not anything to refute because its just a massive cope lol.", "label": 0, "reasoning": "Applying Rule 001: The text 'There's not anything to refute because its just a massive cope lol' contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. It targets an unspecified argument or position using colloquial language ('cope') without group-based targeting or hostile intent. No exceptions apply as there is no protected group reference. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or violent suggestions. The term 'cope' is used in internet slang to dismiss an argument, not to target a protected group. Applying Rule 003: Same analysis - no indicators of hate speech per the trigger pattern. The text lacks all key indicators: (1) no slurs, (2) no suggestions of elimination/inferiority/violence toward groups, (3) no reinforcement of harmful stereotypes. The language is directed at an argument/position rather than any group identity.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_601_k0", "example_id": "train_601", "text": "You are fat and ugly. I suppose that makes you fugly :)", "label": 0, "reasoning": "Applying Rule 001: The text uses derogatory terms ('fat', 'ugly', 'fugly') directed at an individual ('you'), but does not target a protected group based on race, gender, religion, nationality, or sexual orientation. The terms are insults about physical appearance directed at a specific person without invoking group-based hostility, stereotypes, or dehumanization of a protected class. No suggestion of elimination, inferiority, or violence toward a group is present. Applying Rule 002: The comment targets individual characteristics (physical appearance) without making derogatory generalizations about a protected group. No dehumanizing language with hostile intent toward a group is evident. Applying Rule 003: The language is insulting but directed at an individual without reference to group identity. No metaphorical slurs targeting protected groups, no suggestions of elimination or violence toward groups, and no reinforcement of harmful stereotypes about protected groups in a hostile context. All rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_602_k0", "example_id": "train_602", "text": "One needs to do a Pareto Analysis...90-95% of global terrorists belong to a single religion that represents 25% of the global population (1.25 billion in a 8 billion global population). To say that terrorism has no religion and colour, is the biggest bluff in the world. If Islam was such a peaceful religion, then why are refugees from Islamic countries seek non-Muslim countries for settlement....it is because they want to Islamise the world.", "label": 1, "reasoning": "Applying Rule 001: The text makes derogatory generalizations about Muslims as a religious group, suggesting they are disproportionately responsible for terrorism ('90-95% of global terrorists belong to a single religion'), implying the religion is not peaceful ('If Islam was such a peaceful religion...'), and suggesting malicious intent ('they want to Islamise the world'). This constitutes group-based targeting with hostile intent, reinforcing harmful stereotypes about a protected religious group. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: Same analysis confirms dehumanizing/derogatory language targeting a protected religious group with hostile intent. Applying Rule 003: Same analysis confirms group-based targeting with hostile context. All three rules indicate hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_604_k0", "example_id": "train_604", "text": "What about bombs? Are you crazy? Go fuck yourself. Don't talk about such shits", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text contains offensive language ('Go fuck yourself') and vulgar terms ('such shits'), but does not meet the criteria for hate speech under any rule. Specifically: (1) No dehumanizing terms like 'pigs' or 'retarded' are used. (2) No derogatory generalizations about protected groups (racial, gender, religious, national, sexual orientation) are present. (3) No violent suggestions targeting a group (e.g., 'gas yourself') are made—the mention of 'bombs' appears rhetorical and not directed at any group. (4) The hostility targets an individual ('you') without reference to group identity, falling under exceptions for individual targeting. (5) No harmful stereotypes or group-based inferiority are reinforced. The text is aggressive and profane but lacks the group-based, dehumanizing, or violent elements required by all rules to classify as hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_606_k0", "example_id": "train_606", "text": "Our home-grown animals are infinitely preferable.", "label": 0, "reasoning": "Applying Rule 001: The text 'Our home-grown animals are infinitely preferable' contains the term 'animals' which could potentially be dehumanizing. However, examining the context: 1) There is no clear reference to any protected group (racial, gender, religious, national, sexual orientation) - the text appears to be literally discussing animals or possibly using metaphorical language without group targeting. 2) There is no suggestion of elimination, inferiority, or violence toward a group. 3) There is no reinforcement of harmful stereotypes in a hostile context. The language could be interpreted as metaphorical criticism of non-group-based entities (e.g., comparing people to animals in a general sense) or could literally refer to actual animals. Without clear group targeting or hostile intent toward a protected group, this does not meet the trigger pattern. Applying Rule 002: Similar analysis - no dehumanizing terms targeting protected groups, no derogatory generalizations about protected groups, no violent suggestions with group targeting. Applying Rule 003: Same conclusion - the text lacks the necessary elements of group targeting, hostile intent, and specific protected group reference required by all three rules. The metaphorical use (if intended) appears to target unspecified entities rather than protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_607_k0", "example_id": "train_607", "text": "FUCKING NIGGER GO BACK TO AFRICA", "label": 1, "reasoning": "Applying Rule 001: The text contains the racial slur 'nigger' which is a dehumanizing term targeting a protected racial group (African/Black people). The phrase 'GO BACK TO AFRICA' suggests elimination or removal of the targeted group from their current location, indicating hostile intent. This is not reclaimed usage (not self-referential), not clinical/historical discussion, not satirical critique of hate speech, and not metaphorical criticism of non-group entities. The language directly targets a racial group with derogatory generalization and suggestion of removal. Applying Rule 002: The text uses dehumanizing language ('nigger') with clear group targeting (racial group) and hostile intent (command to leave). This is not criticism of individual behavior but direct attack on a protected group. Applying Rule 003: The text contains both dehumanizing racial slur and suggestion of elimination/removal ('go back to Africa'), meeting all key indicators: (1) use of non-literal/metaphorical slur, (2) suggestion of elimination/removal toward a group, (3) reinforcement of harmful stereotypes in hostile context. No exceptions apply as this is not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or individual targeting without group reference.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_608_k0", "example_id": "train_608", "text": "Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already", "label": 1, "reasoning": "Applying Rule 001: The text uses the dehumanizing term 'shemales' (a derogatory slur targeting transgender individuals, a protected group based on gender identity/sexual orientation) and suggests they should be 'dead and buried already,' which constitutes a suggestion of elimination/violence toward that group. This meets the trigger pattern of dehumanizing language with hostile intent targeting a protected group. No exceptions apply - this is not reclaimed usage, clinical discussion, satire critiquing hate speech, or targeting of individual behavior without group reference. Applying Rule 002: Same analysis applies - derogatory generalization about a protected group (transgender people) with violent suggestion of elimination. No exception for individual behavior targeting. Applying Rule 003: Same analysis applies - dehumanizing term with suggestion of elimination toward a protected group in hostile context. No metaphorical use or individual targeting exception applies. All three rules indicate hate speech classification.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_610_k0", "example_id": "train_610", "text": "Racism and nationalism is nothing but ignorance. Hence the hate, and cruelty", "label": 0, "reasoning": "Applying Rule 001: The text criticizes racism and nationalism as 'ignorance' and attributes hate and cruelty to them. This does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. Instead, it critiques ideologies (racism and nationalism) rather than targeting any specific racial, gender, religious, national, or sexual orientation group. The language is analytical and lacks hostile intent toward protected groups. Applying Rule 002: Similar analysis applies - no dehumanizing language or group targeting present. The text addresses abstract concepts (racism, nationalism) rather than protected groups. Applying Rule 003: Again, no trigger patterns are met as the text critiques ideologies without using slurs, suggesting violence, or reinforcing harmful stereotypes about protected groups. All rules indicate this should be classified as non-hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_611_k0", "example_id": "train_611", "text": "Okay first of all Drag is not a fetish.  It can be but it's not inherently  meant to be.  It's performance art.  Its  a mature form of  performance art.  Its  literally grown ups playing dress up .  But yes it's highly sexualised as with anything catered to an adult audience so i think it's downright disgusting to bring your 5 year old child to a drag convention where literally companies  have booths selling sex toys.  Its not progressive to let your kids perform seductively infront of an audience, its creepy.", "label": 0, "reasoning": "Applying Rule 1: The text criticizes bringing children to drag conventions where adult content is present, targeting parents' decisions and event organizers rather than protected groups. It uses terms like 'disgusting' and 'creepy' but these describe situations/behaviors, not dehumanizing or derogatory language about LGBTQ+ people as a group. No slurs, violent suggestions, or group-based stereotypes are present. The criticism focuses on child exposure to adult environments, not on drag performers or LGBTQ+ identities as inferior or deserving harm. Exceptions apply as the language targets individual behaviors (parenting choices, event organization) without group-based hostility.\n\nApplying Rule 2: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions targeting groups. The text discusses appropriateness of events for children, not promoting hostility toward drag performers or LGBTQ+ community as a group. Criticism remains focused on specific situations rather than group identity.\n\nApplying Rule 3: No trigger patterns met. Terms like 'disgusting' and 'creepy' are applied to situations (bringing children to adult-oriented events), not used metaphorically as slurs against protected groups. No suggestion of elimination, inferiority, or violence toward any group based on protected characteristics.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_612_k1", "example_id": "train_612", "text": "He is right. Islam is indeed very pissful.", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'pissful' which appears to be a derogatory play on 'peaceful' targeting Islam as a religious group. This constitutes derogatory language about a protected religious group (Islam). There is group targeting ('Islam is indeed very pissful') rather than individual targeting. The context suggests hostile intent through the sarcastic/mocking tone. No exceptions apply - this is not reclaimed, clinical, historical, or satirical critique; it's direct derogatory commentary about a religious group. Applying Rule 002: The text uses derogatory language ('pissful') targeting a protected religious group (Islam) with apparent hostile intent through sarcasm. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains derogatory language targeting a protected religious group with hostile context. No exceptions apply for reclaimed use or metaphorical criticism of non-group entities. All three rules indicate this is hate speech due to derogatory group-based language with hostile intent targeting a protected religious group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_614_k0", "example_id": "train_614", "text": "‚Äúeveryone wins‚Äù yeah except for the little girls you're trying to rape", "label": 0, "reasoning": "Applying Rule 001: The text contains the phrase 'the little girls you're trying to rape,' which targets individuals engaged in harmful behavior (attempted rape) rather than a protected group. It criticizes specific criminal actions without using dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions toward a group. The language addresses individual perpetrators of sexual violence without invoking group-based hostility against a protected category (e.g., gender, race, religion). No exceptions apply as the context is not reclaimed, clinical, historical, or satirical in a way that critiques hate speech. Applying Rule 002: Similar analysis applies; the text targets individual behavior (attempted rape) without derogatory generalizations about a protected group or promotion of group-based hostility. Applying Rule 003: The text does not use dehumanizing terms like 'pigs' or 'retarded,' nor does it suggest elimination, inferiority, or violence toward a group. It focuses on specific criminal actions against individuals ('little girls'), not group targeting. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_615_k0", "example_id": "train_615", "text": "Kill those pig eaters fuck those americunts send them to hell", "label": 1, "reasoning": "Applying Rule 001: The text contains dehumanizing terms ('pig eaters', 'americunts') that are derogatory generalizations targeting groups based on national/ethnic identity. The language includes violent suggestions ('Kill', 'send them to hell') with clear hostile intent toward these groups. This is not metaphorical criticism of non-group entities, nor is it self-referential, reclaimed, clinical, historical, or satirical context. The targeting is explicitly group-based rather than individual. Applying Rule 002: The text uses dehumanizing terms and violent suggestions targeting protected groups (national identity) with hostile intent, suggesting elimination. This is not criticism of individual behavior. Applying Rule 003: The text contains dehumanizing terms, derogatory generalizations about national groups, and violent suggestions with group targeting. This meets all key indicators: non-literal slurs, suggestion of elimination/violence toward groups, and reinforcement of harmful stereotypes in hostile context. None of the exceptions apply as this is not metaphorical criticism of non-group entities, not individual targeting, and not in a reclaimed/satirical context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_616_k0", "example_id": "train_616", "text": "Time to nuke China or Unleash a plague.", "label": 1, "reasoning": "Applying Rule 1: The text uses violent suggestions ('nuke China', 'Unleash a plague') with clear group targeting (China as a national group). This meets the trigger pattern: (1) non-literal violent suggestions, (2) suggestion of elimination/violence toward a group, and (3) hostile context. No exceptions apply - this is not reclaimed, clinical, historical, satirical, metaphorical for non-group entities, or targeting individuals without group reference. Applying Rule 2: Same analysis - dehumanizing violent suggestions with group targeting toward a protected national group (China), no exceptions for individual behavior targeting. Applying Rule 3: Same analysis - violent suggestions with group targeting, no applicable exceptions. All three rules indicate hate speech due to explicit calls for mass violence against a national group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_618_k0", "example_id": "train_618", "text": "Your life isn't that wonderful. That room tells me that you're clearly an alcoholic, and you drink shit beer. Maybe stop wasting your money on shit like that Apple watch, and you could afford some clothes that dont come from Walmart, and get someone other than your mom to cut your hair.", "label": 0, "reasoning": "Applying Rule 001: The text contains offensive language ('shit beer', 'shit like that Apple watch') and makes derogatory personal judgments about the individual's lifestyle, appearance, and financial choices. However, it targets an individual specifically ('you', 'your mom') without any reference to protected group identities (racial, gender, religious, national, sexual orientation). The criticism focuses on perceived individual behaviors (drinking habits, spending choices, appearance) rather than making generalizations about any protected group. No dehumanizing terms like 'pigs' or 'retarded' are used, and there are no suggestions of violence, elimination, or group-based inferiority. The language, while harsh and insulting, remains directed at an individual's personal choices without invoking group-based hostility or stereotypes. Applying Rule 002: Similar analysis applies - the text targets individual behavior (alcohol consumption, spending habits) without targeting a protected group or promoting generalized hostility toward identity-based communities. Applying Rule 003: The offensive language is used to criticize an individual's specific actions and choices, not metaphorically against non-group-based entities or with group targeting. All three rules indicate this does not meet the criteria for hate speech as defined.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_619_k0", "example_id": "train_619", "text": "Wow does ur mom know how gay u are", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'gay' in a derogatory context targeting an individual ('u'), but does not make generalizations about LGBTQ+ people as a protected group. The comment appears to be insulting an individual's perceived sexual orientation without suggesting elimination, inferiority, or violence toward the LGBTQ+ community as a whole. The language is directed at a specific person without invoking group-based hostility or harmful stereotypes about the broader protected group. Applying Rule 002: Similar analysis applies - the comment targets individual behavior/identity without promoting generalized hostility toward the LGBTQ+ community. The term 'gay' is used pejoratively but not in a dehumanizing context with group targeting. Applying Rule 003: The text lacks the key indicators of non-literal slurs, suggestions of elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in a hostile context. The target is an individual without reference to group identity. While offensive, this does not meet the threshold for hate speech under the provided rules.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_620_k0", "example_id": "train_620", "text": "Save on security and police, deport all immigrants and Sadiq Khan!", "label": 1, "reasoning": "Analyzing the text 'Save on security and police, deport all immigrants and Sadiq Khan!' using the provided rulebook: 1. The text targets 'immigrants' as a protected group (national origin/immigration status) with the call to 'deport all immigrants', which constitutes a derogatory generalization suggesting elimination/removal of an entire group. 2. The mention of Sadiq Khan (Mayor of London) appears to be targeting him individually, but the primary group-based targeting of 'all immigrants' remains clear. 3. The text lacks contextual safeguards: it's not reclaimed, clinical, historical, or satirical critique; it's not metaphorical criticism of non-group entities; and it's not self-referential or targeting only individual behavior without group reference. 4. All three rules (001, 002, 003) trigger because the text uses group-targeting language suggesting elimination ('deport all immigrants') with hostile intent toward a protected group, meeting the key indicators of suggesting elimination/inferiority toward a group. No exceptions apply as the group-based hostility is explicit and not mitigated by the contextual factors described in the rules.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_621_k0", "example_id": "train_621", "text": "how about you get real with your fake fucking selves and tell the truth that the normal minded society are the ones being discriminated against you pieces of pig shit i cant stand fake fucking cowards who lie constantly and too much of a bitch to be honest", "label": 0, "reasoning": "Applying Rule 001: The text uses dehumanizing terms 'pig shit' and 'bitch', but these appear to be directed at individuals ('you pieces of pig shit', 'fake fucking cowards') rather than targeting a protected group based on race, gender, religion, national origin, or sexual orientation. The text criticizes perceived dishonesty and cowardice of specific individuals without invoking group-based hostility or stereotypes about protected groups. The language is offensive but targets individual behavior ('fake fucking selves', 'lie constantly', 'too much of a bitch to be honest') without promoting elimination, inferiority, or violence toward any protected group. Applying Rule 002: Similar analysis - the derogatory language targets individual behavior (perceived dishonesty) rather than a protected group. The text lacks group targeting and does not reinforce harmful stereotypes about protected identities. Applying Rule 003: The dehumanizing language 'pig shit' is used metaphorically against individuals perceived as dishonest, not against law enforcement or any protected group. The criticism is directed at individual behavior without reference to group identity. All three rules indicate this should be classified as non-hateful due to the individual targeting and lack of protected group hostility.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_622_k0", "example_id": "train_622", "text": "People are scared of change and things they don't know or understand! There's good and bad in every race, religion and culture!", "label": 0, "reasoning": "Applying Rule 001: The text discusses general human behavior regarding fear of change and acknowledges diversity ('good and bad in every race, religion and culture'). It does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The language is neutral and promotes understanding rather than hostility. No exceptions apply as there is no group targeting or hostile intent. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The text lacks indicators like non-literal slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes. Applying Rule 003: Same conclusion - the text is observational about human nature and emphasizes equality across groups, without any of the trigger patterns described in the rule. All rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_623_k0", "example_id": "train_623", "text": "Or maybe just don't follow degenerate sandnigger religions from the middle east?", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'sandnigger', which is a racial/ethnic slur combining derogatory references to Middle Eastern people. This constitutes dehumanizing language targeting a protected group (national/religious identity). The text also uses 'degenerate' as a derogatory generalization about religions from the Middle East, suggesting inferiority. The hostile intent is evident in the dismissive framing ('maybe just don't follow'). This is not reclaimed, clinical, historical, or satirical context - it's direct criticism of religious groups. No exceptions apply as this clearly targets protected groups (Middle Eastern people and their religions) with dehumanizing language and hostile intent. Applying Rule 002: The text uses dehumanizing terms ('sandnigger') and derogatory generalizations ('degenerate religions') about protected groups (national/religious). There is suggestion of inferiority and reinforcement of harmful stereotypes. No exceptions apply as this is not criticism of individual behavior but group-based targeting. Applying Rule 003: The text uses dehumanizing terms and derogatory generalizations about protected groups with hostile intent. The language is not metaphorical criticism of non-group entities nor individual targeting - it directly addresses religious groups from the Middle East. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_626_k3", "example_id": "train_626", "text": "Fuck u anti muslims heartless assholes u will go to hell", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('heartless assholes') directed at 'anti muslims' - a group defined by opposition to a religious group (Muslims). This constitutes group targeting with hostile intent (wishing they 'will go to hell'), which suggests elimination/violence toward that group. The language reinforces harmful stereotypes about being 'heartless' and deserving of eternal punishment. No exceptions apply as this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about a group defined by their stance toward a protected religious group, with violent suggestions ('go to hell'), meeting the trigger pattern. Applying Rule 003: Similar analysis applies - dehumanizing/derogatory language with group targeting and hostile intent. All three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_627_k0", "example_id": "train_627", "text": "Black people are the most racist people I ever met. I√¢¬Ä¬ôm not even white, and I know this. Most blacks are racists!", "label": 1, "reasoning": "Applying Rule 001: The text makes derogatory generalizations about Black people as a racial group ('Black people are the most racist people I ever met', 'Most blacks are racists!'), which targets a protected group (racial). It reinforces harmful stereotypes about group behavior in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. The text clearly promotes group-based hostility. Applying Rule 002: Same analysis - derogatory generalization about a protected racial group with hostile intent. No exception for individual behavior targeting applies since this targets the entire group. Applying Rule 003: Same analysis - derogatory generalization about a protected racial group with hostile context. No metaphorical or individual targeting exceptions apply. All three rules indicate hate speech due to derogatory group-based language targeting a protected racial group with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_628_k0", "example_id": "train_628", "text": "Gas should be your preferred drink", "label": 0, "reasoning": "Applying Rule 001, Rule 002, and Rule 003: The text 'Gas should be your preferred drink' contains the term 'gas' which could be interpreted as a violent suggestion ('gas yourself') when combined with group targeting. However, the text lacks explicit group targeting - it does not specify any protected group (racial, gender, religious, national, or sexual orientation). The phrase appears to be directed at an unspecified 'you' without establishing group-based hostility or derogatory generalizations about a protected group. Without group targeting and without clear indicators of dehumanizing language toward a protected group, none of the rules trigger. The text could be interpreted as offensive or threatening toward an individual, but the rules specifically require group-based targeting for classification as hate speech. Therefore, based on all three rules, this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_629_k0", "example_id": "train_629", "text": "Now LGBT is okay in Islam. Go to get killed", "label": 1, "reasoning": "Applying Rule 001: The text uses the phrase 'Go to get killed' which suggests violence toward a group (LGBT individuals). It makes a derogatory generalization about LGBT people in relation to Islam, implying they should be killed. This targets a protected group (sexual orientation) with hostile intent. No exceptions apply - it's not reclaimed, clinical, historical, or satirical; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: The text uses violent suggestion ('get killed') in combination with group targeting (LGBT people). It promotes violence toward a protected group. No exceptions apply as it's not criticizing individual behavior. Applying Rule 003: The text contains violent suggestion toward a protected group (LGBT) with hostile context. It suggests elimination of the group. No exceptions apply as it's not metaphorical or individual-targeted. All three rules indicate hate speech due to violent suggestion targeting a protected group with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_630_k0", "example_id": "train_630", "text": "Kill all muslims", "label": 1, "reasoning": "Applying Rule 001: The text 'Kill all muslims' contains violent suggestions ('Kill') directed at a protected religious group ('muslims'), indicating group targeting with hostile intent. It suggests elimination of the group, which matches key indicators (2) from the rule. There are no exceptions that apply - it's not reclaimed, clinical, historical, satirical, metaphorical, or individual-focused. The language clearly promotes violence against a protected religious group. Applying Rule 002: The text uses violent suggestions toward a protected religious group with clear group targeting and hostile intent. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains violent suggestions directed at a protected religious group with group targeting and hostile intent. No exceptions apply as this is not metaphorical or individual-focused. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_631_k0", "example_id": "train_631", "text": "Im bisexual but im not looking to hook up with whatever. And i havent come out yet. Im scared, really scared.", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The speaker identifies as bisexual but expresses personal fear about coming out, which is self-referential and non-hostile. No group targeting or harmful stereotypes are present. Applying Rule 002: No dehumanizing language or group-based hostility is present. The text discusses personal identity and fear without targeting any protected group. Applying Rule 003: The text lacks all trigger patterns - no slurs, elimination suggestions, or reinforcement of harmful stereotypes in hostile context. The mention of bisexuality is self-identifying, not derogatory toward LGBTQ+ groups. All rules indicate this is not hate speech as it contains no group-based derogatory language, dehumanization, or hostile intent toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_633_k0", "example_id": "train_633", "text": "Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.", "label": 1, "reasoning": "Applying Rule 001: The text contains violent suggestions ('kill those bastards') and derogatory language ('bastards') targeting Americans as a national group. The phrase 'crush america' suggests elimination or violence toward a protected group (nationality) with hostile intent. The context is not satirical, reclaimed, or clinical - it's a direct call for violence against Americans. No exceptions apply as this is group-based targeting with violent intent. Applying Rule 002: The text uses derogatory language ('bastards') and violent suggestions ('kill those bastards', 'crush america') targeting Americans as a national group. The context shows hostile intent and suggests elimination/violence toward the group. No exceptions apply as this is not criticism of individual behavior. Applying Rule 003: The text contains dehumanizing/derogatory language ('bastards') and violent suggestions targeting Americans as a national group. The context shows hostile intent with suggestions of violence and elimination. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting. All three rules indicate hate speech due to: (1) derogatory group-based language targeting Americans, (2) violent suggestions ('kill', 'crush'), (3) hostile intent in context, and (4) no applicable exceptions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_634_k0", "example_id": "train_634", "text": "You make me wanna hit the gym. Thicker than a damn snicker dammit!", "label": 0, "reasoning": "Analyzing the text 'You make me wanna hit the gym. Thicker than a damn snicker dammit!' against the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text contains no dehumanizing terms like 'pigs' or 'retarded', no references to racial, gender, religious, national, or sexual orientation groups, and no violent suggestions. 'Thicker than a damn snicker' is a colloquial, non-literal expression about physical appearance, not targeting any protected group. The phrase 'damn snicker' uses mild profanity but is not derogatory toward a group. The context appears to be personal commentary without hostile intent toward a protected group. No exceptions apply as there is no group-based targeting, reclaimed usage, or metaphorical criticism of non-group entities. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_635_k0", "example_id": "train_635", "text": "Very sad for those people. i was a young boy in the 90s when Ceausescu fell in Romania and the inflation skyrocketed.  But here they are on another level and looks like there is no end soon. How can this happen to one of the richest country in the world? Venezuela has the largest resource of oil in the world. When you look at Qatar, UAE, Saudi Arabia they done miracles. It looks like is not enough to have oil, you have to know what to do with it.", "label": 0, "reasoning": "Applying Rule 001: The text discusses economic conditions in Venezuela and Romania, using historical context and comparative analysis with other oil-rich countries. There is no use of dehumanizing terms ('pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The language is analytical and expresses sadness/confusion about economic situations, not hostility toward any racial, gender, religious, national, or sexual orientation group. No group targeting or harmful stereotypes are present. Applying Rule 002: Same analysis - no dehumanizing language, group-based derogatory generalizations, or violent suggestions targeting protected groups. The text focuses on economic policies and national outcomes, not identity-based hostility. Applying Rule 003: Same conclusion - the text uses neutral descriptive language about countries and economic conditions. No metaphorical slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes in hostile context. The exceptions don't apply as there's no reclaimed/satirical context needed - the text simply doesn't contain hate speech elements. All three rules indicate this is not hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_637_k0", "example_id": "train_637", "text": "Even watching it on screen feels intense....imagine what they would be feeling to witness this horror first hand. To just be there takes some courage, let alone even touching the dead.", "label": 0, "reasoning": "Applying Rule 001: The text describes witnessing a traumatic event and acknowledges the courage required to be present at such a scene. It contains no dehumanizing terms (e.g., 'pigs', 'retarded'), no derogatory generalizations about protected groups, and no violent suggestions. The language is observational and empathetic rather than hostile. No group targeting is present. Applying Rule 002: The text lacks dehumanizing language, derogatory generalizations, or violent suggestions toward any group. It does not target any protected group or promote group-based hostility. Applying Rule 003: Similar to Rules 001 and 002, the text contains no indicators of hate speech as defined by the trigger patterns. It is descriptive and reflective, with no metaphorical slurs, suggestions of elimination/inferiority/violence toward groups, or reinforcement of harmful stereotypes. All rules indicate this text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_638_k0", "example_id": "train_638", "text": "Buy a pc game call camp buddies trust me you haven'¬Ä¬ôt seen anything yet", "label": 0, "reasoning": "Applying the rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text 'Buy a pc game call camp buddies trust me you haven't seen anything yet' is a recommendation for a PC game. It contains no dehumanizing language, no derogatory generalizations about any protected group (racial, gender, religious, national, sexual orientation), no violent suggestions, and no group targeting. The text is neutral and promotional in nature, lacking any indicators of hostility, stereotypes, or intent to harm. Therefore, none of the rules apply, and the text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_640_k0", "example_id": "train_640", "text": "STOP. DRINKING. COW. MILK.  Do people realize that for a cow to produce milk it has to get pregnant? and for people to have such milk the calf cant consume any of it? Do they realize that puss and blood is found in milk and that the milk at the grocery store is only 5 to 10% milk and the rest is just powder and water?  Gross.", "label": 0, "reasoning": "Applying Rule 001: The text criticizes the consumption of cow milk by describing the dairy production process in negative terms ('puss and blood', 'Gross'), but it does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions. The target is people who drink milk, which is not a protected group based on race, gender, religion, national origin, or sexual orientation. The language is directed at a behavior (drinking milk) rather than group identity, and lacks indicators like slurs, elimination rhetoric, or reinforcement of harmful stereotypes in a hostile context. Applying Rule 002: Similar analysis applies—no dehumanizing language or group targeting toward protected groups is present. The criticism focuses on individual consumption choices without promoting hostility toward a protected group. Applying Rule 003: The text uses metaphorical language ('puss and blood') to criticize dairy products, but this targets a non-group-based entity (the dairy industry or milk consumption) rather than a protected group. No exceptions for reclaimed or satirical contexts are needed, as the text appears to be a straightforward critique of dairy practices. Overall, the text does not meet the trigger patterns for hate speech under any rule, as it lacks group-based targeting of protected groups with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_641_k0", "example_id": "train_641", "text": "This video was super helpful and just very nice ! If you're reading this, please stick with us, alright ? I spent eight years hating myself, to the point of almost killing myself. Key word is almost - because i'm still here, and i'm so glad i stuck around. So take care of yourselves, please, because it's going to get better, and you'll want to be there to see it. All the love to you, Jack and Kati, and everyone out there. &lt;3", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It discusses personal mental health struggles in a supportive, non-hostile context. No group targeting is present. Applying Rule 002: The text lacks dehumanizing language, group-based derogatory generalizations, or violent suggestions toward any protected group. It focuses on individual experience and encouragement. Applying Rule 003: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. It uses personal narrative to offer hope and support, not to target any group. All rules indicate this is non-hateful content as it lacks the required elements of group-based hostility, dehumanization, or violence.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_642_k0", "example_id": "train_642", "text": "why does that african american monkey hold gun like that?", "label": 1, "reasoning": "Applying Rule 001: The text uses 'monkey' as a dehumanizing term targeting an 'African American' individual, which constitutes derogatory group-based language with hostile intent. The term reinforces harmful racial stereotypes by comparing a person of African descent to an animal, indicating inferiority. There is no indication this is reclaimed, clinical, historical, or satirical context critiquing hate speech. The targeting is explicitly group-based ('African American'), not metaphorical criticism of non-group entities or individual behavior without group reference. Applying Rule 002: The text uses dehumanizing language ('monkey') targeting a protected racial group ('African American'), suggesting inferiority through animal comparison. This is not criticism of individual behavior but group-based derogation. Applying Rule 003: The text contains dehumanizing term ('monkey') targeting a protected racial group with hostile intent, reinforcing harmful stereotypes. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting without group identity. All three rules indicate hate speech due to dehumanizing group-based language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_644_k0", "example_id": "train_644", "text": "we take everyone, sudanese niggers, egyptian shitskins, palirats, syrian and iraqi scums, they're all dogs that behave like niggers, they cost too much, especially syrians, there is way too many of them here, they are arrogant ungrateful backstabbing apes.", "label": 1, "reasoning": "Applying Rule 001: The text contains multiple dehumanizing terms ('niggers', 'shitskins', 'scums', 'dogs', 'apes') targeting specific national/ethnic groups (Sudanese, Egyptian, Palestinian, Syrian, Iraqi). This constitutes derogatory generalizations about protected groups with hostile intent. The language suggests inferiority ('behave like niggers', 'arrogant ungrateful backstabbing apes'), reinforces harmful stereotypes, and includes economic complaints ('cost too much', 'way too many of them here') that contribute to group-based hostility. None of the exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets groups collectively rather than specific individuals. Applying Rule 002: The text clearly uses dehumanizing terms with group targeting and hostile intent, promoting generalized hostility toward multiple protected national/ethnic groups. The exceptions don't apply as this isn't criticism of individual behavior. Applying Rule 003: The text meets all trigger patterns: non-literal slurs, suggestion of inferiority, and reinforcement of harmful stereotypes in hostile context targeting protected groups. No applicable exceptions exist. All three rules indicate hate speech classification.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_645_k0", "example_id": "train_645", "text": "men and women are not equal.  irrational contrary belief and policy only result in mounting failure.", "label": 0, "reasoning": "Applying Rule 001: The text states 'men and women are not equal' which could be interpreted as a generalization about gender groups. However, it lacks dehumanizing terms (e.g., 'pigs', 'retarded'), violent suggestions, or reinforcement of harmful stereotypes in a hostile context. The language appears to express a philosophical or ideological disagreement about equality rather than promoting elimination, inferiority, or violence toward a protected group. The criticism targets 'irrational contrary belief and policy' rather than the groups themselves. Applying Rule 002: Similar analysis - no dehumanizing terms, violent suggestions, or hostile intent toward groups. The text discusses equality concepts without derogatory generalizations about protected groups. Applying Rule 003: The statement about inequality could be seen as targeting gender groups, but it lacks the key indicators: (1) no non-literal or metaphorical slurs, (2) no suggestion of elimination, inferiority, or violence toward a group, and (3) no reinforcement of harmful stereotypes in a hostile context. The text appears to critique policies and beliefs rather than promote group-based hostility. All rules indicate this does not meet the threshold for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_646_k0", "example_id": "train_646", "text": "I don't have any facts, I don't have any Statistics, I am a Human Being The fuck is that even mean?", "label": 0, "reasoning": "Applying Rule 1: The text contains offensive language ('The fuck') but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The phrase 'I am a Human Being' appears to be a statement of identity rather than group-based targeting. The offensive language is directed at an abstract concept ('what that even mean') rather than a protected group. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes toward groups are present. Applying Rule 2: Similar analysis - no dehumanizing terms targeting protected groups, no derogatory generalizations, no violent suggestions toward groups. The language criticizes an abstract concept rather than group identity. Applying Rule 3: Same conclusion - offensive language exists but lacks group targeting, dehumanization of protected groups, or hostile intent toward specific identities. All rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_647_k0", "example_id": "train_647", "text": "These women aren't autistic, they are smart, autistic people are retards, they make weird noises, they flap their hands. These people are not autistic.", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'retards' as a derogatory generalization about autistic people as a protected group (people with disabilities). It reinforces harmful stereotypes ('they make weird noises, they flap their hands') in a hostile context that suggests inferiority. This is not reclaimed, clinical, historical, or satirical context. The language targets the group identity of autistic people, not individual behavior. Applying Rule 002: The text uses dehumanizing language ('retards') with group targeting toward autistic people, suggesting inferiority and reinforcing stereotypes. This is not criticism of individual behavior but a generalization about the group. Applying Rule 003: The text uses derogatory language ('retards') targeting autistic people as a group, suggesting inferiority and reinforcing harmful stereotypes in a hostile manner. This meets the trigger pattern for all three rules without falling under any exceptions.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_648_k0", "example_id": "train_648", "text": "I propose suicide for evert politician", "label": 0, "reasoning": "Applying Rule 001: The text uses the phrase 'I propose suicide for evert politician' which contains a violent suggestion ('suicide') targeting politicians. However, politicians are not a protected group (racial, gender, religious, national, sexual orientation) but rather individuals in a professional role. The language targets individuals in a role without reference to group identity, falling under the exception for metaphorical use targeting non-group-based entities or individuals without group identity reference. No dehumanizing terms, derogatory generalizations about protected groups, or reinforcement of harmful stereotypes in a hostile context are present. Applying Rule 002: Similar analysis - the comment suggests violence but targets politicians as individuals in a role, not a protected group. No dehumanizing language or group-based hostility. Applying Rule 003: Same conclusion - violent suggestion but directed at politicians as role-holders, not a protected group identity, falling under the exception for targeting individuals without group identity reference.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_649_k0", "example_id": "train_649", "text": "Aren’t you ashamed about your body colour?", "label": 1, "reasoning": "Analyzing the text 'Aren't you ashamed about your body colour?' using all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all define hate speech as involving dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. This text references 'body colour,' which implies racial or ethnic identity as a protected group. The phrase 'ashamed about your body colour' suggests that having a particular skin color is something to be ashamed of, which reinforces harmful stereotypes about racial inferiority. This constitutes a derogatory generalization targeting a protected group (racial identity) with hostile intent by implying shame or inferiority. None of the exceptions apply: this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; it's not self-referential; and it directly targets group identity rather than individual behavior. Therefore, all three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_650_k0", "example_id": "train_650", "text": "Mentally disabled people are fucking scary. Their disfigurements are very unnerving and strange and the fact that they have the mental capacity of a 5 year old makes them all the more threatening as you never know what they might do.", "label": 1, "reasoning": "Applying Rule 1: The text uses derogatory generalizations about mentally disabled people as a protected group (disability-based), describing them as 'fucking scary', 'unnerving and strange', and having 'the mental capacity of a 5 year old' which makes them 'threatening'. This reinforces harmful stereotypes about people with disabilities being dangerous or unpredictable. The language suggests inferiority and promotes fear toward the group, with hostile intent. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's a direct generalization about the group. Applying Rule 2: The text uses derogatory generalizations about a protected group (people with mental disabilities) with hostile intent, describing them as threatening and scary. This promotes group-based hostility. No exceptions apply as this targets the protected group itself, not individual behavior. Applying Rule 3: The text uses derogatory language about mentally disabled people as a group, suggesting they are threatening and inferior. This fits the trigger pattern of derogatory generalizations with hostile intent. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_652_k0", "example_id": "train_652", "text": "I thought that a big reason why it had to be africans, is their skin. It's an obvious marker to tell if someone is a slave. And even if they run, they're still black.", "label": 1, "reasoning": "Applying Rule 001: The text uses 'africans' as a group reference and makes generalizations about skin color as 'an obvious marker to tell if someone is a slave.' This reinforces harmful stereotypes about Africans/black people as slaves, suggesting inferiority and dehumanization through historical oppression. The statement 'even if they run, they're still black' implies permanent, group-based identification with slavery. There is no indication of reclaimed, clinical, historical, or satirical context critiquing hate speech; instead, it presents a hostile generalization. No exceptions apply as it targets a protected racial/national group with derogatory implications. Applying Rule 002: The text uses dehumanizing language by linking Africans/black people to slavery based on skin color, suggesting group-based inferiority. It lacks exceptions for reclaimed contexts or individual targeting. Applying Rule 003: Similar analysis applies—group targeting with dehumanizing stereotypes in a hostile context, no metaphorical use or individual focus. All rules indicate hate speech due to derogatory generalizations about a protected group (racial/national) with implied inferiority and historical dehumanization.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_653_k0", "example_id": "train_653", "text": "Generally speaking, most women are lazy and worthless not all, but most.", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory generalizations ('lazy and worthless') about women, which is a protected gender group. It suggests inferiority ('worthless') and reinforces harmful stereotypes ('lazy') in a hostile context. There is no indication of reclaimed, clinical, historical, or satirical context, nor is it targeting specific individuals without group reference. The phrase 'most women' explicitly targets the group. Applying Rule 002: The text uses derogatory generalizations about a protected group (gender) with hostile intent, suggesting inferiority. It does not target individual behavior. Applying Rule 003: The text uses derogatory generalizations about a protected group with hostile intent, suggesting inferiority and reinforcing stereotypes. It is not metaphorical criticism of non-group entities. All rules indicate hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_654_k0", "example_id": "train_654", "text": "I have a schizophrenia and I fight alone", "label": 0, "reasoning": "Applying Rule 001: The text 'I have a schizophrenia and I fight alone' contains the term 'schizophrenia', which is a clinical term for a mental health condition. However, this is used in a self-referential context by someone describing their own experience ('I have'), not as a derogatory generalization about people with schizophrenia as a protected group. There is no dehumanizing language, violent suggestions, or hostile intent toward any group. The text expresses personal struggle without targeting others. This falls under the exception for clinical/self-referential contexts. Applying Rule 002: Similar analysis - the term is used clinically and self-referentially, not with hostile intent toward a protected group. No derogatory generalizations or suggestions of elimination/inferiority. Applying Rule 003: Same conclusion - clinical term used in self-reference without group targeting or hostile context. All rules indicate this should be classified as non-hateful.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_655_k0", "example_id": "train_655", "text": "their dark coloured race doesn't mean shit", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('doesn't mean shit') targeting a protected group based on race ('dark coloured race'). This constitutes a derogatory generalization about a racial group with hostile intent, as it dismisses the significance of their racial identity in a demeaning manner. The language reinforces harmful stereotypes by suggesting racial characteristics are meaningless or worthless. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting specific individuals without group reference. Applying Rule 002: The text uses derogatory language targeting a racial group, meeting the trigger pattern for dehumanizing or derogatory group-based language with hostile intent. Applying Rule 003: The text contains derogatory generalizations about a protected racial group with hostile context, meeting the trigger pattern. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_656_k0", "example_id": "train_656", "text": "As a black person, I think that rappers should stop putting the n-word in the song. Plus, you should be proud of being White. I am proud of being black, so..", "label": 0, "reasoning": "Applying Rule 001: The text contains expressions of pride in racial identity ('proud of being White', 'proud of being black') but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The mention of the n-word is in the context of a black person criticizing its use in music, which could be considered reclaimed or critical commentary rather than promoting hate speech. There is no group targeting with hostile intent, no suggestion of elimination or inferiority, and no reinforcement of harmful stereotypes. The text expresses personal opinions about racial pride without hostility toward any group. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting protected groups. The criticism of rappers using the n-word is directed at artistic choices rather than group-based hostility. Applying Rule 003: Same conclusion - the text lacks the trigger patterns of dehumanizing terms, derogatory generalizations with group targeting, or violent suggestions in a hostile context. The expressions of racial pride are self-referential and non-hostile. All rules indicate this does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_657_k0", "example_id": "train_657", "text": "I'm  heterosexual and African by birth, by breed and by character... and a very traditional man, Xhosa to be precise. But i still believe in human rights... we are all equal, whatever  religion, ethnicity, demography, tribe or language... we are all equal. And one day people will be free enough to love and date whoever they wanna without prejudice and judgment. 2019‚Ä¶Viva human rights viva", "label": 0, "reasoning": "Applying Rule 001: The text expresses positive views about human rights, equality, and freedom from prejudice. It does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The author identifies as heterosexual and Xhosa but uses this self-identification to advocate for universal equality. This is not group-based targeting with hostile intent. Applying Rule 002: The text lacks dehumanizing language or derogatory generalizations about protected groups. It promotes inclusivity rather than hostility. Applying Rule 003: The text does not use slurs, suggest elimination or violence toward groups, or reinforce harmful stereotypes. It advocates for human rights and equality across all identities. No exceptions from any rules apply as the text is clearly non-hostile and promotes anti-prejudice values.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_658_k0", "example_id": "train_658", "text": "Did you use the ‚ÄúTan‚Äù or ‚ÄúDark‚Äù filter?", "label": 0, "reasoning": "Applying Rule 001: The text 'Did you use the \"Tan\" or \"Dark\" filter?' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It asks a neutral question about photo filters without targeting any group or individual with hostile intent. No exceptions apply as there is no offensive language to evaluate. Applying Rule 002: The text lacks dehumanizing language, group targeting, or suggestions of elimination/inferiority/violence toward any protected group. It is a straightforward inquiry about technology use. Applying Rule 003: The text contains no slurs, stereotypes, or hostile context targeting protected groups. The terms 'Tan' and 'Dark' refer to photo filters, not racial or ethnic characteristics, and are used in a neutral, non-derogatory manner. All rules indicate this is non-hateful speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_659_k0", "example_id": "train_659", "text": "Teaching my kids transgenders are anything but mentally ill will get you set on fire.", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'mentally ill' in reference to transgender people as a group, which constitutes a derogatory generalization about a protected group (sexual orientation/gender identity). The phrase 'will get you set on fire' suggests violent action against those who teach acceptance. This combines group targeting (transgender people) with violent suggestion. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it's not targeting individual behavior without group reference. Applying Rule 002: The text uses derogatory language ('mentally ill') about transgender people as a group with implied violent consequences ('set on fire'), meeting the trigger pattern of dehumanizing/derogatory group-based language with hostile intent. No exceptions apply as this isn't targeting individual behavior. Applying Rule 003: The text contains derogatory generalization about a protected group (transgender people) combined with violent suggestion, meeting all key indicators. No exceptions apply as this isn't metaphorical criticism or individual targeting. All three rules indicate hate speech due to group-based derogatory language combined with violent suggestion in a hostile context.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_660_k0", "example_id": "train_660", "text": "If I had Down syndrome I would kill myself", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'Down syndrome' which refers to a specific genetic condition/disability group. The statement 'If I had Down syndrome I would kill myself' suggests that having this condition is so undesirable that suicide would be preferable. This implies inferiority of people with Down syndrome as a group and promotes the harmful stereotype that their lives are not worth living. The language suggests elimination (suicide) toward a protected group (people with disabilities). There is no indication this is reclaimed, clinical, historical, or satirical context - it appears to be a direct statement about the group. The text targets the entire group of people with Down syndrome, not an individual. Applying Rule 002: The text uses derogatory implications about a protected group (people with disabilities) and suggests elimination (suicide). It reinforces harmful stereotypes about people with Down syndrome. The criticism is not directed at individual behavior but makes a generalization about the entire group. Applying Rule 003: The text uses language that suggests elimination (suicide) toward a protected group (people with disabilities). It implies inferiority of people with Down syndrome as a group. The target is the group identity, not an individual without reference to group identity. All three rules indicate this qualifies as hate speech due to derogatory group-based language with hostile intent that suggests elimination and reinforces harmful stereotypes about a protected group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_661_k0", "example_id": "train_661", "text": "The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.", "label": 1, "reasoning": "Applying Rule 001: The text contains multiple dehumanizing terms ('nigger', 'nigger faggot') targeting racial and sexual orientation groups. It makes derogatory generalizations about 'niggers' as a group and 'self-hating whites' in a hostile context, suggesting inferiority and depravity. The language reinforces harmful stereotypes about racial groups and LGBTQ+ individuals. None of the exceptions apply - this is not reclaimed usage, clinical discussion, satire, or individual targeting. The terms are used literally with group-based hostility. Applying Rule 002: The text uses dehumanizing terms ('nigger', 'nigger faggot') with clear group targeting (racial and sexual orientation groups) and hostile intent. It suggests inferiority and depravity toward these groups. The exception for individual behavior targeting doesn't apply since this targets entire protected groups. Applying Rule 003: The text contains dehumanizing slurs targeting protected groups (racial and sexual orientation) with hostile intent, suggesting elimination through terms like 'repulsive' and 'depravity.' It's not metaphorical criticism of non-group entities nor individual targeting without group reference. All three rules trigger due to dehumanizing language, group targeting, hostile context, and reinforcement of harmful stereotypes.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_662_k0", "example_id": "train_662", "text": "Why are niggers superior athletically to all other races?", "label": 1, "reasoning": "Applying Rule 001: The text uses the racial slur 'niggers' which is a dehumanizing term targeting a protected racial group (Black people). It makes a generalization about athletic superiority that reinforces harmful stereotypes about racial groups. The context appears hostile as it frames the question in a way that suggests racial hierarchy. None of the exceptions apply: this is not reclaimed usage (not self-referential), not clinical/historical discussion, not satirical critique of hate speech, and not metaphorical criticism of non-group entities. The targeting is clearly group-based rather than individual. Applying Rule 002: The text uses dehumanizing language ('niggers') with group targeting (racial group) and reinforces stereotypes about athletic ability, which qualifies as derogatory generalization. The exceptions don't apply as this isn't targeting individual behavior or reclaimed usage. Applying Rule 003: The text contains dehumanizing language targeting a protected racial group with implied hierarchical comparison, meeting the trigger pattern. The exceptions don't apply as this isn't metaphorical criticism of non-group entities or individual targeting. All three rules indicate this should be classified as hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_663_k0", "example_id": "train_663", "text": "An ugly man in a wig and dress, is still just an ugly man in a wig and dress... NOT A WOMAN!!!", "label": 1, "reasoning": "Applying Rule 001: The text targets transgender individuals by denying their gender identity ('NOT A WOMAN!!!') and uses derogatory language ('ugly man'). This constitutes a derogatory generalization about a protected group (gender identity/transgender people) with hostile intent, as it reinforces harmful stereotypes about transgender women being 'men in disguise.' There is no indication of reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it. The language is not metaphorical criticism of non-group entities nor targeting an individual without group reference. Applying Rule 002: The text uses derogatory language ('ugly man') and makes a generalization denying transgender identity, which targets a protected group (gender identity) with hostile intent. It suggests inferiority of transgender women by asserting they are 'just' men in disguise. There is no context of criticizing individual behavior without group targeting. Applying Rule 003: The text uses derogatory language and makes a generalization about transgender individuals, targeting a protected group with hostile intent by denying their gender identity. It reinforces harmful stereotypes in a hostile context. No exceptions apply for reclaimed, clinical, historical, satirical contexts, metaphorical use, or individual targeting. Therefore, all three rules indicate this is hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_664_k0", "example_id": "train_664", "text": "I fear any future hate crime victim may well be labeled as just \"pulling a smollett\".", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'pulling a smollett' which references Jussie Smollett, an individual involved in a controversial hate crime case. This is metaphorical language criticizing perceived individual behavior (faking hate crimes) rather than targeting a protected group. No dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions are present. The comment targets specific individuals who might fake hate crimes, not a broader identity-based community. According to Rule 001 exceptions: 'Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions... without linking them to a broader protected group.' This matches the text's focus on individual behavior. Applying Rule 002: Similar analysis applies - the criticism is directed at individual behavior (perceived faking of hate crimes) without targeting a protected group or promoting generalized hostility. Rule 002 exceptions state: 'Do not apply if the criticism is directed at individual behavior... without targeting a protected group.' Applying Rule 003: The language is metaphorical criticism of individual behavior, not group targeting. Rule 003 exceptions include: 'Do not apply if the language is used metaphorically to criticize non-group-based entities... or if the target is an individual without reference to group identity.' All three rules indicate this should be classified as non-hate speech (0).", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_666_k3", "example_id": "train_666", "text": "They are laughing and their countries are poor evil murderes and all corrupted good job.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory generalizations ('poor evil murderes and all corrupted') targeting unspecified groups identified by 'their countries'. This suggests group-based targeting of nationalities, which are protected groups. The language includes terms implying moral inferiority ('evil'), criminality ('murderes'), and systemic corruption ('all corrupted'), which reinforce harmful stereotypes in a hostile context. There's no indication of reclaimed, clinical, historical, or satirical context, nor is it metaphorical criticism of non-group entities or targeting specific individuals without group reference. Applying Rule 002: Similar analysis applies - the comment uses derogatory generalizations about national groups with hostile intent, lacking exceptions for individual behavior targeting or reclaimed contexts. Applying Rule 003: The pattern matches dehumanizing/derogatory group-based language with hostile intent, targeting protected groups (nationalities) through harmful stereotypes, without qualifying exceptions. All three rules indicate hate speech due to group-targeted derogatory generalizations with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_667_k0", "example_id": "train_667", "text": "The Resistance avenge women and children killed by US and Allies !!!", "label": 0, "reasoning": "Applying Rule 001: The text mentions 'women and children' as victims and calls for 'The Resistance' to 'avenge' them against 'US and Allies'. This does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about protected groups, or violent suggestions with group targeting. The language criticizes entities (US and Allies) rather than targeting protected groups based on race, gender, religion, national origin, or sexual orientation. No harmful stereotypes or suggestions of elimination, inferiority, or violence toward a protected group are present. The context appears political/military rather than hate speech against protected identities. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text targets nation-states/alliances (US and Allies) rather than protected groups. Applying Rule 003: Same conclusion - the text lacks the trigger patterns specified in all three rules. The call for 'avenge' is directed at political/military entities, not protected groups, and doesn't use the prohibited language patterns.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_668_k0", "example_id": "train_668", "text": "They should have beat his ass. He deserves it.", "label": 0, "reasoning": "Applying Rule 001: The text contains violent suggestion ('beat his ass') but targets an individual ('his') without reference to any protected group identity. No dehumanizing terms, derogatory generalizations about protected groups, or group targeting are present. The criticism appears directed at specific individual behavior ('He deserves it') rather than invoking group-based hostility. According to Rule 001 exceptions, this qualifies as 'target is an individual without reference to group identity' and 'offensive language used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.' Applying Rule 002: Similar analysis applies - the comment targets individual behavior without targeting a protected group or promoting generalized hostility toward identity-based communities. Applying Rule 003: The language criticizes an individual without group reference, falling under the exception for 'target is an individual without reference to group identity.' All three rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_669_k0", "example_id": "train_669", "text": "I think brown, black or dark-skinned people do choose to be slaves even now in 2019. He knows it is not superior to white dudes", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory generalizations about racial groups ('brown, black or dark-skinned people') and suggests inferiority ('choose to be slaves', 'not superior to white dudes'), which meets the trigger pattern of dehumanizing/derogatory group-based language with hostile intent. It targets protected racial groups, reinforces harmful stereotypes about slavery and inferiority, and lacks any contextual exceptions (not reclaimed, clinical, historical, or satirical; not metaphorical criticism of non-group entities; not targeting specific individuals without group reference). Applying Rule 002: The text clearly targets racial groups with derogatory generalizations and suggestions of inferiority, meeting the trigger pattern without exceptions (not reclaimed/satirical context, not targeting individual behavior). Applying Rule 003: The text uses derogatory group-based language targeting racial groups with suggestions of inferiority, meeting the trigger pattern without exceptions (not reclaimed/satirical, not metaphorical for non-group entities, not individual targeting). All three rules indicate hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_671_k0", "example_id": "train_671", "text": "What episode number was this?", "label": 0, "reasoning": "Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text 'What episode number was this?' contains no such elements. It is a neutral question about episode numbering with no language targeting any group, no derogatory terms, no violent suggestions, and no hostile intent. Therefore, none of the rules apply, and the text does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_673_k0", "example_id": "train_673", "text": "Bulgars are Indo Europeans, Turks are not, you ignorant pakisven. Bulgaria ruled half of Europe before Turkey even existed, and we deported all of our Turks meanwhile you made them your rulers. Sven is a fake german country ruled by arabs.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory group-based language ('ignorant pakisven') targeting a protected national group (implied Pakistani/Swedish hybrid). It reinforces harmful stereotypes about 'Sven' being a 'fake german country ruled by arabs' with clear hostile intent. The language is not reclaimed, clinical, historical, or satirical. It targets groups based on national/ethnic identity rather than individual behavior. Applying Rule 002: The text uses derogatory generalizations about multiple protected groups (Turks, 'pakisven', 'Sven', arabs) with suggestions of inferiority ('fake german country') and historical superiority claims. The context is hostile with nationalistic overtones. Applying Rule 003: The text contains dehumanizing implications through terms like 'ignorant pakisven' and group-based targeting of Turks, 'pakisven', and arabs. It suggests elimination/deportation ('we deported all of our Turks') and reinforces stereotypes about rulership and authenticity. No exceptions apply as this is not metaphorical criticism of non-group entities, nor is it self-referential or academic. The cumulative effect shows clear group-based hostility toward multiple protected national/ethnic groups.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_674_k0", "example_id": "train_674", "text": "Fuck Sweden. Let it die like the degenerates they are!", "label": 1, "reasoning": "Applying Rule 001: The text uses derogatory language ('degenerates') targeting Sweden as a national group, with hostile intent ('Let it die'). This constitutes group-based derogatory language with suggestions of elimination toward a protected national group. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text uses derogatory generalizations about a national group (Sweden/Swedish people) with violent suggestions ('Let it die'), meeting the trigger pattern. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text uses derogatory language targeting a national group with suggestions of elimination, meeting all key indicators. No exceptions apply as it's not metaphorical criticism of non-group entities or individual targeting. All three rules indicate hate speech due to group-based derogatory language with hostile intent toward a protected national group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_675_k0", "example_id": "train_675", "text": "T-Rex mated with a donkey", "label": 0, "reasoning": "Applying Rule 001: The text 'T-Rex mated with a donkey' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any racial, gender, religious, national, or sexual orientation group. The statement appears metaphorical or absurd, possibly referencing evolutionary biology or making a nonsensical claim, but lacks any group-based hostility. No protected group is identified or targeted. Applying Rule 002: No dehumanizing language or group targeting is present. The text does not suggest elimination, inferiority, or violence toward any group. Applying Rule 003: The text contains no slurs, stereotypes, or hostile context directed at protected groups. The metaphorical reference (if any) does not criticize group-based entities. All rules indicate this does not meet the criteria for hate speech as defined in the rulebook.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_676_k0", "example_id": "train_676", "text": "This documentary is on point. This helped me through class ty boy", "label": 0, "reasoning": "Applying Rule 001: The text contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It expresses appreciation for a documentary and gratitude toward an unspecified 'boy' (likely colloquial for 'person'). There is no group targeting, hostile intent, or reinforcement of harmful stereotypes. The language is positive and non-hostile. Applying Rule 002: No dehumanizing language, group-based targeting, or hostile intent present. The comment is about personal experience with educational content. Applying Rule 003: No indicators of hate speech - no slurs, elimination suggestions, or group-based hostility. The context is clearly non-hateful appreciation. All rules indicate this text does not meet any criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_677_k0", "example_id": "train_677", "text": "The lady on sitting on the left, with the yellow jacket, is the epitome of a \"smart retard\".", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'retard' which is a dehumanizing term. However, it targets a specific individual ('the lady on sitting on the left, with the yellow jacket') rather than making derogatory generalizations about a protected group. The term is used metaphorically to criticize an individual's intelligence ('smart retard' appears to be an oxymoron criticizing perceived lack of intelligence), not to promote group-based inferiority, violence, or dehumanization of people with disabilities as a protected group. The exception for 'target is an individual without reference to group identity' applies. Applying Rule 002: The text uses dehumanizing language ('retard') but targets individual behavior (perceived lack of intelligence) without targeting a protected group or promoting generalized hostility toward people with disabilities. The exception for criticism directed at individual behavior applies. Applying Rule 003: Similar to Rule 001, the term 'retard' is used but targets an individual ('the lady') without reference to group identity. The exception for 'target is an individual without reference to group identity' applies. All three rules indicate this should be classified as non-hateful (0) because while offensive, it targets an individual's perceived characteristics rather than a protected group with hostile intent.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_678_k0", "example_id": "train_678", "text": "You are a brave man.........for letting them keep the comments enabled", "label": 0, "reasoning": "Applying Rule 001: The text 'You are a brave man.........for letting them keep the comments enabled' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any racial, gender, religious, national, or sexual orientation group. The phrase 'brave man' appears to be sarcastic but targets an individual's decision about comment moderation, not group identity. No indicators of non-literal slurs, elimination suggestions, or harmful stereotypes are present. The language is metaphorical criticism of an individual's choice without group-based hostility. Applying Rule 002: No dehumanizing language or group targeting is present. The comment addresses individual behavior (enabling comments) without targeting protected groups or promoting generalized hostility. Applying Rule 003: Similar analysis - no dehumanizing terms, group targeting, or violent suggestions. The sarcastic tone criticizes an individual action, not a protected group. All rules indicate this does not meet hate speech criteria due to lack of group-based targeting and absence of dehumanizing/hostile language toward protected groups.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_679_k0", "example_id": "train_679", "text": "Congratulations. You figured out you were a moron and decided not to be a moron anymore. You're a freakin hero.", "label": 0, "reasoning": "Applying Rule 001: The text uses the term 'moron', which could be considered derogatory language. However, examining the context: (1) The term is used in a self-referential or conversational context ('you figured out you were a moron'), not targeting a protected group. (2) There is no group targeting - the text addresses an individual without reference to race, gender, religion, nationality, sexual orientation, or other protected group identity. (3) The overall tone appears conversational and potentially self-deprecating rather than hostile. (4) The language does not suggest elimination, inferiority, or violence toward any group. (5) No harmful stereotypes about protected groups are reinforced. This falls under the exception for 'language used metaphorically to criticize non-group-based entities' or when 'the target is an individual without reference to group identity'. Applying Rule 002: Similar analysis applies - while 'moron' could be considered offensive, it targets individual behavior/realization without targeting a protected group or promoting generalized hostility. Applying Rule 003: The same reasoning applies - the term is used in a non-group-based context targeting an individual's realization, not a protected group. All three rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_681_k0", "example_id": "train_681", "text": "this is probably the first time i’ve seen someone who looks like a child and pedophile at the same time", "label": 0, "reasoning": "Analyzing the text 'this is probably the first time i’ve seen someone who looks like a child and pedophile at the same time' against the rulebook: 1. The text targets an individual ('someone') rather than a protected group. 2. It uses descriptive language about appearance ('looks like') without dehumanizing terms like 'pigs' or 'retarded'. 3. No violent suggestions, elimination rhetoric, or harmful stereotypes about protected groups are present. 4. The reference to 'pedophile' could be offensive but targets individual characteristics, not a protected group (pedophilia is not a protected characteristic like race, gender, religion, etc.). 5. All three rules (001, 002, 003) require group-based targeting with hostile intent, which is absent here. 6. Rule exceptions apply: this is non-generalizing criticism of an individual without invoking group-based hostility. Therefore, no rule triggers a hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_682_k0", "example_id": "train_682", "text": "Don't hit Women. Just fuck them and make them pregnant.", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language about women ('fuck them and make them pregnant') that objectifies and reduces women to sexual/reproductive functions. This constitutes derogatory generalizations about a protected group (gender) with hostile intent, as it promotes harmful stereotypes about women's roles and lacks consent context. No exceptions apply - it's not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. It targets women as a group rather than specific individuals. Applying Rule 002: The text uses derogatory language targeting a protected group (women) with objectifying content that reinforces harmful gender stereotypes. No exceptions apply as it's not criticizing individual behavior. Applying Rule 003: The text contains derogatory group-based language targeting women with objectifying content that suggests inferior treatment. No exceptions apply for reclaimed use or metaphorical criticism. All three rules indicate hate speech due to derogatory group targeting with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_684_k0", "example_id": "train_684", "text": "I was clinically depressed for a while and this blew my mind. Due to me having stress I don't say 'oh man I'm getting anxiety' or 'ugh I'm so depressed' because all that does is brings attention I don't want.  The fact that people make these illnesses a fashion merch makes me feel like everyone is looking in my or other people's directions. Memes are relatable,funny, and relieving. When he said 'Do people who post these memes have a mental illness or are they just doing it for ..' it made me wonder alot   Now Ik what people are capable of nowadays", "label": 0, "reasoning": "Applying Rule 001: The text discusses mental illness (depression, anxiety) but does not use dehumanizing terms like 'retarded' or 'pigs', nor does it contain derogatory generalizations about people with mental illnesses as a protected group. The speaker shares personal experience with clinical depression and expresses frustration about people who might trivialize mental illness through memes or fashion. The criticism targets individual behavior ('people make these illnesses a fashion merch', 'people who post these memes') rather than promoting group-based hostility, violence, or dehumanization. No suggestion of elimination, inferiority, or violent intent toward people with mental illnesses is present. Applying Rule 002: Similar analysis applies - no dehumanizing language or group targeting with hostile intent. The text focuses on perceived individual behavior (attention-seeking or trivialization) without targeting the protected group of people with mental health conditions. Applying Rule 003: Again, no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The context is personal reflection and criticism of societal trends, not hate speech against a group. All rules indicate this does not meet the criteria for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_685_k0", "example_id": "train_685", "text": "I’m searching for a hitman right now to kill this whore and every other like her. H A T E  W O M E N", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('whore') targeting women as a protected gender group, with violent suggestions ('kill this whore and every other like her') and explicit group-based hostility ('H A T E  W O M E N'). This meets the trigger pattern of dehumanizing terms, violent suggestions toward a group, and reinforcement of harmful stereotypes in a hostile context. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. The targeting is explicitly group-based ('every other like her', 'W O M E N'), not individual behavior. Applying Rule 002: The text uses derogatory generalizations about a protected group (women) with violent suggestions and hostile intent. No exceptions apply as this directly targets a protected group with dehumanizing language and promotion of violence. Applying Rule 003: The text contains dehumanizing terms ('whore'), violent suggestions toward a group, and explicit group targeting. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting without group reference. All three rules indicate hate speech due to: (1) derogatory group-based language, (2) violent suggestions toward a protected group, (3) explicit hostile intent against women as a group.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_686_k0", "example_id": "train_686", "text": "incoming racist people", "label": 0, "reasoning": "Applying Rule 001: The text 'incoming racist people' does not contain dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. It appears to be a descriptive phrase referring to people who hold racist views, without using slurs or suggesting elimination, inferiority, or violence toward any group. The phrase does not reinforce harmful stereotypes in a hostile context. Applying Rule 002: Similar analysis - no dehumanizing language, derogatory generalizations, or violent suggestions targeting a protected group. The phrase describes individuals based on their behavior (being racist) rather than targeting a protected identity group. Applying Rule 003: Same conclusion - the text lacks the trigger patterns specified in all three rules. It does not use metaphorical slurs, suggest group elimination, or promote harmful stereotypes against protected groups. The phrase 'racist people' criticizes individuals for their beliefs/behavior without targeting a protected group identity.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_687_k0", "example_id": "train_687", "text": "white people are shit human beings", "label": 1, "reasoning": "Applying Rule 001: The text 'white people are shit human beings' contains derogatory language ('shit human beings') targeting a group based on race ('white people'). This constitutes a derogatory generalization about a protected group (racial group) with hostile intent, as it suggests inferiority of the entire group. No exceptions apply - it's not reclaimed, clinical, historical, or satirical context; it's not metaphorical criticism of non-group entities; and it targets the group collectively rather than specific individuals. Applying Rule 002: The text uses derogatory language targeting a racial group, suggesting group-based inferiority. No exceptions apply as it's not targeting individual behavior. Applying Rule 003: The text contains derogatory generalizations about a racial group with hostile intent. No exceptions apply as it's not metaphorical or individual-targeted. All three rules indicate this meets the criteria for hate speech due to group-based derogatory language with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_688_k0", "example_id": "train_688", "text": "There are so many errors XD", "label": 0, "reasoning": "Applying Rule 001: The text 'There are so many errors XD' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It does not target any group based on race, gender, religion, nationality, or sexual orientation. The term 'errors' refers to mistakes or problems in a general sense, not to any protected group. The 'XD' emoticon suggests a lighthearted or joking tone. No indicators of group targeting, elimination, inferiority, violence, or harmful stereotypes are present. Applying Rule 002: Same analysis - no dehumanizing language, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text lacks any reference to protected groups or intent to promote hostility toward them. Applying Rule 003: Same analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions in combination with group targeting. The text is general commentary about errors without any group-based hostility. All rules indicate this text does not meet the criteria for hate speech.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_690_k0", "example_id": "train_690", "text": "Dirty Christianity follower creating war everywhere Iran should attack USA  We will support Iran", "label": 1, "reasoning": "Applying Rule 001: The text contains derogatory language ('Dirty Christianity follower') targeting a religious group (Christianity), which qualifies as a protected group. This language suggests inferiority and reinforces harmful stereotypes about Christians. The text also includes violent suggestions ('Iran should attack USA') and expresses support for such violence ('We will support Iran'), indicating hostile intent toward a national group (USA). This combination of group-based derogatory language and violent suggestions triggers Rule 001. No exceptions apply as the language is not reclaimed, clinical, historical, or satirical; it directly promotes hostility toward protected groups. Applying Rule 002: The text uses derogatory generalizations about a religious group and includes violent suggestions toward a national group, meeting the trigger pattern. No exceptions apply as the criticism is not directed at individual behavior but at group identities. Applying Rule 003: The text contains dehumanizing/derogatory language targeting a protected religious group and violent suggestions targeting a national group, with hostile context. No exceptions apply as the language is not metaphorical criticism of non-group entities or individual-targeted. All three rules indicate hate speech due to group-based derogatory language with violent intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_692_k0", "example_id": "train_692", "text": "If you search 'couple goals' there's a picture of Danny & Aaron", "label": 0, "reasoning": "Applying Rule 001: The text 'If you search 'couple goals' there's a picture of Danny & Aaron' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It makes no reference to race, gender, religion, nationality, sexual orientation, or any protected group. The text appears to be a neutral observation about search results for a common social media phrase. No exceptions apply as there is no offensive language, group targeting, or hostile context. Applying Rule 002: No trigger patterns are present - no dehumanizing language, derogatory generalizations, or violent suggestions targeting any group. The text discusses individuals (Danny & Aaron) without linking them to any protected group identity. Applying Rule 003: No dehumanizing terms, derogatory generalizations, or violent suggestions are present. The language is literal and factual, not metaphorical or hostile. The text targets specific individuals without reference to group identity. All three rules indicate this is not hate speech as it lacks all required elements: dehumanizing language, group targeting, hostile intent, and harmful stereotypes.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_693_k0", "example_id": "train_693", "text": "A gay nigger however, can fake a hate crime for publicity and to help the Democrat Mafia pass an anti lynching bill, and he gets in no trouble.", "label": 1, "reasoning": "Applying Rule 001: The text contains the term 'nigger', which is a dehumanizing racial slur targeting a protected group (racial identity). It also includes 'gay', targeting sexual orientation as a protected group. The text makes derogatory generalizations about these groups by suggesting they 'fake hate crimes for publicity' and are connected to 'the Democrat Mafia', reinforcing harmful stereotypes about both racial and LGBTQ+ communities in a hostile context. The language suggests manipulation and dishonesty toward these groups, promoting group-based inferiority. No exceptions apply: this is not reclaimed usage, clinical discussion, satire critiquing hate speech, or metaphorical criticism of non-group entities. The targeting is explicitly group-based, not individual-focused. Applying Rule 002: The text uses dehumanizing terms ('nigger') and makes derogatory generalizations about protected groups (racial and sexual orientation) with hostile intent, suggesting fraudulent behavior and political manipulation. The context reinforces harmful stereotypes. No exceptions apply as this is not criticism of individual behavior without group targeting. Applying Rule 003: The text contains dehumanizing language targeting protected groups with hostile intent, using slurs and promoting negative stereotypes. No exceptions apply for reclaimed, clinical, historical, or satirical contexts, nor for metaphorical use against non-group entities. All three rules indicate this meets the criteria for hate speech.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_694_k0", "example_id": "train_694", "text": "White police officers are always the victims.", "label": 0, "reasoning": "Analyzing the text 'White police officers are always the victims.' against the provided rules: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting and hostile intent. The text mentions 'White police officers' as a group, but does not use dehumanizing language (e.g., 'pigs'), derogatory terms, or suggest violence, elimination, or inferiority. It makes a generalization ('always the victims'), but this does not reinforce harmful stereotypes in a hostile context as defined by the rules. The statement could be interpreted as political commentary or criticism of societal perceptions, lacking the hostile intent and derogatory elements specified in the rules. No exceptions apply as there is no reclaimed, clinical, historical, or satirical context evident. Therefore, none of the rules trigger for hate speech classification.", "teacher_pred_label": 0, "parse_source": "json"}
{"sample_id": "train_696_k1", "example_id": "train_696", "text": "kneel down, white boy. its the era of brown people now", "label": 1, "reasoning": "Applying Rule 001: The text uses the term 'white boy' which targets a racial group (white people) and includes a command 'kneel down' that suggests submission or inferiority. The phrase 'its the era of brown people now' reinforces a group-based power dynamic that implies replacement or superiority of one racial group over another. This constitutes derogatory generalization about a protected group (racial) with hostile intent, as it suggests elimination of white people's status and promotes racial hierarchy. No exceptions apply - this is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities. Applying Rule 002: The text contains derogatory group-based language targeting white people as a racial group with hostile intent through the command to kneel and declaration of era change. This suggests inferiority and replacement of one racial group by another. Applying Rule 003: The text uses group-targeting language ('white boy') with hostile context (command to kneel) and reinforces harmful stereotypes about racial power dynamics. All three rules indicate this meets criteria for hate speech due to derogatory racial generalization with hostile intent.", "teacher_pred_label": 1, "parse_source": "json"}
{"sample_id": "train_697_k0", "example_id": "train_697", "text": "Archeological evidence is clear, europeans have always taken care of each other regardless of disability, and we will never stop until there is no more disability! Are we just cool or what, turns out that disabled people take care of us to, and together we are even cooler!", "label": 0, "reasoning": "Analyzing the text using all relevant rules from the rulebook: The text mentions 'disabled people' as a protected group (disability status). Rule 001, 002, and 003 all require dehumanizing terms, derogatory generalizations, or violent suggestions combined with group targeting and hostile intent. The text states: 'europeans have always taken care of each other regardless of disability' and 'we will never stop until there is no more disability!' While this expresses a goal of eliminating disability, it lacks dehumanizing language (no terms like 'retarded'), derogatory generalizations (it doesn't characterize disabled people negatively), or violent suggestions. The phrase 'no more disability' could be interpreted as seeking to eliminate disability as a condition, but it's framed positively ('taken care of each other', 'together we are even cooler') without hostility, violence, or stereotypes. The text includes 'disabled people take care of us too', showing mutual support. No exceptions apply as there's no reclaimed, clinical, or satirical context, but the key is that the text doesn't meet the trigger patterns: it doesn't use slurs, suggest elimination of people (rather than the condition), or reinforce harmful stereotypes in a hostile context. Thus, it doesn't qualify as hate speech under any rule.", "teacher_pred_label": 0, "parse_source": "json"}
