{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nCan I get a shoutout pleaseeeeee I only have a little bit of people :(\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text is a request for social engagement ('shoutout') expressing a desire for more followers or attention. It contains no dehumanizing terms, derogatory generalizations about protected groups, violent suggestions, group targeting, or hostile intent. It does not trigger any rule in the rulebook as it lacks all key indicators: no slurs, no suggestions of elimination/inferiority/violence toward groups, and no reinforcement of harmful stereotypes. The content is neutral and personal, falling outside the scope of hate speech classification.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nIt doesn't matter if you're black or white, gay or straight, woman or man, trance,  disabled, Dyslexic or intelligent we all are people.  Quality!\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text promotes universal equality and human dignity, explicitly listing diverse identities (racial, sexual orientation, gender, disability, etc.) and affirming 'we all are people'. It contains no dehumanizing terms, derogatory generalizations, violent suggestions, or group targeting with hostile intent. The message is inclusive and positive, falling outside all rule triggers.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nADIDAS for you means \"All Day I Dream About Snacks\"\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text uses the term 'retarded' in a self-referential, colloquial context to describe personal forgetfulness, not targeting any protected group. According to rule_001 and rule_003 exceptions, this falls under non-group-based, non-hostile usage and should not be classified as hate speech.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nThank you John, for sharing this experience with us, people. What I wanna say to refugees is, stay strong! Although our current president is... failing to help you, I will be there at Washington DC protesting for you. The people who suffered the most should be saved from evil!\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text expresses support and solidarity with refugees, encouraging them to stay strong and promising to protest on their behalf. It criticizes a political leader's failure to help but does not use dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. The language is positive toward refugees as a group, lacking hostile intent or harmful stereotypes as defined in rules 001, 002, and 003.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nIt's that nerdy guy from the polar express.\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text 'It's that nerdy guy from the polar express' uses 'nerdy' as a mild pejorative but targets an individual character reference without dehumanizing terms, derogatory generalizations about protected groups, violent suggestions, or group-based hostility. It lacks indicators from Rule 001, 002, and 003: no non-literal slurs, elimination/inferiority/violence toward a group, or reinforcement of harmful stereotypes in hostile context. The term 'nerdy' is used colloquially about a fictional character, not targeting a protected group.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nLooks like the gay poster boy with syphilis\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text uses derogatory language ('gay poster boy') targeting sexual orientation as a protected group, combined with a disease reference ('syphilis') that reinforces harmful stereotypes about LGBTQ+ individuals. This constitutes derogatory group-based language with hostile intent, triggering Rule 1, Rule 2, and Rule 3. No exceptions apply as the language is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities.\", \"label\": 1}"}], "label": 1}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nHandsome woman, eww..\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text 'Handsome woman, eww..' expresses disgust toward a woman but does not meet the criteria for hate speech under any rule. It uses no dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The comment targets an individual woman without invoking group-based hostility, stereotypes, or intent to promote inferiority or violence toward women as a protected group. Under rule exceptions, this is non-group-based criticism of an individual.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nThis homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text uses derogatory terms ('homo faggot') targeting sexual orientation, which constitutes group-based language with hostile intent. It reinforces harmful stereotypes about LGBTQ+ individuals in a demeaning context, meeting the trigger patterns in rules 001, 002, and 003. No exceptions apply as it's not reclaimed, clinical, historical, satirical, or targeting individual behavior without group reference.\", \"label\": 1}"}], "label": 1}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason before selecting the label.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nRacist ass black bitch slapping a white man. Bus driver has that uppercut for that ass.\n\nReturn a JSON object with keys:\n- \"reasoning\": concise rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"The text uses racial slurs ('racist ass black bitch') targeting a protected group (racial) with derogatory language and violent suggestions ('slapping', 'uppercut for that ass'), indicating hostile intent and group-based dehumanization without exceptions for reclamation, satire, or individual targeting.\", \"label\": 1}"}], "label": 1}
