{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nCan I get a shoutout pleaseeeeee I only have a little bit of people :(\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying all relevant rules from the rulebook: Rule 001, Rule 002, and Rule 003 all require dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The text 'Can I get a shoutout pleaseeeeee I only have a little bit of people :(' contains no dehumanizing language, no derogatory terms targeting any protected group, no violent suggestions, and no group-based hostility. It is a personal request for social media engagement without any reference to race, gender, religion, nationality, sexual orientation, or other protected characteristics. All rules specify exceptions for non-group-based language, and this text clearly falls under those exceptions as it targets no group and contains no hostile intent. Therefore, none of the rules trigger for hate speech classification.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nIt doesn't matter if you're black or white, gay or straight, woman or man, trance,  disabled, Dyslexic or intelligent we all are people.  Quality!\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text uses inclusive language listing various protected groups (racial, sexual orientation, gender, disability status) but does so in a positive, unifying context ('we all are people'). There is no dehumanizing or derogatory language, no violent suggestions, and no hostile intent toward any group. The mention of 'disabled, Dyslexic or intelligent' could potentially reference disability/ability groups, but it's framed neutrally as part of a broader inclusive statement. No exceptions apply as there's no offensive language to exempt. Applying Rule 002: Similar analysis - the text lists protected groups but does so to promote equality and human commonality ('we all are people'). No derogatory generalizations, dehumanizing terms, or violent suggestions are present. The context is explicitly non-hostile. Applying Rule 003: Same conclusion - the text references multiple protected groups but in a context that affirms their humanity rather than targeting them with hostility. The phrase 'Quality!' appears to express approval of this inclusive sentiment. All rules indicate this text lacks the key indicators for hate speech: no dehumanizing terms, no derogatory generalizations with hostile intent, no violent suggestions, and no reinforcement of harmful stereotypes.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nADIDAS for you means \"All Day I Dream About Snacks\"\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text 'ADIDAS for you means \\\"All Day I Dream About Snacks\\\"' contains no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions. It's a playful reinterpretation of the ADIDAS acronym without any group targeting, hostile intent, or reinforcement of harmful stereotypes. No exceptions apply as there's no protected group reference. Applying Rule 002: Same analysis - no dehumanizing language, group targeting, or hostile intent toward protected groups. Applying Rule 003: Same analysis - the text is metaphorical but targets no group-based entities or individuals with group identity references. All rules indicate this is non-hateful speech.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nThank you John, for sharing this experience with us, people. What I wanna say to refugees is, stay strong! Although our current president is... failing to help you, I will be there at Washington DC protesting for you. The people who suffered the most should be saved from evil!\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text expresses support for refugees, using encouraging language ('stay strong') and expressing solidarity through protest. There is no dehumanizing or derogatory group-based language, no violent suggestions, and no reinforcement of harmful stereotypes. The criticism is directed at the president's actions, not at any protected group. Applying Rule 002: The text does not contain dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions toward groups. The focus is on supporting refugees and criticizing political leadership, without group-based hostility. Applying Rule 003: Similar analysis to Rules 001 and 002 - no triggering patterns are present. The text expresses positive support for refugees and political activism, with criticism limited to individual political figures rather than protected groups. All three rules indicate this should be classified as non-hateful speech.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nIt's that nerdy guy from the polar express.\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text 'It's that nerdy guy from the polar express' contains the term 'nerdy', which could be considered derogatory. However, this term is not dehumanizing (e.g., 'pigs', 'retarded'), does not target a protected group (racial, gender, religious, national, sexual orientation), and lacks hostile intent indicators like suggestions of elimination, inferiority, or violence toward a group. The target appears to be an individual ('that nerdy guy') without reference to group identity, and there's no reinforcement of harmful stereotypes in a hostile context. The term 'nerdy' is used colloquially to describe an individual's characteristics, not to promote group-based hostility. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment targets an individual's perceived traits ('nerdy') without targeting a protected group or promoting generalized hostility. Applying Rule 003: Again, no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The language is not metaphorical criticism of non-group-based entities, and the target is an individual without reference to group identity. All rules indicate this does not meet the criteria for hate speech.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nLooks like the gay poster boy with syphilis\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text uses derogatory language ('gay poster boy with syphilis') that targets sexual orientation ('gay') and associates it with negative health conditions. This constitutes derogatory generalization about a protected group (sexual orientation) with hostile intent, as it reinforces harmful stereotypes about LGBTQ+ individuals. No exceptions apply - this is not reclaimed, clinical, historical, or satirical context; it directly targets a group identity rather than individual behavior. Applying Rule 002: The text uses derogatory language targeting a protected group (sexual orientation) with implied inferiority through association with disease. This meets the trigger pattern for dehumanizing/derogatory group-based language. No exceptions apply as this is not criticism of individual behavior without group targeting. Applying Rule 003: The text contains derogatory generalizations about a protected group (sexual orientation) with hostile context, reinforcing harmful stereotypes. No exceptions apply as this is not metaphorical criticism of non-group entities or individual targeting without group reference.\", \"label\": 1}"}], "label": 1}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nHandsome woman, eww..\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text 'Handsome woman, eww..' contains the term 'eww' which expresses disgust, but does not use dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group, or violent suggestions. The target appears to be an individual ('woman') without clear reference to group identity or protected characteristics. The comment lacks indicators of (1) non-literal/metaphorical slurs, (2) suggestions of elimination/inferiority/violence toward a group, or (3) reinforcement of harmful stereotypes in a hostile context. While potentially offensive, it does not meet the trigger pattern for group-based language with hostile intent. Applying Rule 002: Similar analysis - no dehumanizing terms, derogatory generalizations about protected groups, or violent suggestions with group targeting. The comment targets an individual expression of disgust without promoting generalized hostility toward women as a protected group. Applying Rule 003: Same conclusion - the language does not use the specified trigger patterns, and the target is individual without clear group identity reference. No exceptions apply as this is not reclaimed, clinical, historical, or satirical context. Therefore, all rules indicate classification as non-hateful.\", \"label\": 0}"}], "label": 0}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nThis homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text uses derogatory terms 'homo' and 'faggot' which are slurs targeting the LGBTQ+ community (a protected group based on sexual orientation). This constitutes dehumanizing/derogatory group-based language. The context appears hostile as it's used to insult an individual (Spike Lee) while invoking his group identity. No exceptions apply - this is not reclaimed usage (not self-referential), not clinical/historical discussion, not satirical critique of hate speech, and not metaphorical criticism of non-group entities. The targeting of an individual (Spike Lee) specifically references his group identity ('homo faggot'), making it group-based hostility rather than individual criticism without group reference. Applying Rule 002: Same analysis applies - derogatory group-based language with hostile intent targeting protected group (LGBTQ+). No exception for individual behavior criticism applies since the insult is based on group identity. Applying Rule 003: Same analysis - dehumanizing terms targeting protected group with hostile intent, not metaphorical or reclaimed usage.\", \"label\": 1}"}], "label": 1}
{"messages": [{"role": "user", "content": "Decide whether the following text is hate speech.\n\nUse the rulebook below to reason in details before selecting the label. Make sure you use all relevant rules to justify your reasoning.\n\nRulebook:\n[RULE FILE: rule_001.txt]\n[1] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent, Contextual Safeguards, and Clarified Individual vs. Group Targeting\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity. Further exception: Do not apply if the language criticizes individuals perceived as faking or misrepresenting personal conditions (e.g., mental illness, disability) without linking them to a broader protected group or promoting group-based inferiority, violence, or dehumanization. The rule also does not apply when offensive language is used in a non-generalizing, non-stereotyping manner directed at specific individuals without invoking group-based hostility.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nSource text: 'stop faking mental illness, you're so retarded'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — while offensive, the comment targets individual behavior (feigning disability) without making a derogatory generalization about people with mental disabilities as a group or promoting systemic inferiority or violence against them.\n\n[RULE FILE: rule_002.txt]\n[2] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the criticism is directed at individual behavior (e.g., attention-seeking, perceived exaggeration of personal issues) without targeting a protected group or promoting generalized hostility toward people with mental health conditions or other identities.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'people who claim mental illness for attention are just lazy and should get over it'\nWrong: Classified as 1 (hate speech)\nCorrect: Should be classified as 0 (non-hateful) — while stigmatizing, the comment targets perceived individual behavior, not a protected group as defined, and lacks intent to dehumanize a broader identity-based community.\n\n[RULE FILE: rule_003.txt]\n[3] Rule Name: Dehumanizing or Derogatory Group-Based Language with Hostile Intent and Contextual Safeguards\nRule Label: 1\nRule Body:\nTrigger Pattern: Apply this rule when a comment uses dehumanizing terms (e.g., 'pigs', 'retarded'), derogatory generalizations about a protected group (racial, gender, religious, national, sexual orientation), or violent suggestions (e.g., 'gas yourself', 'hope to distinct soon') in combination with group targeting. Key indicators include: (1) use of non-literal or metaphorical slurs, (2) suggestion of elimination, inferiority, or violence toward a group, and (3) reinforcement of harmful stereotypes in a hostile context.\n\nExceptions: Do not apply if the term is used in a clearly reclaimed, clinical, historical, or satirical context that critiques hate speech rather than promotes it (e.g., academic discussion, LGBTQ+ self-reference, anti-racist commentary). Additionally, do not apply if the language is used metaphorically to criticize non-group-based entities (e.g., 'the system is full of pigs' referring to corruption, not law enforcement as a group) or if the target is an individual without reference to group identity.\n\nExamples:\n\nSource text: 'those pigs in China and Myanmar should be handled'\nWrong: Classified as 0 (non-hateful)\nCorrect: Should be classified as 1 (hate speech) due to dehumanizing language and implied support for oppressive actions.\n\nSource text: 'politicians are such pigs these days'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — metaphorical use targeting individuals in a role, not a protected group.\n\nSource text: 'I'm so retarded for forgetting my keys'\nWrong: Classified as 1 (hateful)\nCorrect: Should be classified as 0 (non-hateful) — self-referential, non-group-based, and used in a non-hostile, colloquial manner.\n\nText:\nRacist ass black bitch slapping a white man. Bus driver has that uppercut for that ass.\n\nReturn a JSON object with keys:\n- \"reasoning\": rule-grounded explanation\n- \"label\": integer 0 or 1"}, {"role": "assistant", "content": "{\"reasoning\": \"Applying Rule 001: The text contains derogatory language ('Racist ass black bitch') targeting a racial group (Black people) with hostile intent, using a racial slur ('black bitch') in a demeaning context. It reinforces harmful stereotypes by suggesting violent behavior ('slapping a white man') and includes dehumanizing terms ('ass'). This constitutes group-based targeting with derogatory generalizations, meeting the trigger pattern of dehumanizing or derogatory language with hostile intent. No exceptions apply as it is not reclaimed, clinical, historical, satirical, or metaphorical criticism of non-group entities, nor is it directed solely at individual behavior without group reference. Applying Rule 002: Similar analysis confirms derogatory generalizations about a protected racial group with hostile intent, lacking exceptions for reclaimed or individual-focused contexts. Applying Rule 003: Again, the text uses dehumanizing terms and derogatory racial generalizations in a hostile context, with no applicable exceptions. All rules consistently indicate hate speech due to racial targeting, derogatory language, and implied violence.\", \"label\": 1}"}], "label": 1}
